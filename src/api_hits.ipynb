{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import urllib.parse\n",
    "df = pd.read_pickle(\"../data/arxiv_paper_ids.pickle\")\n",
    "\n",
    "ARXIV_LINK= \"http://export.arxiv.org/api/query?search_query=\"\n",
    "ns={'n':'http://www.w3.org/2005/Atom'}\n",
    "\n",
    "def construct_arxiv_link(paper_title=None, author=None, abstract=None, start_idx = 0, max_results= 100):\n",
    "    param_dict= {\n",
    "        \"ti\": paper_title,\n",
    "        \"au\":author,\n",
    "        \"abs\": abstract,\n",
    "        }\n",
    "    str_query = \"\"\n",
    "    query_list = []\n",
    "    for k, v in param_dict.items():\n",
    "        if v is not None:\n",
    "            value_str = \" \".join(v.split(\" \"))\n",
    "            value_str = f\"%22{value_str}%22\"\n",
    "            query_list.append(f\"{k}:{value_str}\")\n",
    "    str_query = \"+AND+\".join(query_list)\n",
    "    str_query = urllib.parse.quote_plus(str_query)\n",
    "        \n",
    "\n",
    "    str_query += f\"&sortBy=lastUpdatedDate&start={start_idx}&max_results={max_results}\"\n",
    "    return ARXIV_LINK + str_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# urllib.parse.quote_plus(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_title=  \"UnsupervisedR&R: Unsupervised Point Cloud Registration via Differentiable Rendering\"\n",
    "author= None\n",
    "abstract= None\n",
    "link_arxiv = construct_arxiv_link(paper_title=paper_title, author=author,abstract=abstract, max_results=200)\n",
    "\n",
    "response = requests.get(link_arxiv)\n",
    "xmlstring = response.text\n",
    "tree = ET.ElementTree(ET.fromstring(xmlstring))\n",
    "tree_root = tree.getroot()\n",
    "all_papers = tree_root.findall('n:entry',namespaces=ns)\n",
    "papers_data = {}\n",
    "for paper in all_papers:\n",
    "    temp_tile = paper.find('n:title',namespaces=ns).text\n",
    "    all_authors = list(paper.findall('n:author',namespaces=ns))\n",
    "    paper_id = paper.find('n:id',namespaces=ns).text.replace(\"http://arxiv.org/\",\"\")\n",
    "    paper_author_list = []\n",
    "    for au in all_authors:\n",
    "        paper_author_list.append(list(au)[0].text)\n",
    "    paper_details = {\"paper_arxiv_id\":paper_id, \"authors\": paper_author_list, \"paper_title\": temp_tile}\n",
    "    papers_data[paper_id] = paper_details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://export.arxiv.org/api/query?search_query=ti%3A%2522UnsupervisedR%26R%3A+Unsupervised+Point+Cloud+Registration+via+Differentiable+Rendering%2522&sortBy=lastUpdatedDate&start=0&max_results=200'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link_arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abs/2102.11870v1': {'paper_arxiv_id': 'abs/2102.11870v1',\n",
       "  'authors': ['Mohamed El Banani', 'Luya Gao', 'Justin Johnson'],\n",
       "  'paper_title': 'UnsupervisedR&R: Unsupervised Point Cloud Registration via\\n  Differentiable Rendering'}}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k,v in papers_data.items():\n",
    "#     temp_df = pd.DataFrame.from_dict(papers_data[k])\n",
    "#     df = pd.concat([df, temp_df])\n",
    "# df = df.drop_duplicates()\n",
    "# df.to_pickle(\"../data/arxiv_paper_ids.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../data/arxiv_paper_ids.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"summary\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "unq_paper_id = df[\"paper_arxiv_id\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abs/2212.00794v1\n",
      "abs/2205.09113v2\n",
      "abs/2203.16527v2\n",
      "abs/2111.06377v3\n",
      "abs/2111.11429v1\n",
      "abs/2104.02057v4\n",
      "abs/2104.14558v1\n",
      "abs/2011.10566v1\n",
      "abs/2007.06559v2\n",
      "abs/2003.12056v2\n",
      "abs/1912.00998v2\n",
      "abs/2003.13678v1\n",
      "abs/1911.05722v3\n",
      "abs/2003.04297v1\n",
      "abs/1912.08193v2\n",
      "abs/1812.03982v3\n",
      "abs/1903.12174v2\n",
      "abs/1904.09664v2\n",
      "abs/1812.05038v2\n",
      "abs/1801.00868v3\n",
      "abs/1901.02446v2\n",
      "abs/1904.01569v2\n",
      "abs/1812.03411v2\n",
      "abs/1811.08883v1\n",
      "abs/1806.05662v3\n",
      "abs/1803.08494v3\n",
      "abs/1805.00932v1\n",
      "abs/1706.02677v2\n",
      "abs/1711.07971v3\n",
      "abs/1711.10370v2\n",
      "abs/1704.07333v3\n",
      "abs/1708.02002v2\n",
      "abs/1703.06870v3\n",
      "abs/1712.04440v1\n",
      "abs/1708.02901v3\n",
      "abs/1612.03144v2\n",
      "abs/1611.05431v2\n",
      "abs/1504.06066v2\n",
      "abs/1607.07032v2\n",
      "abs/1603.05027v3\n",
      "abs/1605.06409v2\n",
      "abs/1604.05144v1\n",
      "abs/1603.08678v1\n",
      "abs/1506.01497v3\n",
      "abs/1512.04412v1\n",
      "abs/1512.03385v1\n",
      "abs/1505.06798v2\n",
      "abs/1501.00092v3\n",
      "abs/1503.01640v2\n",
      "abs/1505.00996v1\n",
      "abs/1406.4729v4\n",
      "abs/1412.1283v4\n",
      "abs/1502.01852v1\n",
      "abs/1412.1710v1\n",
      "abs/1411.4229v1\n",
      "abs/2211.10831v1\n",
      "abs/2206.07643v2\n",
      "abs/2211.01340v2\n",
      "abs/2210.16782v1\n",
      "abs/2107.07110v3\n",
      "abs/2210.08340v2\n",
      "abs/2203.05483v3\n",
      "abs/2210.04135v1\n",
      "abs/2206.02574v2\n",
      "abs/2210.02885v1\n",
      "abs/2210.01571v1\n",
      "abs/2209.15261v1\n",
      "abs/2209.14905v1\n",
      "abs/2209.14884v1\n",
      "abs/2112.09214v2\n",
      "abs/2208.12345v1\n",
      "abs/2110.06848v3\n",
      "abs/2207.10081v1\n",
      "abs/2206.10698v2\n",
      "abs/2206.08954v1\n",
      "abs/2206.07700v1\n",
      "abs/2205.11508v3\n",
      "abs/2205.10279v1\n",
      "abs/2110.09348v3\n",
      "abs/2204.07184v1\n",
      "abs/2204.03632v2\n",
      "abs/2202.08325v1\n",
      "abs/2105.04906v3\n",
      "abs/2201.10000v1\n",
      "abs/2110.09485v2\n",
      "abs/2104.12763v2\n",
      "abs/2103.03230v3\n",
      "abs/1906.11661v2\n",
      "abs/2103.15949v1\n",
      "abs/2010.00679v2\n",
      "abs/1709.01062v2\n",
      "abs/1904.03148v1\n",
      "abs/1902.08401v1\n",
      "abs/1812.01161v2\n",
      "abs/1901.02705v1\n",
      "abs/1811.04201v1\n",
      "abs/1803.11496v2\n",
      "abs/1804.00921v2\n",
      "abs/1706.04223v3\n",
      "abs/1806.00499v1\n",
      "abs/1805.12076v1\n",
      "abs/1711.11248v3\n",
      "abs/1705.07177v2\n",
      "abs/1802.01817v1\n",
      "abs/1711.04994v3\n",
      "abs/1611.07476v2\n",
      "abs/1708.02657v2\n",
      "abs/1703.07684v3\n",
      "abs/1612.03969v3\n",
      "abs/1611.08097v2\n",
      "abs/1611.01838v5\n",
      "abs/1612.05231v3\n",
      "abs/1602.06662v2\n",
      "abs/1609.03126v4\n",
      "abs/1511.06444v3\n",
      "abs/1606.01781v2\n",
      "abs/1511.03719v7\n",
      "abs/1611.03383v1\n",
      "abs/1511.05212v5\n",
      "abs/1606.08057v1\n",
      "abs/1606.01535v1\n",
      "abs/1510.05970v2\n",
      "abs/1502.01710v5\n",
      "abs/1509.01626v3\n",
      "abs/1511.05666v4\n",
      "abs/1511.05440v6\n",
      "abs/1506.02351v8\n",
      "abs/1509.08967v2\n",
      "abs/1503.03438v3\n",
      "abs/1412.6651v8\n",
      "abs/1409.4326v2\n",
      "abs/1509.03591v1\n",
      "abs/1506.03011v2\n",
      "abs/1412.6056v6\n",
      "abs/1506.05163v1\n",
      "abs/1411.4280v3\n",
      "abs/1412.7022v3\n",
      "abs/1504.02518v2\n",
      "abs/1412.7580v3\n",
      "abs/1412.6615v4\n",
      "abs/1410.6973v2\n",
      "abs/1412.0233v3\n",
      "abs/1409.7963v1\n",
      "abs/1406.2984v2\n",
      "abs/1404.0736v2\n",
      "abs/1312.6203v3\n",
      "abs/1404.7195v1\n",
      "abs/1312.5851v5\n",
      "abs/1311.4025v3\n",
      "abs/1312.6229v4\n",
      "abs/1312.1847v2\n",
      "abs/1212.0142v2\n",
      "abs/1301.3764v2\n",
      "abs/1301.3577v3\n",
      "abs/2201.08383v2\n",
      "abs/2211.15876v1\n",
      "abs/2211.13225v1\n",
      "abs/2211.07638v1\n",
      "abs/2211.03785v1\n",
      "abs/2206.00888v2\n",
      "abs/2210.04887v1\n",
      "abs/2210.03109v1\n",
      "abs/2209.12892v1\n",
      "abs/2110.05472v2\n",
      "abs/2209.09232v1\n",
      "abs/2205.15299v2\n",
      "abs/2209.02778v1\n",
      "abs/2009.14193v5\n",
      "abs/2112.02094v2\n",
      "abs/2106.14405v2\n",
      "abs/2110.06199v2\n",
      "abs/2201.10029v2\n",
      "abs/2204.06107v1\n",
      "abs/2112.01526v2\n",
      "abs/2110.07058v3\n",
      "abs/2203.06173v1\n",
      "abs/2202.05265v1\n",
      "abs/2012.09856v2\n",
      "abs/2004.04650v2\n",
      "abs/2112.04477v1\n",
      "abs/2112.01010v1\n",
      "abs/2112.01001v1\n",
      "abs/2111.09887v1\n",
      "abs/2111.07868v1\n",
      "abs/2107.09584v2\n",
      "abs/2111.01674v1\n",
      "abs/2110.04994v1\n",
      "abs/2101.02703v3\n",
      "abs/2107.04034v1\n",
      "abs/2104.11227v1\n",
      "abs/2008.02265v5\n",
      "abs/2012.09843v1\n",
      "abs/2012.01526v1\n",
      "abs/2011.13149v1\n",
      "abs/2011.06698v1\n",
      "abs/2011.01975v1\n",
      "abs/2007.03778v2\n",
      "abs/2010.03592v1\n",
      "abs/1905.07553v4\n",
      "abs/2004.03355v3\n",
      "abs/2007.15649v2\n",
      "abs/2006.16992v2\n",
      "abs/2007.03672v3\n",
      "abs/1912.13503v4\n",
      "abs/2007.10982v1\n",
      "abs/2004.02025v3\n",
      "abs/2006.04096v1\n",
      "abs/2004.03590v1\n",
      "abs/2001.08740v2\n",
      "abs/1906.02739v2\n",
      "abs/1912.11121v1\n",
      "abs/1904.01201v2\n",
      "abs/1905.12612v2\n",
      "abs/1910.02527v1\n",
      "abs/1812.01601v4\n",
      "abs/1811.12373v2\n",
      "abs/1908.04781v2\n",
      "abs/1903.02531v2\n",
      "abs/1906.04160v1\n",
      "abs/1812.11971v3\n",
      "abs/1806.03265v2\n",
      "abs/1904.03239v1\n",
      "abs/1702.03920v3\n",
      "abs/1901.08227v1\n",
      "abs/1901.01971v2\n",
      "abs/1812.08985v1\n",
      "abs/1812.00940v1\n",
      "abs/1811.12569v1\n",
      "abs/1811.12402v1\n",
      "abs/1809.09087v2\n",
      "abs/1810.03599v2\n",
      "abs/1810.01406v1\n",
      "abs/1809.02882v1\n",
      "abs/1808.10654v1\n",
      "abs/1612.00404v4\n",
      "abs/1803.07549v2\n",
      "abs/1805.11085v2\n",
      "abs/1807.06757v1\n",
      "abs/1712.06584v2\n",
      "abs/1806.08354v1\n",
      "abs/1705.08421v4\n",
      "abs/1712.01812v2\n",
      "abs/1801.03910v2\n",
      "abs/1804.08606v1\n",
      "abs/1804.08328v1\n",
      "abs/1712.08125v1\n",
      "abs/1712.02310v1\n",
      "abs/1703.00441v2\n",
      "abs/1704.00710v2\n",
      "abs/1710.06104v2\n",
      "abs/1710.08247v1\n",
      "abs/1612.06851v2\n",
      "abs/1612.09508v3\n",
      "abs/2212.00792v1\n",
      "abs/2211.15601v2\n",
      "abs/2212.00357v1\n",
      "abs/2212.00266v1\n",
      "abs/2211.16799v1\n",
      "abs/2211.16374v1\n",
      "abs/2211.16266v1\n",
      "abs/2211.16991v1\n",
      "abs/2206.11896v2\n",
      "abs/2211.15496v1\n",
      "abs/2211.15402v1\n",
      "abs/2211.14879v1\n",
      "abs/2211.14823v1\n",
      "abs/2211.12432v2\n",
      "abs/2110.03912v2\n",
      "abs/2211.14738v1\n",
      "abs/2211.14662v1\n",
      "abs/2211.14467v1\n",
      "abs/2211.13497v1\n",
      "abs/2110.00990v2\n",
      "abs/2211.12853v1\n",
      "abs/2211.12656v1\n",
      "abs/2211.12046v1\n",
      "abs/2211.11215v2\n",
      "abs/2211.12018v1\n",
      "abs/2211.11836v1\n",
      "abs/2211.11704v1\n",
      "abs/2211.11674v1\n",
      "abs/2210.08398v2\n",
      "abs/2211.11542v1\n",
      "abs/2211.10865v1\n",
      "abs/2211.07365v2\n",
      "abs/2211.08634v1\n",
      "abs/2210.00471v3\n",
      "abs/2208.10937v2\n",
      "abs/2211.07195v1\n",
      "abs/2211.06897v1\n",
      "abs/2211.06195v1\n",
      "abs/2209.08450v2\n",
      "abs/2210.00379v2\n",
      "abs/2211.03889v1\n",
      "abs/2210.12126v2\n",
      "abs/2211.02299v1\n",
      "abs/2206.00447v2\n",
      "abs/2211.09715v1\n",
      "abs/2209.02692v3\n",
      "abs/2203.15065v2\n",
      "abs/2210.16674v1\n",
      "abs/2210.16135v1\n",
      "abs/2210.15664v1\n",
      "abs/2210.15200v1\n",
      "abs/2210.15040v1\n",
      "abs/2210.13041v1\n",
      "abs/2210.08291v3\n",
      "abs/2210.12636v1\n",
      "abs/2210.11467v1\n",
      "abs/2210.10767v1\n",
      "abs/2210.09148v1\n",
      "abs/2210.05714v3\n",
      "abs/2210.07301v2\n",
      "abs/2210.08738v1\n",
      "abs/2210.01276v2\n",
      "abs/2206.13597v2\n",
      "abs/2205.15585v2\n",
      "abs/2206.00665v2\n",
      "abs/2210.06094v1\n",
      "abs/2210.05517v1\n",
      "abs/2210.04572v1\n",
      "abs/2210.04265v1\n",
      "abs/2205.10636v5\n",
      "abs/2210.02299v1\n",
      "abs/2210.01721v1\n",
      "abs/2209.15511v1\n",
      "abs/2209.15383v1\n",
      "abs/2209.15153v1\n",
      "abs/2209.14861v1\n",
      "abs/2110.03170v3\n",
      "abs/2209.13433v1\n",
      "abs/2209.13362v1\n",
      "abs/2112.02082v2\n",
      "abs/2209.13159v1\n",
      "abs/2209.13091v1\n",
      "abs/2209.11336v1\n",
      "abs/2204.03353v2\n",
      "abs/2209.10029v1\n",
      "abs/2209.09733v1\n",
      "abs/2210.01772v1\n",
      "abs/2207.08284v2\n",
      "abs/2209.08791v1\n",
      "abs/2209.08409v1\n",
      "abs/2209.08221v1\n",
      "abs/2209.06926v1\n",
      "abs/2209.06562v1\n",
      "abs/2209.05612v1\n",
      "abs/2207.10494v2\n",
      "abs/2208.07003v2\n",
      "abs/2205.00123v5\n",
      "abs/2209.04436v1\n",
      "abs/2209.02705v1\n",
      "abs/2209.02485v1\n",
      "abs/2209.01753v1\n",
      "abs/2209.01104v1\n",
      "abs/2208.14743v1\n",
      "abs/2209.02385v1\n",
      "abs/2205.05335v3\n",
      "abs/2208.12737v1\n",
      "abs/2203.13296v2\n",
      "abs/2208.11537v1\n",
      "abs/2205.02996v2\n",
      "abs/2208.05350v1\n",
      "abs/2203.11397v2\n",
      "abs/2208.04307v1\n",
      "abs/2208.04274v1\n",
      "abs/2208.03840v1\n",
      "abs/2208.03167v1\n",
      "abs/2208.01960v1\n",
      "abs/2207.09686v2\n",
      "abs/2208.00183v1\n",
      "abs/2208.00113v1\n",
      "abs/2207.14279v1\n",
      "abs/2207.13464v1\n",
      "abs/2207.12244v1\n",
      "abs/2207.11094v1\n",
      "abs/2207.10985v1\n",
      "abs/2207.10940v1\n",
      "abs/2207.10690v1\n",
      "abs/2207.10663v1\n",
      "abs/2207.09629v2\n",
      "abs/2207.10183v1\n",
      "abs/2207.10156v1\n",
      "abs/2207.10061v1\n",
      "abs/2112.08906v2\n",
      "abs/2203.15946v2\n",
      "abs/2207.09204v1\n",
      "abs/2107.04286v3\n",
      "abs/2207.08439v1\n",
      "abs/2207.08434v1\n",
      "abs/2203.07553v2\n",
      "abs/2203.03041v4\n",
      "abs/2207.03078v3\n",
      "abs/2111.03170v4\n",
      "abs/2207.04622v1\n",
      "abs/2106.12102v2\n",
      "abs/2207.03434v1\n",
      "abs/2207.03041v1\n",
      "abs/2108.02708v3\n",
      "abs/2112.04846v3\n",
      "abs/2206.15255v1\n",
      "abs/2202.12369v2\n",
      "abs/2206.12959v1\n",
      "abs/2206.12145v1\n",
      "abs/2206.10802v1\n",
      "abs/2206.10274v1\n",
      "abs/2206.08990v1\n",
      "abs/2206.08368v1\n",
      "abs/2206.08365v1\n",
      "abs/2206.08077v1\n",
      "abs/2206.07163v1\n",
      "abs/2206.06340v1\n",
      "abs/2206.08749v1\n",
      "abs/2206.05344v1\n",
      "abs/2206.05236v1\n",
      "abs/2201.12170v4\n",
      "abs/2103.04789v3\n",
      "abs/2206.02840v1\n",
      "abs/2206.02564v1\n",
      "abs/2201.11579v2\n",
      "abs/2205.15954v1\n",
      "abs/2205.14575v1\n",
      "abs/2205.12955v1\n",
      "abs/2205.11480v1\n",
      "abs/2206.02688v1\n",
      "abs/1807.01874v2\n",
      "abs/2204.01899v2\n",
      "abs/2205.02836v2\n",
      "abs/2112.09648v2\n",
      "abs/2205.03716v1\n",
      "abs/2205.02445v1\n",
      "abs/2202.11271v2\n",
      "abs/2205.01634v1\n",
      "abs/2007.03891v3\n",
      "abs/2205.00967v1\n",
      "abs/2204.14240v1\n",
      "abs/2204.13845v1\n",
      "abs/2204.13662v1\n",
      "abs/2204.13096v1\n",
      "abs/2204.11715v1\n",
      "abs/2204.11312v1\n",
      "abs/2204.10211v1\n",
      "abs/2204.10112v1\n",
      "abs/2106.01907v2\n",
      "abs/2204.09083v1\n",
      "abs/2203.01247v2\n",
      "abs/2204.03688v2\n",
      "abs/2204.04730v1\n",
      "abs/2202.01020v3\n",
      "abs/2204.03715v1\n",
      "abs/2204.03642v1\n",
      "abs/2111.14465v2\n",
      "abs/2210.10959v4\n",
      "abs/2212.00122v1\n",
      "abs/2211.17081v1\n",
      "abs/2211.16951v1\n",
      "abs/2211.16940v1\n",
      "abs/2211.16835v1\n",
      "abs/2211.16335v2\n",
      "abs/2211.16798v1\n",
      "abs/1903.09755v4\n",
      "abs/2211.16487v1\n",
      "abs/2211.16290v1\n",
      "abs/2211.03174v2\n",
      "abs/2211.15868v1\n",
      "abs/2211.15692v1\n",
      "abs/2204.13613v2\n",
      "abs/2211.16193v1\n",
      "abs/2205.14971v2\n",
      "abs/2205.01694v2\n",
      "abs/2211.15127v1\n",
      "abs/2211.14651v1\n",
      "abs/2012.01511v5\n",
      "abs/2211.14125v1\n",
      "abs/2211.14054v1\n",
      "abs/2206.06112v2\n",
      "abs/2211.13572v1\n",
      "abs/2211.13398v1\n",
      "abs/2211.12829v1\n",
      "abs/2208.03792v2\n",
      "abs/2208.11975v2\n",
      "abs/2205.15448v2\n",
      "abs/2211.12193v1\n",
      "abs/2211.11983v1\n",
      "abs/2202.09115v3\n",
      "abs/2211.11188v2\n",
      "abs/2211.11941v1\n",
      "abs/2211.11734v1\n",
      "abs/2211.11394v1\n",
      "abs/2211.11354v1\n",
      "abs/2211.11182v1\n",
      "abs/2211.11066v1\n",
      "abs/2211.10963v1\n",
      "abs/2211.10946v1\n",
      "abs/2206.11752v2\n",
      "abs/2211.10470v1\n",
      "abs/2211.10284v1\n",
      "abs/2203.04275v4\n",
      "abs/2011.08790v2\n",
      "abs/2211.09067v1\n",
      "abs/2211.08805v1\n",
      "abs/2211.08754v1\n",
      "abs/2211.08182v1\n",
      "abs/2207.08925v2\n",
      "abs/2211.07214v2\n",
      "abs/2211.07491v1\n",
      "abs/2211.07021v1\n",
      "abs/2203.10180v3\n",
      "abs/2211.04656v2\n",
      "abs/2211.05272v1\n",
      "abs/2211.04691v1\n",
      "abs/2207.03333v2\n",
      "abs/2210.13540v2\n",
      "abs/2210.15022v2\n",
      "abs/2211.03587v1\n",
      "abs/2211.03375v1\n",
      "abs/2202.12555v2\n",
      "abs/2209.09484v2\n",
      "abs/2211.03211v1\n",
      "abs/2211.03151v1\n",
      "abs/2206.02622v2\n",
      "abs/2211.02337v1\n",
      "abs/2209.08418v2\n",
      "abs/2211.01644v1\n",
      "abs/2210.13856v2\n",
      "abs/2211.01048v1\n",
      "abs/2211.00960v1\n",
      "abs/2210.04006v2\n",
      "abs/2210.16788v1\n",
      "abs/2106.05969v3\n",
      "abs/2210.15121v2\n",
      "abs/2210.15134v2\n",
      "abs/2210.15287v1\n",
      "abs/2203.11471v3\n",
      "abs/2210.15145v1\n",
      "abs/2210.04216v3\n",
      "abs/2108.11826v2\n",
      "abs/2006.04335v6\n",
      "abs/2204.09616v2\n",
      "abs/2210.13853v1\n",
      "abs/2210.13797v1\n",
      "abs/2210.17414v1\n",
      "abs/2210.13705v1\n",
      "abs/2210.13702v1\n",
      "abs/2210.13641v1\n",
      "abs/2210.12564v1\n",
      "abs/2210.12476v1\n",
      "abs/2210.12418v1\n",
      "abs/2210.10491v2\n",
      "abs/2210.10033v2\n",
      "abs/2202.14019v2\n",
      "abs/2210.06110v3\n",
      "abs/2210.11826v1\n",
      "abs/2210.11718v1\n",
      "abs/2210.11697v1\n",
      "abs/2210.14165v1\n",
      "abs/2210.12157v1\n",
      "abs/2210.11554v1\n",
      "abs/2210.11384v1\n",
      "abs/2210.11940v1\n",
      "abs/2205.06187v2\n",
      "abs/2210.10716v1\n",
      "abs/2210.10428v1\n",
      "abs/2210.10426v1\n",
      "abs/2208.10211v2\n",
      "abs/2210.10247v1\n",
      "abs/2210.10108v1\n",
      "abs/2210.09757v1\n",
      "abs/2210.09678v1\n",
      "abs/2210.09481v1\n",
      "abs/2210.05318v2\n",
      "abs/2210.08860v1\n",
      "abs/2210.08562v1\n",
      "abs/2210.08394v1\n",
      "abs/2209.06779v3\n",
      "abs/2210.08123v1\n",
      "abs/2210.08054v1\n",
      "abs/2210.07650v1\n",
      "abs/2206.09106v3\n",
      "abs/2210.07199v1\n",
      "abs/2210.07181v1\n",
      "abs/2205.14764v2\n",
      "abs/2201.13065v2\n",
      "abs/2204.12484v3\n",
      "abs/2206.05683v2\n",
      "abs/2210.06551v1\n",
      "abs/2210.06463v1\n",
      "abs/2208.06195v3\n",
      "abs/2210.06028v1\n",
      "abs/2210.06001v1\n",
      "abs/2210.05232v1\n",
      "abs/2205.09821v2\n",
      "abs/2210.05130v1\n",
      "abs/2010.08202v4\n",
      "abs/2210.04553v1\n",
      "abs/2210.04233v1\n",
      "abs/2210.04014v1\n",
      "abs/2210.03984v1\n",
      "abs/2210.03437v1\n",
      "abs/2111.14341v4\n",
      "abs/2210.02231v1\n",
      "abs/2206.08916v2\n",
      "abs/2210.08117v1\n",
      "abs/2210.01406v1\n",
      "abs/2210.01340v1\n",
      "abs/2210.00740v2\n",
      "abs/2209.09777v2\n",
      "abs/2210.01112v1\n",
      "abs/2210.01044v1\n",
      "abs/2210.00924v1\n",
      "abs/2210.00812v1\n",
      "abs/2210.00662v1\n",
      "abs/2210.00507v1\n",
      "abs/2204.03635v2\n",
      "abs/2209.12354v2\n",
      "abs/2210.00294v1\n",
      "abs/2210.00893v1\n",
      "abs/2209.15397v1\n",
      "abs/2208.00237v2\n",
      "abs/2209.13948v1\n",
      "abs/2209.13916v1\n",
      "abs/2206.12628v2\n",
      "abs/2209.13156v1\n",
      "abs/2209.13043v1\n",
      "abs/2209.06855v2\n",
      "abs/2209.12009v1\n",
      "abs/2209.11945v1\n",
      "abs/2208.11328v2\n",
      "abs/2203.09645v3\n",
      "abs/2209.10185v1\n",
      "abs/2209.09987v1\n",
      "abs/2209.09659v1\n",
      "abs/2207.05483v3\n",
      "abs/2209.09470v1\n",
      "abs/2106.10852v4\n",
      "abs/2209.07976v2\n",
      "abs/2209.09050v1\n",
      "abs/2209.08895v1\n",
      "abs/2209.08864v1\n",
      "abs/2209.08790v1\n",
      "abs/2104.07300v3\n",
      "abs/2209.08498v1\n",
      "abs/2208.02129v3\n",
      "abs/2109.12292v2\n",
      "abs/2209.08266v1\n",
      "abs/2209.08194v1\n",
      "abs/2206.12946v2\n",
      "abs/2207.13691v1\n",
      "abs/2206.13345v1\n",
      "abs/2205.07763v1\n",
      "abs/2203.12870v3\n",
      "abs/2109.09934v2\n",
      "abs/2102.13187v1\n",
      "abs/1905.07807v1\n",
      "abs/1710.07400v1\n",
      "abs/2211.06624v1\n",
      "abs/2208.06933v1\n",
      "abs/2205.14313v3\n",
      "abs/2110.03940v2\n",
      "abs/2207.12620v1\n",
      "abs/2009.04710v2\n",
      "abs/2206.01916v1\n",
      "abs/2109.10115v3\n",
      "abs/2104.07639v4\n",
      "abs/2110.08977v1\n",
      "abs/2109.12030v1\n",
      "abs/2109.11282v1\n",
      "abs/2109.05483v1\n",
      "abs/2107.00822v1\n",
      "abs/2105.05600v1\n",
      "abs/2102.07560v3\n",
      "abs/2104.05252v1\n",
      "abs/2104.03176v2\n",
      "abs/2103.15279v1\n",
      "abs/2002.12324v4\n",
      "abs/2009.12662v1\n",
      "abs/2008.09042v1\n",
      "abs/2007.00258v3\n",
      "abs/2006.04847v1\n",
      "abs/1909.06293v4\n",
      "abs/2001.00682v1\n",
      "abs/1912.12726v1\n",
      "abs/1912.08601v1\n",
      "abs/1910.13102v1\n",
      "abs/1909.10270v1\n",
      "abs/1908.08891v1\n",
      "abs/1908.06109v1\n",
      "abs/1702.04423v3\n",
      "abs/1903.08789v1\n",
      "abs/1901.00463v1\n",
      "abs/1809.10035v1\n",
      "abs/1710.10519v3\n",
      "abs/1804.00050v2\n",
      "abs/1803.02380v3\n",
      "abs/1805.04496v1\n",
      "abs/1710.07965v1\n",
      "abs/1611.07853v2\n",
      "abs/1704.04826v1\n",
      "abs/1606.00151v2\n",
      "abs/1612.00040v1\n",
      "abs/1610.04889v1\n",
      "abs/1602.03860v1\n",
      "abs/1601.03329v1\n",
      "abs/1312.7482v2\n",
      "abs/1410.7566v1\n",
      "abs/1409.6045v1\n",
      "abs/1310.4638v2\n",
      "abs/cs/0611135v1\n",
      "abs/2212.00793v1\n",
      "abs/2212.00787v1\n",
      "abs/2212.00774v1\n",
      "abs/2212.00537v1\n",
      "abs/2212.00490v1\n",
      "abs/2212.00362v1\n",
      "abs/2208.13753v2\n",
      "abs/2211.11214v2\n",
      "abs/2212.00235v1\n",
      "abs/2212.00210v1\n",
      "abs/2211.17220v1\n",
      "abs/2210.14870v2\n",
      "abs/2210.03142v2\n",
      "abs/2211.17084v1\n",
      "abs/2211.15029v2\n",
      "abs/2211.16879v1\n",
      "abs/2211.00611v3\n",
      "abs/2211.16750v1\n",
      "abs/2211.16677v1\n",
      "abs/2211.16582v1\n",
      "abs/2211.16431v1\n",
      "abs/2211.16247v1\n",
      "abs/2211.16152v1\n",
      "abs/2211.16116v1\n",
      "abs/2211.16032v1\n",
      "abs/2205.14807v2\n",
      "abs/2201.00308v3\n",
      "abs/2211.17091v1\n",
      "abs/2211.15736v1\n",
      "abs/2211.15657v1\n",
      "abs/2211.15099v1\n",
      "abs/2211.15089v1\n",
      "abs/2211.17106v1\n",
      "abs/2211.14842v1\n",
      "abs/2211.10658v2\n",
      "abs/2211.14680v1\n",
      "abs/2211.14305v1\n",
      "abs/2211.14304v1\n",
      "abs/2211.14169v1\n",
      "abs/2211.14108v1\n",
      "abs/2211.13785v1\n",
      "abs/2211.13757v1\n",
      "abs/2211.13752v1\n",
      "abs/2210.15793v2\n",
      "abs/2211.13006v2\n",
      "abs/2211.13449v1\n",
      "abs/2211.15388v1\n",
      "abs/2210.02438v2\n",
      "abs/2211.13352v1\n",
      "abs/2211.13287v1\n",
      "abs/2209.11888v2\n",
      "abs/2211.13227v1\n",
      "abs/2211.13224v1\n",
      "abs/2211.13221v1\n",
      "abs/2211.13220v1\n",
      "abs/2211.13095v1\n",
      "abs/2211.12737v1\n",
      "abs/2210.12254v2\n",
      "abs/2211.12572v1\n",
      "abs/2211.12500v1\n",
      "abs/2211.12446v1\n",
      "abs/2211.12445v1\n",
      "abs/2210.09276v2\n",
      "abs/2211.12340v1\n",
      "abs/2211.06146v2\n",
      "abs/2207.00050v2\n",
      "abs/2211.12267v1\n",
      "abs/2211.12131v1\n",
      "abs/2211.12039v1\n",
      "abs/2211.11743v1\n",
      "abs/2211.11742v1\n",
      "abs/2211.11694v1\n",
      "abs/2210.00939v3\n",
      "abs/2207.11192v2\n",
      "abs/2210.04872v2\n",
      "abs/2211.11319v1\n",
      "abs/2211.11255v1\n",
      "abs/2207.14626v2\n",
      "abs/2211.15462v1\n",
      "abs/2211.11138v1\n",
      "abs/2211.08332v2\n",
      "abs/2211.11018v1\n",
      "abs/2206.13397v5\n",
      "abs/2211.10950v1\n",
      "abs/2211.10949v1\n",
      "abs/2111.06042v3\n",
      "abs/2112.03860v3\n",
      "abs/2211.12343v1\n",
      "abs/2211.10794v1\n",
      "abs/2211.10682v1\n",
      "abs/2211.10656v1\n",
      "abs/2211.10655v1\n",
      "abs/2211.08892v2\n",
      "abs/2211.10440v1\n",
      "abs/2211.10437v1\n",
      "abs/2211.10370v1\n",
      "abs/2211.09869v1\n",
      "abs/2211.09800v1\n",
      "abs/2211.09795v1\n",
      "abs/2211.09794v1\n",
      "abs/2211.09707v1\n",
      "abs/2209.12152v2\n",
      "abs/2211.09383v1\n",
      "abs/2211.09357v1\n",
      "abs/2211.09324v1\n",
      "abs/2211.01324v4\n",
      "abs/2211.08901v1\n",
      "abs/2211.02048v2\n",
      "abs/2211.08506v1\n",
      "abs/2210.14896v2\n",
      "abs/2211.08089v1\n",
      "abs/2211.08428v1\n",
      "abs/2211.06956v2\n",
      "abs/2211.07825v1\n",
      "abs/2211.07804v1\n",
      "abs/2211.07793v1\n",
      "abs/2203.11072v2\n",
      "abs/2211.07751v1\n",
      "abs/2202.04053v2\n",
      "abs/2211.07600v1\n",
      "abs/2211.07239v1\n",
      "abs/2206.07696v3\n",
      "abs/2209.14687v2\n",
      "abs/2211.06757v1\n",
      "abs/2211.06150v1\n",
      "abs/2211.05556v1\n",
      "abs/2211.04835v1\n",
      "abs/2211.04779v1\n",
      "abs/2211.04604v1\n",
      "abs/2210.15228v2\n",
      "abs/2211.04332v1\n",
      "abs/2211.04236v1\n",
      "abs/2206.14138v3\n",
      "abs/2211.04197v1\n",
      "abs/2211.04195v1\n",
      "abs/2211.04124v1\n",
      "abs/2209.12092v2\n",
      "abs/2209.10690v2\n",
      "abs/2211.03826v1\n",
      "abs/2211.02527v1\n",
      "abs/2211.01323v2\n",
      "abs/2211.02448v1\n",
      "abs/2211.02397v1\n",
      "abs/2211.01777v2\n",
      "abs/2207.05876v2\n",
      "abs/2210.16031v3\n",
      "abs/2211.00948v1\n",
      "abs/2211.00902v1\n",
      "abs/2211.00222v2\n",
      "abs/2211.00529v2\n",
      "abs/2211.00680v1\n",
      "abs/2211.00322v1\n",
      "abs/2211.00135v1\n",
      "abs/2210.17432v1\n",
      "abs/2210.17366v1\n",
      "abs/2202.09778v2\n",
      "abs/2210.17128v1\n",
      "abs/2211.03756v1\n",
      "abs/2210.16886v1\n",
      "abs/2210.16870v1\n",
      "abs/2210.16805v1\n",
      "abs/2203.10197v2\n",
      "abs/2209.14734v2\n",
      "abs/2210.16056v1\n",
      "abs/2210.15629v1\n",
      "abs/2210.15257v1\n",
      "abs/2210.14784v1\n",
      "abs/2210.14571v1\n",
      "abs/2210.08933v2\n",
      "abs/2210.14124v1\n",
      "abs/2111.04090v3\n",
      "abs/2210.13935v1\n",
      "abs/2210.13774v1\n",
      "abs/2210.13695v1\n",
      "abs/2210.12965v1\n",
      "abs/2209.00796v9\n",
      "abs/2210.12867v1\n",
      "abs/2210.12565v1\n",
      "abs/2210.12315v1\n",
      "abs/2210.12192v1\n",
      "abs/2210.12100v1\n",
      "abs/2202.04579v3\n",
      "abs/2207.08208v2\n",
      "abs/2210.11752v1\n",
      "abs/2210.11633v1\n",
      "abs/2210.11427v1\n",
      "abs/2210.09477v3\n",
      "abs/2209.15571v2\n",
      "abs/2210.09292v2\n",
      "abs/2210.11058v1\n",
      "abs/2210.10960v1\n",
      "abs/2206.11898v3\n",
      "abs/2210.10578v1\n",
      "abs/2212.00484v1\n",
      "abs/2212.00449v1\n",
      "abs/2212.00217v1\n",
      "abs/2211.14753v2\n",
      "abs/2211.16791v1\n",
      "abs/2210.15235v2\n",
      "abs/2211.16710v1\n",
      "abs/2211.16654v1\n",
      "abs/2211.16098v1\n",
      "abs/2211.15961v1\n",
      "abs/2211.15662v2\n",
      "abs/2211.15807v1\n",
      "abs/2204.07172v4\n",
      "abs/2211.15303v1\n",
      "abs/2211.13974v2\n",
      "abs/2107.09543v2\n",
      "abs/2211.14902v1\n",
      "abs/2211.03550v2\n",
      "abs/2211.08615v4\n",
      "abs/2211.14577v1\n",
      "abs/2211.14573v1\n",
      "abs/2211.14475v1\n",
      "abs/2210.17274v3\n",
      "abs/2211.14017v1\n",
      "abs/2211.13991v1\n",
      "abs/2211.15513v1\n",
      "abs/2211.13808v1\n",
      "abs/2211.13772v1\n",
      "abs/2211.13339v1\n",
      "abs/2206.08903v2\n",
      "abs/2211.12352v2\n",
      "abs/2208.12055v2\n",
      "abs/2208.03085v2\n",
      "abs/2211.08321v2\n",
      "abs/2211.12084v2\n",
      "abs/2211.12674v1\n",
      "abs/2203.13964v2\n",
      "abs/2211.12553v1\n",
      "abs/2211.12444v1\n",
      "abs/2211.12314v1\n",
      "abs/2211.12209v1\n",
      "abs/2211.12180v1\n",
      "abs/2211.12021v1\n",
      "abs/2211.11695v1\n",
      "abs/2211.11321v1\n",
      "abs/2211.14314v1\n",
      "abs/2211.11208v1\n",
      "abs/2211.11039v1\n",
      "abs/2204.04090v7\n",
      "abs/2211.10883v1\n",
      "abs/2211.10747v1\n",
      "abs/2211.10713v1\n",
      "abs/2208.06222v2\n",
      "abs/2208.00800v2\n",
      "abs/2211.10595v1\n",
      "abs/2211.10563v1\n",
      "abs/2101.04230v3\n",
      "abs/2211.10295v1\n",
      "abs/2202.06533v2\n",
      "abs/2205.01754v3\n",
      "abs/2211.10026v1\n",
      "abs/2202.07773v2\n",
      "abs/2202.00569v4\n",
      "abs/2211.00577v5\n",
      "abs/2211.09454v1\n",
      "abs/2010.15315v2\n",
      "abs/2211.08990v1\n",
      "abs/2211.08424v1\n",
      "abs/2211.08843v1\n",
      "abs/2112.12741v4\n",
      "abs/2211.08772v1\n",
      "abs/2103.10502v3\n",
      "abs/2108.01852v3\n",
      "abs/2211.08702v1\n",
      "abs/2211.08570v1\n",
      "abs/2210.16251v2\n",
      "abs/1907.07786v2\n",
      "abs/2209.10811v2\n",
      "abs/2211.07588v1\n",
      "abs/2211.07316v1\n",
      "abs/2211.07234v1\n",
      "abs/2003.13898v2\n",
      "abs/2210.06334v2\n",
      "abs/2211.06719v1\n",
      "abs/2211.06659v1\n",
      "abs/2211.06595v1\n",
      "abs/2211.06522v1\n",
      "abs/2211.03264v2\n",
      "abs/2211.06198v1\n",
      "abs/2211.06089v1\n",
      "abs/2211.07555v1\n",
      "abs/2205.09204v2\n",
      "abs/2211.05420v1\n",
      "abs/2211.05269v1\n",
      "abs/2206.09349v2\n",
      "abs/2211.02947v2\n",
      "abs/2211.05000v1\n",
      "abs/2211.04734v1\n",
      "abs/2210.04052v2\n",
      "abs/2211.04659v1\n",
      "abs/2211.04610v1\n",
      "abs/2210.00918v2\n",
      "abs/2211.04488v1\n",
      "abs/2109.06315v2\n",
      "abs/2211.04005v1\n",
      "abs/2106.05566v5\n",
      "abs/2211.03144v1\n",
      "abs/2211.03000v1\n",
      "abs/2211.02972v1\n",
      "abs/2210.14874v2\n",
      "abs/2211.02584v1\n",
      "abs/2210.15137v3\n",
      "abs/2211.02141v1\n",
      "abs/2008.08930v7\n",
      "abs/2211.01646v1\n",
      "abs/2211.05629v1\n",
      "abs/2211.01471v1\n",
      "abs/2211.09728v1\n",
      "abs/2211.00930v1\n",
      "abs/2211.00829v1\n",
      "abs/2211.00731v1\n",
      "abs/2209.12243v2\n",
      "abs/2109.11078v3\n",
      "abs/2211.05234v1\n",
      "abs/2211.00098v1\n",
      "abs/2211.00047v1\n",
      "abs/2206.11682v2\n",
      "abs/2103.16262v2\n",
      "abs/2210.15533v2\n",
      "abs/2210.17013v1\n",
      "abs/2210.16857v1\n",
      "abs/2205.03743v3\n",
      "abs/2210.16823v1\n",
      "abs/2210.16482v1\n",
      "abs/2107.12003v2\n",
      "abs/2206.14314v2\n",
      "abs/2210.16248v1\n",
      "abs/2210.16110v1\n",
      "abs/2210.14666v2\n",
      "abs/2210.15887v1\n",
      "abs/2210.15745v1\n",
      "abs/2210.15663v1\n",
      "abs/2201.03139v2\n",
      "abs/2210.15173v1\n",
      "abs/2207.08265v2\n",
      "abs/2210.14775v1\n",
      "abs/2203.09445v2\n",
      "abs/2210.14474v1\n",
      "abs/2210.14409v1\n",
      "abs/2210.14392v1\n",
      "abs/2206.05764v3\n",
      "abs/2210.14090v1\n",
      "abs/2103.15510v3\n",
      "abs/2210.14228v1\n",
      "abs/2210.15657v1\n",
      "abs/2206.09065v2\n",
      "abs/2210.14225v1\n",
      "abs/2201.13279v3\n",
      "abs/2210.12870v1\n",
      "abs/2210.12683v1\n",
      "abs/2209.13002v2\n",
      "abs/2210.12524v1\n",
      "abs/2211.02626v1\n",
      "abs/2210.12504v1\n",
      "abs/2210.12231v1\n",
      "abs/2208.07715v2\n",
      "abs/2210.12113v1\n",
      "abs/2210.11921v1\n",
      "abs/2210.11750v1\n",
      "abs/2210.11654v1\n",
      "abs/2210.07002v3\n",
      "abs/2210.11096v1\n",
      "abs/2202.11701v2\n",
      "abs/2210.11408v1\n",
      "abs/2012.03902v3\n",
      "abs/2210.11428v1\n",
      "abs/2101.08367v3\n",
      "abs/2210.10182v1\n",
      "abs/2210.10780v1\n",
      "abs/2203.02557v3\n",
      "abs/2210.09682v1\n",
      "abs/2210.09509v1\n",
      "abs/2206.14797v3\n",
      "abs/2210.09382v1\n",
      "abs/2210.06909v2\n",
      "abs/2210.08528v1\n",
      "abs/2206.09319v2\n",
      "abs/2008.05865v4\n",
      "abs/2212.00779v1\n",
      "abs/2212.00777v1\n",
      "abs/2212.00760v1\n",
      "abs/2212.00757v1\n",
      "abs/2203.05732v2\n",
      "abs/2212.00694v1\n",
      "abs/2205.01303v2\n",
      "abs/2212.00680v1\n",
      "abs/2212.00665v1\n",
      "abs/2212.00650v1\n",
      "abs/2212.00626v1\n",
      "abs/2111.14477v2\n",
      "abs/2112.11862v2\n",
      "abs/2211.16565v2\n",
      "abs/2211.17177v2\n",
      "abs/2207.10366v2\n",
      "abs/2210.17499v2\n",
      "abs/2212.00547v1\n",
      "abs/2211.16593v2\n",
      "abs/2109.15248v3\n",
      "abs/2209.13779v3\n",
      "abs/2212.00514v1\n",
      "abs/2212.00512v1\n",
      "abs/2212.00507v1\n",
      "abs/2211.10838v2\n",
      "abs/2212.00461v1\n",
      "abs/2211.02030v2\n",
      "abs/2212.00454v1\n",
      "abs/2109.06537v4\n",
      "abs/2212.00441v1\n",
      "abs/2206.04631v2\n",
      "abs/2204.10336v2\n",
      "abs/2212.00411v1\n",
      "abs/2212.00409v1\n",
      "abs/2212.00400v1\n",
      "abs/2206.10519v3\n",
      "abs/2212.00376v1\n",
      "abs/2212.00370v1\n",
      "abs/2212.00366v1\n",
      "abs/2206.02302v2\n",
      "abs/2212.00358v1\n",
      "abs/2212.00327v1\n",
      "abs/2212.00324v1\n",
      "abs/2211.04957v3\n",
      "abs/2205.00030v2\n",
      "abs/2212.00248v1\n",
      "abs/2212.00245v1\n",
      "abs/1905.06491v6\n",
      "abs/2111.07656v2\n",
      "abs/2205.15433v2\n",
      "abs/2212.00185v1\n",
      "abs/2212.00183v1\n",
      "abs/2212.00179v1\n",
      "abs/2212.00153v1\n",
      "abs/2212.00152v1\n",
      "abs/2211.07740v2\n",
      "abs/2212.00130v1\n",
      "abs/2207.05766v2\n",
      "abs/2007.07975v3\n",
      "abs/2110.12156v3\n",
      "abs/2205.09771v3\n",
      "abs/2211.06789v2\n",
      "abs/2212.00080v1\n",
      "abs/2212.00038v1\n",
      "abs/2212.00032v1\n",
      "abs/2211.15619v2\n",
      "abs/2211.17243v1\n",
      "abs/2211.17233v1\n",
      "abs/2211.00630v2\n",
      "abs/2205.12004v2\n",
      "abs/2211.17153v1\n",
      "abs/2211.17141v1\n",
      "abs/2211.17120v1\n",
      "abs/2211.17114v1\n",
      "abs/2211.17088v1\n",
      "abs/2211.17082v1\n",
      "abs/2211.17069v1\n",
      "abs/2210.01118v2\n",
      "abs/2211.17045v1\n",
      "abs/2211.17035v1\n",
      "abs/2211.17026v1\n",
      "abs/2206.01596v2\n",
      "abs/2209.07995v2\n",
      "abs/2211.16924v1\n",
      "abs/2211.16916v1\n",
      "abs/2211.16888v1\n",
      "abs/2211.16880v1\n",
      "abs/2212.00019v1\n",
      "abs/2211.16857v1\n",
      "abs/2211.16836v1\n",
      "abs/2211.06629v2\n",
      "abs/1504.06963v4\n",
      "abs/2211.16814v1\n",
      "abs/2211.16810v1\n",
      "abs/2211.16805v1\n",
      "abs/2112.12628v2\n",
      "abs/2211.16795v1\n",
      "abs/2112.13671v2\n",
      "abs/2211.16785v1\n",
      "abs/2211.16774v1\n",
      "abs/2211.16767v1\n",
      "abs/2211.11408v2\n",
      "abs/2211.11302v2\n",
      "abs/2211.11301v2\n",
      "abs/2211.11299v2\n",
      "abs/2211.16679v1\n",
      "abs/2211.16659v1\n",
      "abs/2203.04514v3\n",
      "abs/2211.14408v2\n",
      "abs/2206.14881v2\n",
      "abs/2211.16591v1\n",
      "abs/2211.16586v1\n",
      "abs/2211.11767v2\n",
      "abs/2211.11969v2\n",
      "abs/2211.16537v1\n",
      "abs/2211.16530v1\n",
      "abs/2211.16528v1\n",
      "abs/2211.16521v1\n",
      "abs/2211.16524v1\n",
      "abs/2211.16493v1\n",
      "abs/2208.12391v2\n",
      "abs/2211.16481v1\n",
      "abs/2205.07715v3\n",
      "abs/2211.16464v1\n",
      "abs/2211.16461v1\n",
      "abs/2206.15084v3\n",
      "abs/2211.16456v1\n",
      "abs/2211.16443v1\n",
      "abs/2107.09806v3\n",
      "abs/2208.08573v3\n",
      "abs/2202.01305v2\n",
      "abs/2211.16409v1\n",
      "abs/2211.16399v1\n",
      "abs/2211.16388v1\n",
      "abs/2211.16383v1\n",
      "abs/2201.08518v2\n",
      "abs/2211.16378v1\n",
      "abs/2212.00583v1\n",
      "abs/2210.10674v2\n",
      "abs/2211.02941v3\n",
      "abs/2211.08973v4\n",
      "abs/2111.05213v2\n",
      "abs/2211.16317v1\n",
      "abs/2211.16295v1\n",
      "abs/2203.06710v2\n",
      "abs/2211.17095v1\n",
      "abs/2211.16267v1\n",
      "abs/2207.07716v3\n",
      "abs/2206.14293v2\n",
      "abs/2210.12342v2\n",
      "abs/2210.09322v2\n",
      "abs/2209.05992v2\n",
      "abs/2211.15246v2\n",
      "abs/2207.00544v2\n",
      "abs/2211.16091v1\n",
      "abs/2211.14897v2\n",
      "abs/2206.08527v3\n",
      "abs/2211.16054v1\n",
      "abs/2211.16020v1\n",
      "abs/1803.11074v4\n",
      "abs/2211.13334v2\n",
      "abs/2211.16009v1\n",
      "abs/2211.15999v1\n",
      "abs/2211.15981v1\n",
      "abs/2211.15970v1\n",
      "abs/2211.15964v1\n",
      "abs/2209.04119v3\n",
      "abs/2211.15908v1\n",
      "abs/2209.14292v3\n",
      "abs/2211.15860v1\n",
      "abs/2211.15857v1\n",
      "abs/2211.15855v1\n",
      "abs/2211.15854v1\n",
      "abs/2208.10343v4\n",
      "abs/2111.05400v2\n",
      "abs/2211.15835v1\n",
      "abs/2211.14147v2\n",
      "abs/2211.15816v1\n",
      "abs/2211.17209v1\n",
      "abs/2207.04795v2\n",
      "abs/2211.15791v1\n",
      "abs/2211.15787v1\n",
      "abs/2208.08517v3\n",
      "abs/2209.11948v2\n",
      "abs/2211.15769v1\n",
      "abs/2210.08510v3\n",
      "abs/2209.03105v2\n",
      "abs/2211.15747v1\n",
      "abs/2211.15746v1\n",
      "abs/2209.12907v2\n",
      "abs/2203.00287v2\n",
      "abs/2211.15710v1\n",
      "abs/2207.02862v2\n",
      "abs/2211.15698v1\n",
      "abs/2211.15693v1\n",
      "abs/2211.15687v1\n",
      "abs/2211.15653v1\n",
      "abs/2111.10477v2\n",
      "abs/2211.15624v1\n",
      "abs/1110.3649v3\n",
      "abs/2211.15654v1\n",
      "abs/2211.11177v1\n",
      "abs/2208.00277v3\n",
      "abs/2205.15838v4\n",
      "abs/2211.01600v1\n",
      "abs/2210.06965v2\n",
      "abs/2210.04628v1\n",
      "abs/2209.10684v1\n",
      "abs/2209.02417v1\n",
      "abs/1912.03207v5\n",
      "abs/2207.09978v1\n",
      "abs/2202.01999v3\n",
      "abs/2205.04334v1\n",
      "abs/2111.09996v2\n",
      "abs/2111.13152v3\n",
      "abs/2203.03570v1\n",
      "abs/2112.05124v1\n",
      "abs/2112.01983v2\n",
      "abs/2111.13260v3\n",
      "abs/2111.14643v1\n",
      "abs/2108.04869v2\n",
      "abs/2111.13112v1\n",
      "abs/2012.04718v2\n",
      "abs/2103.14167v2\n",
      "abs/2106.14274v2\n",
      "abs/2006.07982v2\n",
      "abs/2106.03804v1\n",
      "abs/2104.12229v1\n",
      "abs/2011.13920v2\n",
      "abs/1907.02545v5\n",
      "abs/2012.10518v1\n",
      "abs/1911.06971v6\n",
      "abs/1811.10725v5\n",
      "abs/2006.09930v2\n",
      "abs/2011.12490v1\n",
      "abs/2007.04883v2\n",
      "abs/2010.11339v1\n",
      "abs/2010.05066v1\n",
      "abs/2005.08877v1\n",
      "abs/1909.05736v4\n",
      "abs/2004.05980v1\n",
      "abs/1912.03629v1\n",
      "abs/1901.07124v3\n",
      "abs/1906.05260v1\n",
      "abs/1905.12162v1\n",
      "abs/1711.05944v4\n",
      "abs/1705.07175v2\n",
      "abs/1301.6809v2\n",
      "abs/2207.14660v1\n",
      "abs/2109.12925v6\n",
      "abs/2204.08870v1\n",
      "abs/2112.12027v1\n",
      "abs/2003.01587v5\n",
      "abs/1901.09780v2\n",
      "abs/2011.11986v2\n",
      "abs/2011.09832v1\n",
      "abs/2010.05365v1\n",
      "abs/1910.02190v2\n",
      "abs/1901.10915v2\n",
      "abs/1711.06704v4\n",
      "abs/1711.07064v4\n",
      "abs/1705.10872v4\n",
      "abs/1608.06800v1\n",
      "abs/1606.02228v2\n",
      "abs/1503.02619v2\n",
      "abs/1511.06422v7\n",
      "abs/1504.06603v2\n",
      "abs/1306.3855v2\n",
      "abs/2211.16421v1\n",
      "abs/2208.08988v1\n",
      "abs/2206.08355v3\n",
      "abs/2207.10660v1\n",
      "abs/2206.07028v1\n",
      "abs/2112.04481v2\n",
      "abs/2112.01530v2\n",
      "abs/2112.01520v1\n",
      "abs/2111.11431v1\n",
      "abs/2006.06666v3\n",
      "abs/2108.05892v1\n",
      "abs/2106.13933v1\n",
      "abs/2106.00677v1\n",
      "abs/2105.07576v1\n",
      "abs/2102.11870v1\n",
      "abs/2012.04630v1\n",
      "abs/2007.08501v1\n",
      "abs/1912.08804v2\n",
      "abs/1911.09655v1\n",
      "abs/1908.05656v1\n",
      "abs/1905.13214v1\n",
      "abs/1807.09937v1\n",
      "abs/1804.01622v1\n",
      "abs/1803.11361v1\n",
      "abs/1803.10892v1\n",
      "abs/1705.03633v1\n",
      "abs/1705.02092v1\n",
      "abs/1611.06607v2\n",
      "abs/1612.06890v1\n",
      "abs/1603.08155v1\n",
      "abs/1602.07332v1\n",
      "abs/1511.07571v1\n",
      "abs/1506.02078v2\n",
      "abs/1508.07647v2\n",
      "abs/2211.16373v1\n",
      "abs/2210.03094v1\n",
      "abs/2209.09217v1\n",
      "abs/2206.11894v2\n",
      "abs/2203.11931v1\n",
      "abs/2012.15412v2\n",
      "abs/2102.02202v1\n",
      "abs/1908.03195v2\n",
      "abs/2210.07277v1\n",
      "abs/2201.02605v3\n",
      "abs/2206.08356v1\n",
      "abs/2112.01527v3\n",
      "abs/2204.07141v1\n",
      "abs/2201.08377v2\n",
      "abs/2110.03336v4\n",
      "abs/2202.08360v2\n",
      "abs/2112.10764v1\n",
      "abs/2103.10211v2\n",
      "abs/2106.05392v2\n",
      "abs/2109.08141v1\n",
      "abs/2104.13963v3\n",
      "abs/2104.14294v2\n",
      "abs/2105.06461v1\n",
      "abs/2004.12943v3\n",
      "abs/2103.15916v1\n",
      "abs/2103.01988v2\n",
      "abs/2006.09882v5\n",
      "abs/2101.02691v1\n",
      "abs/2011.13046v1\n",
      "abs/2001.03615v2\n",
      "abs/1906.02729v3\n",
      "abs/1912.03330v1\n",
      "abs/1912.01991v1\n",
      "abs/1906.02659v2\n",
      "abs/1905.01235v2\n",
      "abs/1901.06595v2\n",
      "abs/1712.01238v1\n",
      "abs/1708.01642v1\n",
      "abs/1603.08561v2\n",
      "abs/1603.06059v3\n",
      "abs/1604.03968v1\n",
      "abs/1512.06974v2\n",
      "abs/1604.03539v1\n",
      "abs/1505.05769v1\n",
      "abs/1303.2171v1\n",
      "abs/2212.00771v1\n",
      "abs/2212.00667v1\n",
      "abs/2212.00399v1\n",
      "abs/2212.00280v1\n",
      "abs/2208.12527v2\n",
      "abs/2211.16930v1\n",
      "abs/2211.16632v1\n",
      "abs/2006.15578v4\n",
      "abs/2205.14320v2\n",
      "abs/2211.15158v1\n",
      "abs/2211.15133v1\n",
      "abs/2211.15045v1\n",
      "abs/2211.14929v1\n",
      "abs/2207.07933v2\n",
      "abs/2211.12322v2\n",
      "abs/2211.14235v1\n",
      "abs/2111.00794v2\n",
      "abs/2211.10705v2\n",
      "abs/2211.15371v1\n",
      "abs/2211.11801v1\n",
      "abs/2211.11514v1\n",
      "abs/2204.01244v2\n",
      "abs/2211.10681v1\n",
      "abs/2211.10593v1\n",
      "abs/2211.10581v1\n",
      "abs/2211.08657v2\n",
      "abs/2211.11749v1\n",
      "abs/2211.14443v1\n",
      "abs/2211.09352v1\n",
      "abs/2211.08887v1\n",
      "abs/2211.08783v1\n",
      "abs/2211.08217v1\n",
      "abs/2209.07042v2\n",
      "abs/2203.10977v3\n",
      "abs/2210.11169v2\n",
      "abs/2211.06641v1\n",
      "abs/2112.13060v2\n",
      "abs/2211.02006v1\n",
      "abs/2111.02163v2\n",
      "abs/2110.00620v2\n",
      "abs/2210.15444v2\n",
      "abs/2210.17398v1\n",
      "abs/2210.08210v2\n",
      "abs/2210.16834v1\n",
      "abs/2210.16742v1\n",
      "abs/2208.06882v2\n",
      "abs/2208.12079v2\n",
      "abs/2210.16467v1\n",
      "abs/2210.15808v1\n",
      "abs/2203.13068v2\n",
      "abs/2210.09900v2\n",
      "abs/2210.12578v1\n",
      "abs/2209.09341v2\n",
      "abs/2210.09615v1\n",
      "abs/2210.09198v1\n",
      "abs/2210.09045v1\n",
      "abs/2210.08350v1\n",
      "abs/2202.12104v3\n",
      "abs/2101.01611v2\n",
      "abs/2207.05736v2\n",
      "abs/2210.07279v1\n",
      "abs/2210.06223v1\n",
      "abs/2209.13507v2\n",
      "abs/2111.11546v3\n",
      "abs/2210.05076v1\n",
      "abs/2210.04506v1\n",
      "abs/2210.04428v1\n",
      "abs/2108.01335v2\n",
      "abs/2210.03779v1\n",
      "abs/2110.05044v3\n",
      "abs/2210.03417v1\n",
      "abs/2210.02493v1\n",
      "abs/2210.02401v1\n",
      "abs/2210.02391v1\n",
      "abs/2210.00911v1\n",
      "abs/2210.01125v1\n",
      "abs/2210.00674v1\n",
      "abs/2105.14173v3\n",
      "abs/2103.15145v4\n",
      "abs/2209.14819v1\n",
      "abs/2209.13959v1\n",
      "abs/2209.13808v1\n",
      "abs/2209.13761v1\n",
      "abs/2209.13233v1\n",
      "abs/2209.13113v1\n",
      "abs/2209.13090v1\n",
      "abs/2209.12770v1\n",
      "abs/2209.12476v1\n",
      "abs/2209.12254v1\n",
      "abs/2109.05676v2\n",
      "abs/2209.12160v1\n",
      "abs/2209.11475v1\n",
      "abs/2209.04145v4\n",
      "abs/2208.00571v2\n",
      "abs/2209.10071v1\n",
      "abs/2209.09844v1\n",
      "abs/2112.06482v4\n",
      "abs/2209.05996v2\n",
      "abs/2209.07989v1\n",
      "abs/2209.06421v1\n",
      "abs/2209.06399v1\n",
      "abs/1908.05006v2\n",
      "abs/2209.05299v1\n",
      "abs/2209.05261v1\n",
      "abs/2209.05167v1\n",
      "abs/2208.14484v2\n",
      "abs/2209.04077v1\n",
      "abs/2106.07929v5\n",
      "abs/2209.03494v1\n",
      "abs/2209.01763v1\n",
      "abs/2209.01517v1\n",
      "abs/2209.01339v1\n",
      "abs/2208.14871v1\n",
      "abs/2110.03674v2\n",
      "abs/2107.01063v2\n",
      "abs/2208.11499v2\n",
      "abs/2208.12908v1\n",
      "abs/2208.11905v1\n",
      "abs/2208.11876v1\n",
      "abs/2208.11868v1\n",
      "abs/2208.10830v1\n",
      "abs/2203.12612v5\n",
      "abs/2208.10808v1\n",
      "abs/2207.10242v2\n",
      "abs/2208.10358v1\n",
      "abs/2208.09849v1\n",
      "abs/2206.01160v2\n",
      "abs/2208.09394v1\n",
      "abs/2208.09003v1\n",
      "abs/2204.11511v2\n",
      "abs/2208.08295v1\n",
      "abs/2208.08292v1\n",
      "abs/2203.04050v3\n",
      "abs/2208.08007v1\n",
      "abs/1911.11534v4\n",
      "abs/2205.01643v2\n",
      "abs/2208.07496v1\n",
      "abs/2202.13124v3\n",
      "abs/2208.06049v2\n",
      "abs/2207.00319v2\n",
      "abs/2105.10087v2\n",
      "abs/2208.07022v1\n",
      "abs/2208.06818v1\n",
      "abs/2208.02642v2\n",
      "abs/2109.01123v2\n",
      "abs/2208.05114v1\n",
      "abs/2208.04318v1\n",
      "abs/2208.03550v1\n",
      "abs/2208.03440v1\n",
      "abs/2208.02311v1\n",
      "abs/2208.01753v1\n",
      "abs/2208.01667v1\n",
      "abs/2206.05737v2\n",
      "abs/2208.00704v1\n",
      "abs/2108.08618v2\n",
      "abs/2204.01186v2\n",
      "abs/2207.14242v1\n",
      "abs/2207.14172v1\n",
      "abs/2203.16875v2\n",
      "abs/2207.12988v1\n",
      "abs/2105.04143v2\n",
      "abs/2103.08862v2\n",
      "abs/2207.11467v1\n",
      "abs/2110.05240v2\n",
      "abs/2204.04627v2\n",
      "abs/2207.10589v1\n",
      "abs/2110.04079v5\n",
      "abs/2207.09291v1\n",
      "abs/2203.05625v3\n",
      "abs/2207.08677v1\n",
      "abs/2202.12613v3\n",
      "abs/2207.08427v1\n",
      "abs/2207.08412v1\n",
      "abs/2207.08210v1\n",
      "abs/2207.08119v1\n",
      "abs/2205.14354v3\n",
      "abs/2205.01931v2\n",
      "abs/2207.07370v1\n",
      "abs/2107.14178v2\n",
      "abs/2207.06421v1\n",
      "abs/2107.13802v5\n",
      "abs/2203.07756v2\n",
      "abs/2207.05749v1\n",
      "abs/2207.04132v1\n",
      "abs/2207.03917v1\n",
      "abs/2206.11501v3\n",
      "abs/2204.03842v2\n",
      "abs/2112.06596v4\n"
     ]
    }
   ],
   "source": [
    "for unq_id in unq_paper_id:\n",
    "    id_paper = unq_id.replace(\"abs/\", \"\")\n",
    "    query_arxiv_abstract = f\"http://export.arxiv.org/api/query?id_list={id_paper}\"\n",
    "    out_id = requests.get(query_arxiv_abstract)\n",
    "    tree = ET.ElementTree(ET.fromstring(out_id.text))\n",
    "    tree_root = tree.getroot()\n",
    "    paper = tree_root.findall('n:entry',namespaces=ns)[0]\n",
    "    paper_summary = paper.find('n:summary',namespaces=ns).text\n",
    "    summary = paper_summary.replace(\"\\n\",\"\").lstrip().rstrip()\n",
    "    df[\"summary\"][df[\"paper_arxiv_id\"] == unq_id] = summary\n",
    "    print(unq_id)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"../data/arxiv_paper_ids.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parsel import Selector\n",
    "import os, json, requests, re\n",
    "from fp.fp import FreeProxy\n",
    "import time \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../data/arxiv_paper_ids.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = df.authors.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem_sch_author_cols = [\"authorId\", \"name\",\"aliases\", \"homepage\",\"paperCount\",\"citationCount\",\"hIndex\"]\n",
    "sem_sch_paper_cols = ['authorId', 'name', 'paperId', 'url', 'title', 'abstract', 'year',\n",
    "       'referenceCount', 'citationCount', 'influentialCitationCount',\n",
    "       'isOpenAccess']\n",
    "sem_scholdar_api_reqs = [\"paperId\",\"url\",\"title\",\"abstract\", \"year\", \"referenceCount\",\n",
    "                            \"citationCount\",\"influentialCitationCount\",\n",
    "                            \"isOpenAccess\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_author_link(author_name):\n",
    "    authors_req = \"name,aliases,homepage,paperCount,citationCount,hIndex\"\n",
    "    author_query = \"+\".join(author_name.lower().split(\" \"))\n",
    "    url = f\"https://api.semanticscholar.org/graph/v1/author/search?query={author_query}&fields={authors_req}\"\n",
    "    return url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers={\"Content-Type\":\"text\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# results_authors = requests.get(create_author_link(\"Kaiming He\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sem_sch_authors = pd.DataFrame(columns=sem_sch_author_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "proxy = FreeProxy(rand=True, elite=True).get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "find authors:   3%|▎         | 149/5642 [43:50<26:56:31, 17.66s/it]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [39], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m _df_sem_sch_authors \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(columns\u001b[39m=\u001b[39msem_sch_author_cols)\n\u001b[1;32m     13\u001b[0m _df_sem_scholar_papers \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(columns\u001b[39m=\u001b[39msem_sch_paper_cols)\n\u001b[0;32m---> 16\u001b[0m \u001b[39mfor\u001b[39;00m author_data \u001b[39min\u001b[39;00m results[\u001b[39m\"\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m\"\u001b[39;49m]:\n\u001b[1;32m     17\u001b[0m     author_df \u001b[39m=\u001b[39m {k:v \u001b[39mfor\u001b[39;00m k,v \u001b[39min\u001b[39;00m author_data\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39min\u001b[39;00m sem_sch_author_cols}\n\u001b[1;32m     19\u001b[0m     \u001b[39mif\u001b[39;00m author_df[\u001b[39m\"\u001b[39m\u001b[39maliases\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'data'"
     ]
    }
   ],
   "source": [
    "for i in tqdm(list(range(3021, len(authors))), desc=\"find authors\"):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3538.102 Safari/537.36 Edge/18.19582',\n",
    "    }\n",
    "\n",
    "    if i%100 ==0:\n",
    "        proxy = FreeProxy(rand=True, elite=True).get()\n",
    "\n",
    "    results_authors = requests.get(create_author_link(authors[i]), headers=headers, proxies={\"http\": proxy})\n",
    "    results = results_authors.json()\n",
    "\n",
    "    _df_sem_sch_authors = pd.DataFrame(columns=sem_sch_author_cols)\n",
    "    _df_sem_scholar_papers = pd.DataFrame(columns=sem_sch_paper_cols)\n",
    "\n",
    "\n",
    "    for author_data in results[\"data\"]:\n",
    "        author_df = {k:v for k,v in author_data.items() if k in sem_sch_author_cols}\n",
    "        \n",
    "        if author_df[\"aliases\"] is None:\n",
    "            author_df[\"aliases\"] = [author_df[\"name\"]]\n",
    "        author_df = pd.DataFrame.from_dict(author_df)\n",
    "        _df_sem_sch_authors = pd.concat([author_df, _df_sem_sch_authors])\n",
    "        paper_auth = pd.DataFrame(columns=sem_sch_paper_cols)\n",
    "\n",
    "    df_sem_sch_authors = pd.concat([df_sem_sch_authors, _df_sem_sch_authors])\n",
    "    df_sem_sch_authors.to_pickle(\"../data/sem_sch_authorsv2.pickle\")\n",
    "\n",
    "    time.sleep(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Internal Server Error'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.333333333333336"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(5*60)/9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Too Many Requests'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = requests.get(create_author_link(authors[i]), headers=headers, proxies={\"http\": proxy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total': 1,\n",
       " 'offset': 0,\n",
       " 'data': [{'authorId': '3142556',\n",
       "   'name': 'P. Sermanet',\n",
       "   'aliases': ['P. Sermanet', 'Pierre Sermanet'],\n",
       "   'homepage': None,\n",
       "   'paperCount': 53,\n",
       "   'citationCount': 42339,\n",
       "   'hIndex': 27}]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rr.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_authors = requests.get(create_author_link(authors[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://api.semanticscholar.org/graph/v1/author/search?query=yanghao+li&fields=name,aliases,homepage,paperCount,citationCount,hIndex'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_author_link(authors[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Too Many Requests'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_authors.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'paper_req' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m paper_req\n",
      "\u001b[0;31mNameError\u001b[0m: name 'paper_req' is not defined"
     ]
    }
   ],
   "source": [
    "paper_req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_req = \"fields=url,title,abstract,year,referenceCount,citationCount,influentialCitationCount,isOpenAccess,fieldsOfStudy,citations,references&limit=800\"\n",
    "result_papers = requests.get(f\"https://api.semanticscholar.org/graph/v1/author/2058350112/papers?{paper_req}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "r=requests.get(\"http://www.example.com/\", headers={\"Content-Type\":\"text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sem_sch_authors = pd.read_pickle(\"../data/sem_sch_authors.pickle\")\n",
    "df_sem_scholar_papers = pd.DataFrame(columns=sem_sch_paper_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from data.twitter_key import SemanticScholarCreds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEMSCH_LINK = \"https://api.semanticscholar.org/graph/v1\"\n",
    "semsch_paperid = \"3230e2d6b4671cc03974af2219c6d3270e6fac70\"\n",
    "author_fields = \"authors.name,authors.hIndex,authors.paperCount,authors.citationCount\"\n",
    "citations_fields = \"citations.title,citations.influentialCitationCount\"\n",
    "req_fields = f\"url,title,{author_fields},abstract,year,referenceCount,citationCount,influentialCitationCount,isOpenAccess,fieldsOfStudy,{citations_fields},references&limit=50\"\n",
    "url_paper = f\"{SEMSCH_LINK}/paper/{semsch_paperid}?fields={req_fields}\"\n",
    "_results = requests.get(url_paper, headers={\"x-api-key\":SemanticScholarCreds.API_KEY })\n",
    "results = _results.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'paperId': '3230e2d6b4671cc03974af2219c6d3270e6fac70',\n",
       " 'url': 'https://www.semanticscholar.org/paper/3230e2d6b4671cc03974af2219c6d3270e6fac70',\n",
       " 'title': 'RAFT: Recurrent All-Pairs Field Transforms for Optical Flow',\n",
       " 'abstract': None,\n",
       " 'year': 2020,\n",
       " 'referenceCount': 57,\n",
       " 'citationCount': 663,\n",
       " 'influentialCitationCount': 187,\n",
       " 'isOpenAccess': True,\n",
       " 'fieldsOfStudy': ['Materials Science', 'Computer Science'],\n",
       " 'authors': [{'authorId': '8048414',\n",
       "   'name': 'Zachary Teed',\n",
       "   'paperCount': 13,\n",
       "   'citationCount': 937,\n",
       "   'hIndex': 8},\n",
       "  {'authorId': '153302678',\n",
       "   'name': 'Jia Deng',\n",
       "   'paperCount': 93,\n",
       "   'citationCount': 83360,\n",
       "   'hIndex': 47}],\n",
       " 'citations': [{'paperId': 'd8ec2218fb6dd8b13607623bef2e23342485716a',\n",
       "   'title': 'Survey on Digital Video Stabilization: Concepts, Methods, and Challenges',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': 'f138fbe7dba46507b350180b1c2fc601bc06562f',\n",
       "   'title': 'EditableNeRF: Editing Topologically Varying Neural Radiance Fields by Key Points',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'a9956ab1e416dd73286c33a10ddabb05fa8a64a6',\n",
       "   'title': 'Self-supervised AutoFlow',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '551671d3503bbc34659fc57b8e2d598d9cf02918',\n",
       "   'title': 'Optical Flow in the Dark',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'a243cee08b47cbc8deaaca2d304ecd05d0fe1246',\n",
       "   'title': 'Scale Invariant Low Frame Rate Tracking',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '0ddb75bb3def72dfdacbe8c9ba1e0e15d7f068d6',\n",
       "   'title': 'I2D-Loc: Camera localization via image to LiDAR depth flow',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'f1b14b7ed6601b4e1fd847a3043e749ca0bf02aa',\n",
       "   'title': 'Rethinking Disparity: A Depth Range Free Multi-View Stereo Based on Disparity',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '021c6395cfaa05670ea282f8d4aa430150a4fe33',\n",
       "   'title': 'Sprite-from-Sprite',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '0fa395c61bbdb08ee13bc3d5d262ae238d6f062d',\n",
       "   'title': 'Rapid Face Asset Acquisition with Recurrent Feature Alignment',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'cad29d0de9ab7f88089fe745d604e04320cd24f3',\n",
       "   'title': 'FloRen: Real-time High-quality Human Performance Rendering via Appearance Flow Using Sparse RGB Cameras',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '1e0cf0e78bc145c0096b19b80ec2603c9cf03247',\n",
       "   'title': 'Procedural Image Programs for Representation Learning',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'e7c200e184442d212cb2f492524eadb4556601c5',\n",
       "   'title': 'FBMOT: Flow Bridges the Gap between Detection and Tracking in Multiple Object Tracking',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'a2a04c7a4f57c19940d7726c2613ca4528c6a8ed',\n",
       "   'title': 'WALDO: Future Video Synthesis using Object Layer Decomposition and Parametric Flow Prediction',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '439e78b3b11aff3d25879e6183383999f1cf4c59',\n",
       "   'title': 'Efficient 3D Reconstruction, Streaming and Visualization of Static and Dynamic Scene Parts for Multi-client Live-telepresence in Large-scale Environments',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '6bbd1446f45d1ceda130821d4e178fc415a93bb6',\n",
       "   'title': 'Efficient Feature Extraction for High-resolution Video Frame Interpolation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '4b71b1455d1abbde4ca2cc8055b6833b92871fe4',\n",
       "   'title': 'Lightweight Event-based Optical Flow Estimation via Iterative Deblurring',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '0fb7c50aa914422c7b002c8efade9f84fd8f988d',\n",
       "   'title': 'TemporalStereo: Efficient Spatial-Temporal Stereo Matching Network',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'c201542be1a875302a14328a7c9b5207facde51f',\n",
       "   'title': 'Learning to Imitate Object Interactions from Internet Videos',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '2d03f2a8b5a91202c425efe84cf217a38b007519',\n",
       "   'title': 'Data-driven Feature Tracking for Event Cameras',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '1bc63d155498af7c07eae8d2a06f58246e15cf06',\n",
       "   'title': 'Video Instance Shadow Detection',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'd922fd75ccf540c81148cf949d86fd70d17107d3',\n",
       "   'title': 'Domain Alignment and Temporal Aggregation for Unsupervised Video Object Segmentation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '6c2d8d1963e47488e81ac4164f240cad7edf06d7',\n",
       "   'title': 'The Monocular Depth Estimation Challenge',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '12392f3a4b7c70114c721011d5c78caf27102dc4',\n",
       "   'title': 'Blur Interpolation Transformer for Real-World Motion from Blur',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '1dc1ec86dedd525ab4c47a645bc9ecc350ea1369',\n",
       "   'title': 'H-VFI: Hierarchical Frame Interpolation for Videos with Large Motions',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'deae9bff430734803684af3b0b481e0f821f21ad',\n",
       "   'title': 'DynIBaR: Neural Dynamic Image-Based Rendering',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '4367736e4552ef98da98b967e678376377e3e3c3',\n",
       "   'title': 'Improved Cross-view Completion Pre-training for Stereo Matching',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '0e4bcfa22adeb54759a9794fc745f750fe92defa',\n",
       "   'title': 'AligNeRF: High-Fidelity Neural Radiance Fields via Alignment-Aware Training',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'b60acde4e913df777cb2f73ba85e964f13c491d0',\n",
       "   'title': 'Learning Dense and Continuous Optical Flow From an Event Camera',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '0d82953cf2c406a3dc620a5d0487a9cc8b5538c1',\n",
       "   'title': 'Machine learning for flow field measurements: a perspective',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '2423b4c82df02d1983c38a7e8ced016ed6a7959d',\n",
       "   'title': 'VGFlow: Visibility guided Flow Network for Human Reposing',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'c6c74e211284f464cdbab63b7c848a5e80bb8141',\n",
       "   'title': 'MDFlow: Unsupervised Optical Flow Learning by Reliable Mutual Knowledge Distillation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '1408d0ab2076fbe12303c4326bf16e01eb41df8f',\n",
       "   'title': 'Unifying Flow, Stereo and Depth Estimation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '80e1a0d0175add21335d5780f3682f3a93ca73bc',\n",
       "   'title': 'AnimeRun: 2D Animation Visual Correspondence from Open Source 3D Movies',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '0ffa5839cf05b5d0c211672c718898f19a39e383',\n",
       "   'title': 'Common Pets in 3D: Dynamic New-View Synthesis of Real-Life Deformable Categories',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '62c97003229f1820834b69813d301068b4275475',\n",
       "   'title': 'TAP-Vid: A Benchmark for Tracking Any Point in a Video',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '510d47017ef5ca1542e3a7da9424baa5e48f59d3',\n",
       "   'title': 'A Unified Pyramid Recurrent Network for Video Frame Interpolation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '3b8f16365156df18377c872b2d2ee72637d3c543',\n",
       "   'title': 'Contact-Free Simultaneous Sensing of Human Heart Rate and Canine Breathing Rate for Animal Assisted Interactions',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'dfc3bc5362c2746292ffef1a8af522c16bbf7da0',\n",
       "   'title': 'SizeGAN: Improving Size Representation in Clothing Catalogs',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '10afac32f90faf66227788e80c62ca9a10213d19',\n",
       "   'title': 'CASA: Category-agnostic Skeletal Animal Reconstruction',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'ca0060ae78cf981323898382356b845fba9a5133',\n",
       "   'title': 'FactorMatte: Redefining Video Matting for Re-Composition Tasks',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '28bfc904cabfd4b78d9e4f95e5b2b6fd31c3bacb',\n",
       "   'title': 'Temporal Consistency Learning of inter-frames for Video Super-Resolution',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'cdc3aa9a1211f6b7e6ca9a434369959820a772ca',\n",
       "   'title': 'Benchmarking equivariance for Deep Learning based optical flow estimators',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '4d3985396931d007b32152c784026c77877fcc1f',\n",
       "   'title': 'Robust visual odometry using sparse optical flow network',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'ddf0d5227fca5af4959d54d9235901edcd7e0da2',\n",
       "   'title': 'GotFlow3D: Recurrent Graph Optimal Transport for Learning 3D Flow Motion in Particle Tracking',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '0103f81e3fee69cbb46ef1f224d9d4e30154d1f0',\n",
       "   'title': 'High Resolution Multi-Scale RAFT (Robust Vision Challenge 2022)',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'e5ece410e3f8f8249170cb34bee90ec1fd234740',\n",
       "   'title': 'Phát hiện bất thường: dự đoán khung hình tương lai kết hợp sota optical-flow model và cải tiến hàm lỗi dựa trên FenceGan',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '8a332f891d825c2757a667959d1f8c9c6a0565e9',\n",
       "   'title': 'Learning Audio-Visual Dynamics Using Scene Graphs for Audio Source Separation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'c1e2828eccddec17aef9e9ed80020fcb0859b05d',\n",
       "   'title': 'Exploring Spatial-Temporal Features for Deepfake Detection and Localization',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '06a45d931caf12fc75208768640e22e796f8100d',\n",
       "   'title': 'Bootstrapping Human Optical Flow and Pose',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '4f7770079d5538a1f18a7cb251d3cb88b089ab3e',\n",
       "   'title': 'State of the Art in Dense Monocular Non-Rigid 3D Reconstruction',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '7cd49e43adbb6a4bdf3b56094da8b3f274c9cf69',\n",
       "   'title': 'CLIP-FLow: Contrastive Learning by {s}emi-supervised Iterative Pseudo {l}abeling for Optical Flow Estimation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '4fa8e23738b75a2594cea2c04b79e979a873c73d',\n",
       "   'title': 'Multi-task Video Enhancement for Dental Interventions',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '1fbe23a0d6e45b0bd7861ea33b7e51c27b1a8ef4',\n",
       "   'title': 'NeRF-SLAM: Real-Time Dense Monocular SLAM with Neural Radiance Fields',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '09179234dec5fc6dea4a8b02a9d98eef712d45e9',\n",
       "   'title': 'Monocular Dynamic View Synthesis: A Reality Check',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '3480639dd6d4609ed706f30d1a62dae555a70aab',\n",
       "   'title': 'An Improved RaftStereo Trained with A Mixed Dataset for the Robust Vision Challenge 2022',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'a058da4e3b06e201bab4d91992e7ef326fcc787f',\n",
       "   'title': 'SC-wLS: Towards Interpretable Feed-forward Camera Re-localization',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'ec7bc3f54074bb73109b8e2348c1b4d822e7ee72',\n",
       "   'title': 'Unsupervised Multi-object Segmentation by Predicting Probable Motion Patterns',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '66b9c82b5904f40f6e7087c886cfd9013fc9802d',\n",
       "   'title': 'Visual odometry based on camera motion and bidirectional long short-term memory network',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '62c4022e36e76833df0a5e3dfc846ea7387ebf4d',\n",
       "   'title': 'Survey on unsupervised learning methods for optical flow estimation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'f150d3b793e1284f8fcb19b86d480eefe9e39b7e',\n",
       "   'title': 'Comparison of optical flow image preprocessing options for state of the art deep learning models',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '9e5b4a5a8aaaac56272d6035621ffae6ea1526f6',\n",
       "   'title': 'CroCo: Self-Supervised Pre-training for 3D Vision Tasks by Cross-View Completion',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '019e77cb0fc4e180d189a000bf0c1ee75a194262',\n",
       "   'title': 'End-to-End Entity Detection with Proposer and Regressor',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '000afaecb29db80539b66c769b5ddb0f8234aa7f',\n",
       "   'title': 'Deep learning for complex displacement field measurement',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '02cc23cd5b6ea6dd8962cc11e95e07f2868d8efc',\n",
       "   'title': 'Hierarchical Normalization for Robust Monocular Depth Estimation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'e78b94214da8a21ada19bd3affd2646f83054466',\n",
       "   'title': 'Facial optical flow estimation via neural non-rigid registration',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '1c0d06f669e52d8826fb15b4705745d4103e0856',\n",
       "   'title': 'Urban road users detection and velocity estimation from top-view fish-eye imagery under low light conditions',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '6afb9024f4f7efb2e7c5817d87cfb8267e2c758c',\n",
       "   'title': 'Geometric Representation Learning for Document Image Rectification',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '4b45bc50e862c032c0812e08ff5483a8cf15d0fb',\n",
       "   'title': 'Self-Supervised 2D/3D Registration for X-Ray to CT Image Fusion',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '0293fc7dd66cd7d16085406f7de48c98bbc1b842',\n",
       "   'title': 'ARO-DeepSFM: deep structure-from-motion with alternating recursive optimization',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '15ccb12d59618f27bbed391ba649d3d4ea4231a2',\n",
       "   'title': 'Match Cutting: Finding Cuts with Smooth Visual Transitions',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '35c51f24113ae4b36ba13e5c44ebbbb51f814fca',\n",
       "   'title': 'It Takes Two: Masked Appearance-Motion Modeling for Self-supervised Video Transformer Pre-training',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '7a6352c3f85f31153d39c1af9d37d0092b5e2595',\n",
       "   'title': 'DeepMLE: A Robust Deep Maximum Likelihood Estimator for Two-view Structure from Motion',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'bacda4e7667873453e0fb2321de144ecbe787553',\n",
       "   'title': 'Weakly-Supervised Optical Flow Estimation for Time-of-Flight',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'd8a1d90e502a4bc756952565d3c73645a8e6aee6',\n",
       "   'title': 'Scale-flow: Estimating 3D Motion from Video',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'f16312db06b53e386df47bf4a98cf913489feec6',\n",
       "   'title': 'Generation of realistic simulated B-mode image texture with a GAN',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '6d4508cb9acc2971326349fb6165f36387473ec0',\n",
       "   'title': 'Progressive Limb-Aware Virtual Try-On',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '68435a2584277adaea0d07e4a985a04af27f7af0',\n",
       "   'title': 'RPPformer-Flow: Relative Position Guided Point Transformer for Scene Flow Estimation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '21d416a64a8c2fb9068ce9456312d38fb553cf9b',\n",
       "   'title': 'UConNet: Unsupervised Controllable Network for Image and Video Deraining',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '2684db17428d441bb47ec5983cd85991da679422',\n",
       "   'title': 'OISSR: Optical Image Stabilization Based Super Resolution on Smartphone Cameras',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '9a7b36742b34d54879f12da981810539166db189',\n",
       "   'title': 'E-HANet:Event-based Hybrid Attention Network for Optical Flow Estimation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'a6e49798d1c598f0cfaa7b21d3bd4202bf8ba98c',\n",
       "   'title': 'Monocular Fisheye Depth Estimation for Automated Valet Parking: Dataset, Baseline and Deep Optimizers',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '9f185e3add321541359c0d5edbb4b8428d572b76',\n",
       "   'title': 'Visual Looming from Motion Field and Surface Normals',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '813a84629330d42c6bc93d659ec218193f6a8ce3',\n",
       "   'title': 'IronDepth: Iterative Refinement of Single-View Depth using Surface Normal and its Uncertainty',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '055fe58ea72df3fa296f2f0f3ad3abacafb84204',\n",
       "   'title': 'GMA3D: Local-Global Attention Learning to Estimate Occluded Motions of Scene Flow',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'bd5cbd5464891858ae67df27018ab636e5fdf1bd',\n",
       "   'title': 'Rolling Shutter Inversion: Bring Rolling Shutter Images to High Framerate Global Shutter Video',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'f0b43d6b734d5e42c766076a6489b6122ee0d3b8',\n",
       "   'title': 'FloatingFusion: Depth from ToF and Image-stabilized Stereo Cameras',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '00f08c81cf7a969766cc2956f037f8a6a781950f',\n",
       "   'title': 'Vision+X: A Survey on Multimodal Learning in the Light of Data',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'af68411daefc7d428c518c46bde3ffa47a3135db',\n",
       "   'title': 'Inharmonious Region Localization via Recurrent Self-Reasoning',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '598a117ed291a04b31a57091240c75d027cd6268',\n",
       "   'title': 'MBW: Multi-view Bootstrapping in the Wild',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '16f5b9a699cfd6d272c57aa987cac2d466dd9d72',\n",
       "   'title': 'Probabilistic Volumetric Fusion for Dense Monocular SLAM',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '2e9ff22cc1109cd251c6b8e2ff1c809df16ff9d8',\n",
       "   'title': 'WorldGen: A Large Scale Generative Simulator',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'b9129ae658a8bb833c11ff1646a895643397df62',\n",
       "   'title': 'Motion-inductive Self-supervised Object Discovery in Videos',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'e4d6d3b50207dffbc16e1ecf14d7bcb99cbdec80',\n",
       "   'title': 'Effective Multi-Object Tracking via Global Object Models and Object Constraint Learning',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '930580f50f3feeb9a9f1eebf40a95c9702d15b14',\n",
       "   'title': 'Sparse Optical Flow Implementation Using a Neural Network for Low-Resolution Thermal Aerial Imaging',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'f28b39494b8d4c3d642ad03256b80e9fd545bfef',\n",
       "   'title': 'Alignment-guided Temporal Attention for Video Action Recognition',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'f2e60a839fbf8d68c0ebf5eb0f57743c58d6529d',\n",
       "   'title': 'RADACS: Towards Higher-Order Reasoning using Action Recognition in Autonomous Vehicles',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'a750ab08128838939e492060aa43a957ef2cf2ea',\n",
       "   'title': 'Frame Interpolation for Dynamic Scenes with Implicit Flow Encoding',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '1227f5c4ed0753929d93c97d3c64f61836d22bbf',\n",
       "   'title': 'Deep Video Super-Resolution with Flow-Guided Deformable Alignment and Sparsity-based Temporal-Spatial Enhancement',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'bb5bad2daf43870eab31b6ecad143584ec3ff85d',\n",
       "   'title': 'Gradient Consistency Based Multi-Scale Optical Flow',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'b4b8d6ecc10241467caf446e1109bb490699bab1',\n",
       "   'title': 'ECO-TR: Efficient Correspondences Finding Via Coarse-to-Fine Refinement',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': '60c80dd0da732176945f5560cec3c1e0964b3969',\n",
       "   'title': 'Hybrid Warping Fusion for Video Frame Interpolation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '866e09b1b9fcca7371346fd225479485a2bae20b',\n",
       "   'title': 'VToonify: Controllable High-Resolution Portrait Video Style Transfer',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'ad09485866a8c79fd3730a489c65c159b82949b8',\n",
       "   'title': 'An Unsupervised Video Stabilization Algorithm Based on Key Point Detection',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '4667e5424b8286fe714458652d6cc58dae8183e6',\n",
       "   'title': 'Sample, Crop, Track: Self-Supervised Mobile 3D Object Detection for Urban Driving LiDAR',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'af0dde927d26a4859f0db6ff73a2957bf7c3ca56',\n",
       "   'title': 'wildNeRF: Complete view synthesis of in-the-wild dynamic scenes captured using sparse monocular data',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'b5c8fece45dd1563551edfa6bf56e1e756fb7d10',\n",
       "   'title': 'A Simple and Powerful Global Optimization for Unsupervised Video Object Segmentation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '6e4ead322dc77453ec6e0d8128aabf12460eda7d',\n",
       "   'title': 'N E RF-SOS: A NY -V IEW S ELF - SUPERVISED O BJECT S EGMENTATION FROM C OMPLEX R EAL -W ORLD S CENES',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '75d08c91c7d41a5f1cd0a81a149d2cab197e0127',\n",
       "   'title': 'NeRF-SOS: Any-View Self-supervised Object Segmentation on Complex Scenes',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '3000fd428cab62784e4370060ccb3fc1b6f48372',\n",
       "   'title': 'NeuralMarker: A Framework for Learning General Marker Correspondence',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '7d36d1dc10654ff340e78dfc351b5b58ca296d2b',\n",
       "   'title': 'SF2SE3: Clustering Scene Flow into SE(3)-Motions via Proposal and Selection',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '9f8563f4c8ba4e3f5db156fcb5d8b88fdac6c388',\n",
       "   'title': 'TwistSLAM++: Fusing multiple modalities for accurate dynamic semantic SLAM',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '8043f099794637b9a3620ab0f0fef5a6ad1003d8',\n",
       "   'title': 'An Attention-guided Multistream Feature Fusion Network for Localization of Risky Objects in Driving Videos',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '1b1d066e2778435e3ae1cdcb07ab2b5aac75b240',\n",
       "   'title': 'Spatial-then-Temporal Self-Supervised Learning for Video Correspondence',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'c32354794fed70a8d93c0c5417b36e0b7b1582d7',\n",
       "   'title': 'PIZZA: A Powerful Image-only Zero-Shot Zero-CAD Approach to 6 DoF Tracking',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'ac2b771281a4965815143b348777a3e3fd3919b0',\n",
       "   'title': 'A Benchmark and a Baseline for Robust Multi-view Depth Estimation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'ffe1ca8a25f2061d1a605c94a8bfe716d627f13a',\n",
       "   'title': 'Unsupervised Learning of 3D Scene Flow with 3D Odometry Assistance',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '5437f983d652766a950ffcde61cfbeb413e379cd',\n",
       "   'title': 'Unsupervised Video Object Segmentation via Prototype Memory Network',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': '076fe5f45006ec53de21f56abb866eead08c8588',\n",
       "   'title': 'An Empirical Study of End-to-End Video-Language Transformers with Masked Visual Modeling',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': '887687c9c30c8bdb89c7094aca4228e43054eda4',\n",
       "   'title': 'Treating Motion as Option to Reduce Motion Dependency in Unsupervised Video Object Segmentation',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': '00fbca26b4fdb0a866f1831524d366fd4020b7c7',\n",
       "   'title': 'Overview of deep learning application on visual SLAM',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'ba2c14ce1266861d5c92b2705c53821b034c4ce7',\n",
       "   'title': 'TokenCut: Segmenting Objects in Images and Videos with Self-supervised Transformer and Normalized Cut',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '0fe2b40eca5675bd25e01dda24bb11a3448cbec6',\n",
       "   'title': 'Modeling Driver’s Visual Fixation Behavior Using White-Box Representations',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'ff59e36f93640ac722ff81e3be92273df6ca7ef2',\n",
       "   'title': 'ASpanFormer: Detector-Free Image Matching with Adaptive Span Transformer',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': '027626d146ceb02efe34126f78f3b94436a5371e',\n",
       "   'title': 'Self-supervised learning for automated anatomical tracking in medical image data with minimal human labeling effort',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'e4a52268c011c9507a3b49b696044f36b0fc7a9e',\n",
       "   'title': 'A Compacted Structure for Cross-domain learning on Monocular Depth and Flow Estimation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '085e80e5a6ae495dcc9bcdcbb4c56e66f4b728a4',\n",
       "   'title': 'NoiseFlow: Learning Optical Flow from Low SNR Cryo-EM Movie',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '588042275a2e338df56ace42453c727137da36fc',\n",
       "   'title': 'Crafting Monocular Cues and Velocity Guidance for Self-Supervised Multi-Frame Depth Learning',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '6b9d058fe3e3b93cb56655197d56a80488779f86',\n",
       "   'title': 'LoRD: Local 4D Implicit Representation for High-Fidelity Dynamic Human Modeling',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '0896e33cbd4b46c259613bfafa86c4ef78f8b591',\n",
       "   'title': 'Dense Feature Tracking of Atmospheric Winds with Deep Optical Flow',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '2a755c2b01cf2f3b8a91e1ce98facaf11f90bc92',\n",
       "   'title': 'Flow-Guided Transformer for Video Inpainting',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '603840e755a7e36cd900e0c028439819bb79c9a1',\n",
       "   'title': 'Motion Sensitive Contrastive Learning for Self-supervised Video Representation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '4bd8f9f7daec78d7a86ff8a4d1326fd347b963be',\n",
       "   'title': 'Language-Guided Face Animation by Recurrent StyleGAN-based Generator',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'd49c621cb7981ce6c01d6cf288322db9ee34dc97',\n",
       "   'title': 'Deep Patch Visual Odometry',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '1b37046a5be6cf3374a871cdb2f9d28f98de9994',\n",
       "   'title': 'Depth Quality-Inspired Feature Manipulation for Efficient RGB-D and Video Salient Object Detection',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '86ed353d5709f22a87d0139bd705b39bf9f861dd',\n",
       "   'title': 'Learning Omnidirectional Flow in 360-degree Video via Siamese Representation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '10c3566550735f503127f945a87de0d6eccc5503',\n",
       "   'title': 'Leveraging the HW/SW Optimizations and Ecosystems that Drive the AI Revolution',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '3e8eb241d5c8e4ee9f599919db4b730e71691e63',\n",
       "   'title': 'Globally Consistent Video Depth and Pose Estimation with Efficient Test-Time Training',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '32cbfbb1b2748d7c1df6accf65fa0f4b69656292',\n",
       "   'title': 'Multi-scale Sampling and Aggregation Network For High Dynamic Range Imaging',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'cf3facec793d3448e68aaeff5b8126c33099228b',\n",
       "   'title': 'Unsupervised Flow Refinement near Motion Boundaries',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '38e2a00bbafac8e33f21e53c1bef219b943838b8',\n",
       "   'title': 'Disparity-Guided Light Field Video Synthesis with Temporal Consistency',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'a7b3478a3f6225f9f3d1fbaa9869d2c93e74d608',\n",
       "   'title': 'BATMAN: Bilateral Attention Transformer in Motion-Appearance Neighboring Space for Video Object Segmentation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '3043653a81d6c30c6d6b89515eb9eb4b5524ba85',\n",
       "   'title': 'Less is More: Consistent Video Depth Estimation with Masked Frames Modeling',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '7a676b09bebcddc7bdff679556d95a3a345dd98f',\n",
       "   'title': 'AlphaVC: High-Performance and Efficient Learned Video Compression',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '8ae8b55780e45517d1dc5f90747a86cd4ac187ba',\n",
       "   'title': 'Depth Field Networks for Generalizable Multi-view Scene Representation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '1e07fd925ba51d47a194b347e77b13a7db4d5c31',\n",
       "   'title': 'Efficient Video Deblurring Guided by Motion Magnitude',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'f92abdc0ce58cd0db145c8646f542c664982d92e',\n",
       "   'title': 'Deep 360$^\\\\circ $ Optical Flow Estimation Based on Multi-projection Fusion',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'c6cdcba1a5db363f02f29c02143aee6b4538ffe2',\n",
       "   'title': 'GPS-GLASS: Learning Nighttime Semantic Segmentation Using Daytime Video and GPS data',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '04cb0ee4e680463c9909e892a447bb257e722c2b',\n",
       "   'title': 'Pseudo-3D Scene Modeling for Virtual Reality Using Stylized Novel View Synthesis',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'eee4aed7886a2ce000330f8faed02b2b29633400',\n",
       "   'title': 'Cascaded Feature Interaction Network for Stereo Matching',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'c685a0705518e728d0fe592694bcda145937945b',\n",
       "   'title': 'Key frames assisted hybrid encoding for high-quality compressive video sensing.',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '74467ece2153d514fb75030adf5ccc242ec54aa6',\n",
       "   'title': 'Multi-Scale RAFT: Combining Hierarchical Concepts for Learning-based Optical FLow Estimation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'e4872822687a60cbaddcfc506130bfabab12008a',\n",
       "   'title': 'Error-Aware Spatial Ensembles for Video Frame Interpolation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '6ff75d1f054c871d1dbdbed4464ce7adbe4b4c55',\n",
       "   'title': 'RealFlow: EM-based Realistic Optical Flow Dataset Generation from Videos',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': '7665a78749bbd0f8e5fe07ca3dd011646d6076fd',\n",
       "   'title': 'Error Compensation Framework for Flow-Guided Video Inpainting',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '0795d8d0e415484710025f0ac3ce1c5c79666fcd',\n",
       "   'title': 'Synthesizing Light Field Video from Monocular Video',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'b9d22e0b3f2b747184a01beffc85ff9e0a7cc83d',\n",
       "   'title': 'Semi-Supervised Learning of Optical Flow by Flow Supervisor',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '89d65e6b892cfe579ba0fa959233fc7a5638b946',\n",
       "   'title': 'FADE: Fusing the Assets of Decoder and Encoder for Task-Agnostic Upsampling',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '70f8d4029c3af108037897012acaab249b854359',\n",
       "   'title': 'Semantic-Aware Fine-Grained Correspondence',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': '683d632d3b5f2d3abb18b6098afee72bf9d76853',\n",
       "   'title': 'Approximate Differentiable Rendering with Algebraic Surfaces',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '0a9d559449d65b2397eab012d1c9f39ac37123af',\n",
       "   'title': 'Region Aware Video Object Segmentation with Deep Motion Modeling',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '36ed3b3425c460d21813007ec82c5a4e3caf6abe',\n",
       "   'title': 'NeuralBF: Neural Bilateral Filtering for Top-down Instance Segmentation on Point Clouds',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '110aa301f17955e3fdb6ee3a503bed414270003b',\n",
       "   'title': 'Animation from Blur: Multi-modal Blur Decomposition with Motion Guidance',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '036e538d7b5a0711612eeebbeec2c132e66da538',\n",
       "   'title': 'Latent Discriminant deterministic Uncertainty',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '02bc6fdcce5f66efd27bac7273b4072ce3856fd9',\n",
       "   'title': 'Secrets of Event-Based Optical Flow',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '75592a6b4fc378558e39907b065ec24610785f11',\n",
       "   'title': 'Spotting Temporally Precise, Fine-Grained Events in Video',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'feef738119a852409c8bf93586b52fe0b4bfc54a',\n",
       "   'title': 'ParticleSfM: Exploiting Dense Point Trajectories for Localizing Moving Cameras in the Wild',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '29393c19ca8a675caf889808d7913624aadced84',\n",
       "   'title': 'What Matters for 3D Scene Flow Network',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': '3c3412fe79422c2427566c3f4c0449762b26b23a',\n",
       "   'title': 'Direct measurement of vorticity using tracer particles with internal markers',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '57935c0daf3d5b95768176c5517559f58121a4f8',\n",
       "   'title': 'Hierarchical Feature Alignment Network for Unsupervised Video Object Segmentation',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': '0f2b8709d6e657e9676557f42c4bfc9e0dc1ef10',\n",
       "   'title': 'C2F-CFN: Coarse-to-Fine ClothFlow Network for High-Fidelity Virtual Try-On',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'e80a64a058aa234dcf29d9cfa7cc4c3072686efd',\n",
       "   'title': 'Adversarial structured prediction for domain-adaptive semantic segmentation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '05d8a8dfb6b56dd134ebe35c3141573c293f5888',\n",
       "   'title': 'Neighbor Correspondence Matching for Flow-based Video Frame Synthesis',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '802e54d116cb34c060c6190b874842d209854e9e',\n",
       "   'title': 'Towards Grand Unification of Object Tracking',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': '274ee7fc9179e2b770c9f1fa5653219728894ab5',\n",
       "   'title': 'Is Appearance Free Action Recognition Possible?',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '6d70d5cd3bd3331f914cb8ccd02f98e94ec89ccf',\n",
       "   'title': 'M-FUSE: Multi-frame Fusion for Scene Flow Estimation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'b26071f224426e6e4fd6ca288ba4b7b3071aa191',\n",
       "   'title': 'Towards Hybrid-Optimization Video Coding',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '710fc9418b14803aea4e8ccf3fbe703a525a5ce3',\n",
       "   'title': 'Complementing Brightness Constancy with Deep Networks for Optical Flow Prediction',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'd57f439df3d6538cc7783db24bf25491c1c8e514',\n",
       "   'title': 'Cross-Attention Transformer for Video Interpolation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '8a1c4df3df79b2536c684d705165985ab69e3d60',\n",
       "   'title': 'Pixel-level Correspondence for Self-Supervised Learning from Video',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': 'b6b07e0d32060b4880061db744b3125cf75801d9',\n",
       "   'title': 'Visual-Assisted Sound Source Depth Estimation in the Wild',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '4e1fb957d851f58b0b5ddedd6e4b7ad8c7848204',\n",
       "   'title': 'Segmenting Moving Objects via an Object-Centric Layered Representation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'be4e6139b6df5a3c90b842fe332d2baef889fe10',\n",
       "   'title': 'SNeRF: Stylized Neural Implicit Representations for 3D Scenes',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': '48c19e3d24e3570fc69daa283daf641d250891fe',\n",
       "   'title': 'FlowNAS: Neural Architecture Search for Optical Flow Estimation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'a4a1ffc47ce1e24f39122f565d6e8dca28282e67',\n",
       "   'title': 'PVO: Panoptic Visual Odometry',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '046ade92e1e39e937a75c6f141ca8bcf03952d78',\n",
       "   'title': 'Egocentric scene reconstruction from an omnidirectional video',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '03dd503647d39f182b231dbdccb8c74dd5f6f605',\n",
       "   'title': 'MRDFlow: Unsupervised Optical Flow Estimation Network With Multi-Scale Recurrent Decoder',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '1b471acfff9d0a76423d0696fe34ef7154bba038',\n",
       "   'title': 'Lagrangian Motion Magnification with Landmark-Prior and Sparse PCA for Facial Microexpressions and Micromovements',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '587d836b88b6b8f222fa03213ddb1703f6f5a70f',\n",
       "   'title': 'Face deblurring using dual camera fusion on mobile phones',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '5222c1de35b59cb4ebc62a86074a10eda5a86931',\n",
       "   'title': 'Roadside HD Map Object Reconstruction Using Monocular Camera',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '5ca0180552cc0e1c74dd755ff11851bde207c42a',\n",
       "   'title': 'Exploring Temporally Dynamic Data Augmentation for Video Recognition',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '52cfe9a77ebbd621e1e8f0f09d9637aab98aa865',\n",
       "   'title': 'Promoting Single-Modal Optical Flow Network for Diverse Cross-Modal Flow Estimation',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': '4105b681f89911f3c70c7b929789f63163b6c0ac',\n",
       "   'title': 'Unsupervised Representation for Semantic Segmentation by Implicit Cycle-Attention Contrastive Learning',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '621558b26e16a6d35b3fd907e50ab303ba65a5ca',\n",
       "   'title': 'SImProv: Scalable Image Provenance Framework for Robust Content Attribution',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '6d1bd610ec727214134e55f405e3b2fba5f1eba0',\n",
       "   'title': 'SearchMorph: Multi-scale Correlation Iterative Network for Deformable Registration',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '716b45ad25715a8c5792df5a7b9e047984239c28',\n",
       "   'title': 'Perceptual Conversational Head Generation with Regularized Driver and Enhanced Renderer',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '5245ff3c247240b34243aeb85ccf213bff037208',\n",
       "   'title': 'Enhanced Deep Animation Video Interpolation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'cd2a6f9dde5a297be0eb58cbfb879be3b42c306d',\n",
       "   'title': 'Not Just Streaks: Towards Ground Truth for Single Image Deraining',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': '97314468e7189fcd5f3cad84b1f55b8664008756',\n",
       "   'title': 'Temporally Consistent Semantic Video Editing',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': 'a03546b073d47b655bd60041cc32491d195131e0',\n",
       "   'title': 'Unsupervised optical flow estimation method based on transformer and occlusion compensation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '63f2ba45b7d58022c92b2e2a18d328246b86baf2',\n",
       "   'title': 'Video frame interpolation for high dynamic range sequences captured with dual-exposure sensors',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '33b5865f517c57a7d55ce00c4c1f8d4c7ae45a4b',\n",
       "   'title': 'Enhanced Bi-directional Motion Estimation for Video Frame Interpolation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '4f9af46dd497fa6055a43bdd9e829e7680d94596',\n",
       "   'title': 'Transformer Lesion Tracker',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '42c131608e091cbaf4906af7b12d811775a0a637',\n",
       "   'title': '$\\\\texttt{GradICON}$: Approximate Diffeomorphisms via Gradient Inverse Consistency',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '5617e3540f157f0a4dc2b176a1e6d448f7d00948',\n",
       "   'title': 'Learning Optical Flow with Kernel Patch Attention',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '31831c6363927ed5c9b6c3ecc176dd90aafcd3fd',\n",
       "   'title': 'Efficient Multi-view Stereo by Iterative Dynamic Cost Volume',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '12750cfd6aa03e4ef24eabfd340550dd3be45355',\n",
       "   'title': 'KeyTr: Keypoint Transporter for 3D Reconstruction of Deformable Objects in Videos',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '5fdfb61bdd0adf08df8ab244ca74822d931d7101',\n",
       "   'title': 'ADeLA: Automatic Dense Labeling with Attention for Viewpoint Shift in Semantic Segmentation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'b54cf1e8bb5b9163fdf791d46bedfe4ec5cd2021',\n",
       "   'title': 'APES: Articulated Part Extraction from Sprite Sheets',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '0516c53d71f7f0c2d2eadb47be16da951dccad07',\n",
       "   'title': 'Artistic Style Novel View Synthesis Based on A Single Image',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '656f923e04e1436f79c9a11bea019b8c99bb18d7',\n",
       "   'title': 'Revisiting the Receptive Field of Conv-GRU in DROID-SLAM',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '1bc5fd23fbe3057a4a08d4373aeb90b6426cb5be',\n",
       "   'title': 'Lagrange Motion Analysis and View Embeddings for Improved Gait Recognition',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'acec832caa147358234433399f07eb51d0d50257',\n",
       "   'title': 'RCP: Recurrent Closest Point for Point Cloud',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'b9a93ff7a2e69f77520015d59f1c0e365f5ca526',\n",
       "   'title': 'SHIFT: A Synthetic Driving Dataset for Continuous Multi-Task Domain Adaptation',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': '6012ce8ee569f3a67dcc61d7e71faed2c7181aa8',\n",
       "   'title': 'Complete and temporally consistent video outpainting',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'e6507ec0bd0034672344ce3ed80a34c0073a1865',\n",
       "   'title': 'PUMP: Pyramidal and Uniqueness Matching Priors for Unsupervised Learning of Local Descriptors',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '7d5f406dae00cb987e86a38dcddc457f97a9dbca',\n",
       "   'title': 'Audio-driven Neural Gesture Reenactment with Video Motion Graphs',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '2b7f4c6ef0bff93236b313ab78dd71ba4723f0b1',\n",
       "   'title': 'Video Anomaly Detection Based on Convolutional Recurrent AutoEncoder',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '55ddb228ce6289c3a6f16311078ff33e7a3b57ac',\n",
       "   'title': 'Inertia-Guided Flow Completion and Style Fusion for Video Inpainting',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'c14e9e9f0d92fba7f565616e87c1d2640b556ed1',\n",
       "   'title': 'Exploiting Rigidity Constraints for LiDAR Scene Flow Estimation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '1a4c60da1a8e0572eae329e1b3acefa7f253a880',\n",
       "   'title': 'A Deeper Dive Into What Deep Spatiotemporal Networks Encode: Quantifying Static vs. Dynamic Information',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'f10d0baf7fb6a1d03c0531278108e7fef6feeb51',\n",
       "   'title': 'Efficient Multi-Purpose Cross-Attention Based Image Alignment Block for Edge Devices',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '393a244df22768a6140530b1e3ca76c273e1b5b5',\n",
       "   'title': 'Optimizing Video Prediction via Video Frame Interpolation',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': '031359683a5b932c262694da46e38a4a0b66b293',\n",
       "   'title': 'Local Homography Estimation on User-Specified Textureless Regions',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '010f2187e734f6e7d690fca68c4d8416ab016e42',\n",
       "   'title': 'A comprehensive overview of dynamic visual SLAM and deep learning: concepts, methods and challenges',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '506fdb3d3498b1f2858355b40dac2bb6f07ca25a',\n",
       "   'title': 'DeVRF: Fast Deformable Voxel Radiance Fields for Dynamic Scenes',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': '1b3f5780cfe9dee836c6d857d13a6f3c4fbed879',\n",
       "   'title': 'SKFlow: Learning Optical Flow with Super Kernels',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '0c6320832d9fe1637d60d2964702ecccf52459de',\n",
       "   'title': 'IFRNet: Intermediate Feature Refine Network for Efficient Frame Interpolation',\n",
       "   'influentialCitationCount': 4},\n",
       "  {'paperId': '1d57909b8c6b9479df0712f85eb24673c0511170',\n",
       "   'title': 'DeepRM: Deep Recurrent Matching for 6D Pose Refinement',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '562acaa4ee8ec58c75ad4d3ecbc21a547bc83a62',\n",
       "   'title': 'RIAV-MVS: Recurrent-Indexing an Asymmetric Volume for Multi-View Stereo',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '7358563190deb74f815a88915325c5270353c330',\n",
       "   'title': 'FlowNet-PET: Unsupervised Learning to Perform Respiratory Motion Correction in PET Imaging',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '4365cbf5889920c42136279773d6b4cecc52d9ab',\n",
       "   'title': 'A Hybrid Deep Learning and Visualization Framework for Pushing Behavior Detection in Pedestrian Dynamics',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'c67dd4354182ab89acfaf6c4f3f473bb9d185a22',\n",
       "   'title': 'Generalization of deep recurrent optical flow estimation for particle-image velocimetry data',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'b0f96566dc80ae46f69c4d606686e19a88347d52',\n",
       "   'title': 'On the Evolution of A.I. and Machine Learning: Towards Measuring and Understanding Impact, Influence, and Leadership at Premier A.I. Conferences',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '873912ff913b11d32759ef1c5817667bb5abc78b',\n",
       "   'title': 'Context-Aware Video Reconstruction for Rolling Shutter Cameras',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '82fee197fe95470260ae684139dfb504c9113c76',\n",
       "   'title': 'RCP: Recurrent Closest Point for Scene Flow Estimation on 3D Point Clouds',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '435ef122ef55223960c8fe8b6106f5937aad75c6',\n",
       "   'title': 'UnDAF: A General Unsupervised Domain Adaptation Framework for Disparity or Optical Flow Estimation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'abc32728cc98abf4758adc34398816f5dc66abb0',\n",
       "   'title': 'Fast Graph Refinement and Implicit Neural Representation for Tissue Tracking',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'f0fcdf4b3989318b57172569175c1bd57cce05c8',\n",
       "   'title': 'UFO Depth: Unsupervised learning with flow-based odometry optimization for metric depth estimation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '8818a3548c4264dfd4f4542907b30f163b93a88b',\n",
       "   'title': 'Unsupervised Flow-Aligned Sequence-to-Sequence Learning for Video Restoration',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '046b26f365bf973cb2ad5ecf142c6024277111a5',\n",
       "   'title': 'Unsupervised Learning of Depth, Camera Pose and Optical Flow from Monocular Video',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '3e0f0e65a9591a8de89cd4a44633a949f46c5a93',\n",
       "   'title': 'Towards Unified Keyframe Propagation Models',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '46536e7ed11c21a4ed2f3231a6dc6456d99e8ae3',\n",
       "   'title': 'Sargassum detection and path estimation using neural networks',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '4bbb5a36210599d4c3be092e078f39aa11463dc0',\n",
       "   'title': 'Unsupervised Segmentation in Real-World Images via Spelke Object Inference',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'c4c0cfc77796131e012ecf267cad13eecdf85572',\n",
       "   'title': 'Guess What Moves: Unsupervised Video and Image Segmentation by Anticipating Motion',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': '3912c18f219cb2459907684ad9e3e6f25966374a',\n",
       "   'title': '3D Moments from Near-Duplicate Photos',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'a0274068d613e389a4f14277b49eb879b81c54ef',\n",
       "   'title': 'Diverse Video Generation from a Single Video',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '678dd2fa4a726d9ed014d76e69d5271eb9f818f2',\n",
       "   'title': 'Review on Panoramic Imaging and Its Applications in Scene Understanding',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '73b269dfcf53fdc3816e8bce0a6b3cc0a4df6655',\n",
       "   'title': 'Spatial-Temporal Space Hand-in-Hand: Spatial-Temporal Video Super-Resolution via Cycle-Projected Mutual Learning',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '49acf6076662ba284e4c8f957d65041c4649a4ff',\n",
       "   'title': 'Multiview Stereo with Cascaded Epipolar RAFT',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': '7a8c362bbd189172bae87ee5f1cc3e0dd96a0397',\n",
       "   'title': 'FlowBot3D: Learning 3D Articulation Flow to Manipulate Articulated Objects',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '0f914a3b495fe9c9a629fd1f77695330ea154ae5',\n",
       "   'title': 'Quantification of Robotic Surgeries with Vision-Based Deep Learning',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '5deac5c1de21472324f216e00394b546eed2eb98',\n",
       "   'title': 'Exploiting Correspondences with All-pairs Correlations for Multi-view Depth Estimation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '04b0e7e7670c36a9bd544d4e8b409a4ee0c9a139',\n",
       "   'title': 'Detection Anomaly in Video Based on Deep Support Vector Data Description',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '67969b851e9b003e9e64c7e0cea728ebed4dd687',\n",
       "   'title': 'GeoRefine: Self-Supervised Online Depth Refinement for Accurate Dense Mapping',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '9a5016fde8f91c2bf1e21726ee5a570bdde834a8',\n",
       "   'title': 'RAFT-MSF: Self-Supervised Monocular Scene Flow using Recurrent Optimizer',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '8e7cfc9b817f826a2ace83215a7a8f6e2cce2227',\n",
       "   'title': 'A comparative study on optical flow for facial expression analysis',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'd4e0ab43439bc86881fadfd87701db0019531d95',\n",
       "   'title': 'Differential SfM and image correction for a rolling shutter stereo rig',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '8b828084d9830cf37f5d391799e417ed7bd68273',\n",
       "   'title': 'Optical flow estimation of coronary angiography sequences based on semi-supervised learning',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'cf6a902bb51fc8c75e29db3cb91b04f12782e066',\n",
       "   'title': 'Coupled Iterative Refinement for 6D Multi-Object Pose Estimation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '023125e8b2c2827e2e0c3d8da6d3de36a543117a',\n",
       "   'title': '4DAC: Learning Attribute Compression for Dynamic Point Clouds',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'fbc2ec83684ddc742aa3d4ce22869727c1898b3c',\n",
       "   'title': 'Efficient Progressive High Dynamic Range Image Restoration via Attention and Alignment Network',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'cf4598fea62df626fa1ac3d87e8696f0fe04b502',\n",
       "   'title': 'A qualitative investigation of optical flow algorithms for video denoising',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '78a6ef2030d32aa1d0386da860ad79338d8e3b8a',\n",
       "   'title': 'Deep Equilibrium Optical Flow Estimation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '57e1ca124ecb208859a6212c2fde763b76ccdf5e',\n",
       "   'title': 'Lagrangian Motion Magnification with Double Sparse Optical Flow Decomposition',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '16119ed6135e18dfea79e2068c18532ed49a8fa4',\n",
       "   'title': 'Multi-Frame Self-Supervised Depth with Transformers',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': '64c18d9712dd1ae5eb3398d58bbe34c87fbc017a',\n",
       "   'title': 'Imposing Consistency for Optical Flow Estimation',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': '3303e078759075ac13a57e90eeb87a7d307005fd',\n",
       "   'title': 'Deformable Sprites for Unsupervised Video Decomposition',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': 'fcf3918398e3023419679eb9933946ae69fb3035',\n",
       "   'title': 'Video K-Net: A Simple, Strong, and Unified Baseline for Video Segmentation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '18f1f85fcccb117c9dbee6ccdea91d43430d06c2',\n",
       "   'title': 'Beyond Cross-view Image Retrieval: Highly Accurate Vehicle Localization Using Satellite Image',\n",
       "   'influentialCitationCount': 3},\n",
       "  {'paperId': '6cd66bafd46f027c43519c880c0e47e30d72b1c3',\n",
       "   'title': 'Particle Videos Revisited: Tracking Through Occlusions Using Point Trajectories',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '6ce5428f4695fdb0ac21bedf23c62cf73d37f43d',\n",
       "   'title': 'Video Demoiréing with Relation-Based Temporal Consistency',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': '3fafcbe986fffe2e9cf4715e1ff6339e1dfe6470',\n",
       "   'title': 'Modeling Motion with Multi-Modal Features for Text-Based Video Segmentation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'b55bfca964dedd457c7c38024596058f523ca556',\n",
       "   'title': 'Action-Conditioned Contrastive Policy Pretraining',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'd772fccbc28a007913f78a53346ea1eb3a47504b',\n",
       "   'title': 'Learning to Drive by Watching YouTube Videos: Action-Conditioned Contrastive Policy Pretraining',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '1eec0537b05c8dd6c43afccf2dafa45006df1c83',\n",
       "   'title': 'Learning Video Salient Object Detection Progressively from Unlabeled Videos',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'ae0d51f697169a1f7e2cd1b293b21d63b4b27c7b',\n",
       "   'title': 'Neural Global Shutter: Learn to Restore Video from a Rolling Shutter Camera with Global Reset Feature',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '482411d98c2ee57cbf8e9acf2f75d50987f68484',\n",
       "   'title': 'Unsupervised Coherent Video Cartoonization with Perceptual Motion Consistency',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'ea9088c20493ffb2952db09446ce5683141350f5',\n",
       "   'title': 'DIP: Deep Inverse Patchmatch for High-Resolution Optical Flow',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': '935fb74758e8ebb2ad85a80a00646ea24e7ee096',\n",
       "   'title': 'GraftNet: Towards Domain Generalized Stereo Matching with a Broad-Spectrum and Task-Oriented Feature',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '0146c411e5f9632a698b93a091eb228db9d79486',\n",
       "   'title': 'RMS-FlowNet: Efficient and Robust Multi-Scale Scene Flow Estimation for Large-Scale Point Clouds',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '3e36d8e03ed7a8e300a55c458f12b7a44a90048a',\n",
       "   'title': 'Learning HDR video reconstruction for dual-exposure sensors with temporally-alternating exposures',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '09e70edfe628ba2e444cf7a3638c2ed0c25a33a4',\n",
       "   'title': 'CRAFT: Cross-Attentional Flow Transformer for Robust Optical Flow',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': 'ea1db7d13d6b512c118e50691ec96c0a360de435',\n",
       "   'title': 'Bringing Old Films Back to Life',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '7bffc157b3b3626a3912a3b0ef74ce5904630fce',\n",
       "   'title': 'FlowFormer: A Transformer Architecture for Optical Flow',\n",
       "   'influentialCitationCount': 2},\n",
       "  {'paperId': 'e4dd79446088b7f10954d44d952fb7d97d5cbc8a',\n",
       "   'title': 'Iterative Deep Homography Estimation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'b0bf5745ae77a084ce97cdf1ad352c385085ff03',\n",
       "   'title': 'Understanding 3D Object Articulation in Internet Videos',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': '3a7cde2f64e5937b5ed2a2e1899b02b59504bbd0',\n",
       "   'title': 'Monitored Distillation for Positive Congruent Depth Completion',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'ccd9fd4faeef42888c7ab97eb24b440d370af049',\n",
       "   'title': 'Dressing in the Wild by Watching Dance Videos',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': '84acc08381f30952cd1fd5df7ccba2f57c5a1135',\n",
       "   'title': 'Learning Optical Flow, Depth, and Scene Flow without Real-World Labels',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '2d766a59c792f04acc795b44d57a78cd48f9e655',\n",
       "   'title': 'Dense Continuous-Time Optical Flow from Events and Frames',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '1cdc8a6c221896045e3c6780985498d3f9930014',\n",
       "   'title': 'RNNPose: Recurrent 6-DoF Object Pose Refinement with Robust Correspondence Field Estimation and Pose Optimization',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '9c6e15595db76e94b8d2dca356db7b5ba3fd3ace',\n",
       "   'title': 'Industrial Style Transfer with Large-scale Geometric Warping and Content Preservation',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': 'df6e0f138915817a0cf228cd4448747c2b72188d',\n",
       "   'title': 'A Perturbation Constrained Adversarial Attack for Evaluating the Robustness of Optical Flow',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': 'fd647e6467fa9605e664145cc1de78532acda903',\n",
       "   'title': 'Learning Scene Flow in 3D Point Clouds with Noisy Pseudo Labels',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '3b073f2d04fc758cf72ae5a64541fef21d12aab7',\n",
       "   'title': 'Self-Supervised Robust Scene Flow Estimation via the Alignment of Probability Density Functions',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'c71dd23cc8671d321d799dd3b1792581bf5a56e5',\n",
       "   'title': 'Practical Stereo Matching via Cascaded Recurrent Network with Adaptive Correlation',\n",
       "   'influentialCitationCount': 6},\n",
       "  {'paperId': '2f6f4d1f410e4e677f835ac78c4f553b3454e9c9',\n",
       "   'title': 'PlaneMVS: 3D Plane Reconstruction from Multi-View Stereo',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '54613977f4c845d3cd2e28cebd7f49c9df6aaf59',\n",
       "   'title': 'Global Matching with Overlapping Attention for Optical Flow Estimation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '00a716b12733a590bae81d04883e450a56ec9aa4',\n",
       "   'title': 'What Makes RAFT Better Than PWC-Net?',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'b54e6762eeaa1f5c03ead7b8b1bda462bc055676',\n",
       "   'title': 'Disentangling Architecture and Training for Optical Flow',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '1ffa8d09044c93bd7278ee2a70fb09ddd7bc5d48',\n",
       "   'title': 'Depth Estimation by Combining Binocular Stereo and Monocular Structured-Light',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '805b0b01a6a2c0346b1edb4ebd9226fb56987588',\n",
       "   'title': 'Discovering Objects that Can Move',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': '75d3671ea8fc6af70359f4cc4cad6471470df6b1',\n",
       "   'title': 'Perspective Flow Aggregation for Data-Limited 6D Object Pose Estimation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '88aac2a9aacc75bd9bc4d12d881c391ed18ae5c2',\n",
       "   'title': 'Beyond a Video Frame Interpolator: A Space Decoupled Learning Approach to Continuous Image Transition',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '236b28c56a53f1846e336a97db174df79c7bb0e2',\n",
       "   'title': 'DXQ-Net: Differentiable LiDAR-Camera Extrinsic Calibration Using Quality-aware Flow',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '3bb7be2bba23067c9715507b1c2fec3c4097d363',\n",
       "   'title': 'A Differentiable Two-stage Alignment Scheme for Burst Image Reconstruction with Large Shift',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'dc6aaacef65638ecc76baa241929cfb0013460f1',\n",
       "   'title': 'Unsupervised Semantic Segmentation by Distilling Feature Correspondences',\n",
       "   'influentialCitationCount': 9},\n",
       "  {'paperId': '03e252c8219a130d542bda8f3348e8b4d156d682',\n",
       "   'title': 'OcclusionFusion: Occlusion-aware Motion Estimation for Real-time Dynamic 3D Reconstruction',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': 'a54e8b88566bd7ac4c420fd0c2bf1dcf5dc21fa9',\n",
       "   'title': 'Implicit Motion Handling for Video Camouflaged Object Detection',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '943dc4edee648a8f5e63486248cc1084dccfcd1f',\n",
       "   'title': 'RCL: Recurrent Continuous Localization for Temporal Action Detection',\n",
       "   'influentialCitationCount': 2},\n",
       "  {'paperId': '06a6a178d4a54c34ca5a41a5a92d5d096b77246a',\n",
       "   'title': 'Bringing Rolling Shutter Images Alive with Dual Reversed Distortion',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '1973f0229cc6b3c1e5a7a12aa6cb65ca54338023',\n",
       "   'title': 'Information-Theoretic Odometry Learning',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '30040a7270b7de8aca27810ba73f44fda0ad9da1',\n",
       "   'title': 'Optical Flow Training under Limited Label Budget via Active Learning',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'e1362a06b4ae99b84a5d1c2de3c6ad11fdf1b97e',\n",
       "   'title': 'Investigation of Factorized Optical Flows as Mid-Level Representations',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'fd2c0e45a95933cacc2a69c79ec1f74553d0cb39',\n",
       "   'title': 'NeReF: Neural Refractive Field for Fluid Surface Reconstruction and Implicit Representation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '7613b1df07b909a91e608d75babc834df40cf85a',\n",
       "   'title': 'Kubric: A scalable dataset generator',\n",
       "   'influentialCitationCount': 2},\n",
       "  {'paperId': '3d890b6d0cec119a118e220ee60da03cdadd446a',\n",
       "   'title': 'Optical Flow Based Motion Detection for Autonomous Driving',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'f2ee6b6e3dd3b42daf981d6f1fd5339f32cbd3b4',\n",
       "   'title': 'Hybrid Tracker with Pixel and Instance for Video Panoptic Segmentation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '60a113163057c4adb780b8a1b1c5f1866a423553',\n",
       "   'title': 'Learning Cross-Video Neural Representations for High-Quality Frame Interpolation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '4af80923dee966208d02684969c6c2370ed323f5',\n",
       "   'title': 'Voxelmorph++ Going beyond the cranial vault with keypoint supervision and multi-channel instance optimisation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '51eefbf1b284c93df3bde5b0bc247465b5a33065',\n",
       "   'title': 'PanoFlow: Learning 360{\\\\deg} Optical Flow for Surrounding Temporal Understanding',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'a7b081747bfbbbfccfbcd983dd41d28c12aea11f',\n",
       "   'title': 'PanoFlow: Learning Optical Flow for Panoramic Images',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '4549b06e02dbc2e26164dcbea3aaef8d454d93f4',\n",
       "   'title': 'ARIA: Adversarially Robust Image Attribution for Content Provenance',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '4014dc86de33941bbb096c52e213b7e2becb8c4a',\n",
       "   'title': 'TwistSLAM: Constrained SLAM in Dynamic Environment',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': '4a8ca6e643bb22c916392e4a78bb50d5cc482730',\n",
       "   'title': 'FUN-SIS: a Fully UNsupervised approach for Surgical Instrument Segmentation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '6b279e13e5e77470db933e006a70e9acf7b257ca',\n",
       "   'title': 'Can Deep Learning be Applied to Model-Based Multi-Object Tracking?',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '0a727c5e867f062f9d3c25c9a588a79e117c7072',\n",
       "   'title': 'Beyond Natural Motion: Exploring Discontinuity for Video Frame Interpolation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'a25b714cf51906fcf09cde29ae93c3ef936c2f81',\n",
       "   'title': 'Box Supervised Video Segmentation Proposal Network',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '68bfc928d2141b9b0c5cb953004c97b017cd583e',\n",
       "   'title': 'Depth-Cooperated Trimodal Network for Video Salient Object Detection',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'c330b74145ae77cbc335531964dceb94951dd7de',\n",
       "   'title': 'Deep soccer captioning with transformer: dataset, semantics-related losses, and multi-level evaluation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '3ae69ec5a9fd4f28dfc495ddf1259e936b140000',\n",
       "   'title': 'Learning Optical Flow with Adaptive Graph Reasoning',\n",
       "   'influentialCitationCount': 2},\n",
       "  {'paperId': 'f246312f917c50413b0cbc06a4dd0d9e74e8ad9a',\n",
       "   'title': 'Boosting Monocular Depth Estimation with Sparse Guided Points',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'eef792a236509a19a5d977c2aa43c2f7c6a19d20',\n",
       "   'title': 'Towards 3D Scene Reconstruction from Locally Scale-Aligned Monocular Video Depth',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '40802db321a6f8ed0a554fbd6c711e08d295ef7b',\n",
       "   'title': 'CSFlow: Learning Optical Flow via Cross Strip Correlation for Autonomous Driving',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'f81119cbcdf01e51136cad8368b7a7c4373ce1ed',\n",
       "   'title': 'IFOR: Iterative Flow Minimization for Robotic Object Rearrangement',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': '0f60c5381fd4e7f8b25af97d3266bbcefdf7b007',\n",
       "   'title': 'Rigid-aware self-supervised GAN for camera ego-motion estimation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '5791a73cc31e0dec699f3febb3e7e29b997abb6c',\n",
       "   'title': 'Cross attention redistribution with contrastive learning for few shot object detection',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': '033bbbc16dd7ea49962291b749e7898bf3582e8f',\n",
       "   'title': 'Contextual Detection of Pedestrians and Vehicles in Orthophotography by Fusion of Deep Learning Algorithms',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '397f012d4b78d4d4eb89a61f7569554d9ed88854',\n",
       "   'title': 'Deep Kernelized Dense Geometric Matching',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '19b479d5a8ca312880f41fb288139ddd6b3683cf',\n",
       "   'title': 'Leveraging Bitstream Metadata for Fast and Accurate Video Compression Correction',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '550516a60b0fd6d7965e45437ed03517e9c66dad',\n",
       "   'title': 'Self-Supervised Moving Vehicle Detection From Audio-Visual Cues',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '85f9d5f61402df21d2b7888cd98d39324d3141c4',\n",
       "   'title': 'Semantically Video Coding: Instill Static-Dynamic Clues into Structured Bitstream for AI Tasks',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'cf7400f4b8aa7d8d17df0aae98b8ccd7ec22e9bd',\n",
       "   'title': 'Splatting-based Synthesis for Video Frame Interpolation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '9b35a09b29feeef36a017f192cc89315dc57bd4f',\n",
       "   'title': 'Content-aware Warping for View Synthesis',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '5713ff36ddb34855574a11b16e7d064f542737bb',\n",
       "   'title': 'Learning Pixel Trajectories with Multiscale Contrastive Random Walks',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '670b4da9e69c7690df06f19ccd18a12f13ee23b4',\n",
       "   'title': 'Autoencoding Video Latents for Adversarial Video Generation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'a58f072f9eb94d79926bbf99ea7bd54c1bf13dde',\n",
       "   'title': 'End-to-end driving model based on deep learning and attention mechanism',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'b653d056feceeaaa06271d2b81cb724a264c5f09',\n",
       "   'title': 'Learning Temporally and Semantically Consistent Unpaired Video-to-Video Translation through Pseudo-Supervision from Synthetic Optical Flow',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '8f2f74b7cc63a0e2ddd735fc30a136c0917efc47',\n",
       "   'title': 'Stereo Magnification with Multi-Layer Images',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '5d7d11d5b1190194e65f4e43f8d72e0c4af1d33a',\n",
       "   'title': 'Neural Residual Flow Fields for Efficient Video Representations',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': '142e3c929be44e46e02a502361350b87e9d1ff79',\n",
       "   'title': 'FlexHDR: Modeling Alignment and Exposure Uncertainties for Flexible HDR Imaging',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '03dc0e226da9cee801ade2886cdde42bbe54065a',\n",
       "   'title': 'EM-Driven Unsupervised Learning for Efficient Motion Segmentation.',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': 'c6e4cc47e0360641e7f91a9b8c83b101939788ea',\n",
       "   'title': 'Time-Space Transformers for Video Panoptic Segmentation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '671cda271adf11e425a1da5a1c2f31f2562827a3',\n",
       "   'title': 'Real-Time Optical Flow for Vehicular Perception With Low- and High-Resolution Event Cameras',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'cdbc5449fb4a47f23bf74188e6813b3b7d2efd2a',\n",
       "   'title': 'Multi-View Depth Estimation by Fusing Single-View Depth Probability with Multi-View Geometry',\n",
       "   'influentialCitationCount': 4},\n",
       "  {'paperId': '9e9c46ba0a347336a2d53b0a6918e1846aab0de7',\n",
       "   'title': 'Stereoscopic Universal Perturbations across Different Architectures and Datasets',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '2536b0a17a97f78a44e029b756acf7b6df16baea',\n",
       "   'title': 'IterMVS: Iterative Probability Estimation for Efficient Multi-View Stereo',\n",
       "   'influentialCitationCount': 2},\n",
       "  {'paperId': '03871045478e9a5062c336b16230e4a79d488052',\n",
       "   'title': 'GAN-Supervised Dense Visual Alignment',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '5ca5c74df211750fc5a22baf7155ff913d8a3db1',\n",
       "   'title': 'Recurrent Glimpse-based Decoder for Detection with Transformer',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': '5af48c42e56fe46087d0412678873ffab7ddf3ad',\n",
       "   'title': 'Input-level Inductive Biases for 3D Reconstruction',\n",
       "   'influentialCitationCount': 3},\n",
       "  {'paperId': '97a21d76a29b132a314846c9c03fe44645bc8de7',\n",
       "   'title': 'Deep Depth from Focus with Differential Focus Volume',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'd2c59336c0c5b4b20831ec752e3da206078ac67e',\n",
       "   'title': 'Improving wildlife tracking using 3D information',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '62ce6451efb635c61a52d08a9ab7d499f87cc5f8',\n",
       "   'title': 'Self-Supervised Monocular Depth and Ego-Motion Estimation in Endoscopy: Appearance Flow to the Rescue',\n",
       "   'influentialCitationCount': 2},\n",
       "  {'paperId': 'a6ad246ef641902cbab4355991d1949d04916278',\n",
       "   'title': 'Revisiting Temporal Alignment for Video Restoration',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'e4733ff919aefc7048774876b05e73bae56fcb49',\n",
       "   'title': 'GMFlow: Learning Optical Flow via Global Matching',\n",
       "   'influentialCitationCount': 2},\n",
       "  {'paperId': '1831959445c2e995b9fe79dfa6386de6c58138cf',\n",
       "   'title': 'Improving the Perceptual Quality of 2D Animation Interpolation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '5d916f1c8930c1e7b25a7e86d9650f9f833e858e',\n",
       "   'title': 'CamLiFlow: Bidirectional Camera-LiDAR Fusion for Joint Optical Flow and Scene Flow Estimation',\n",
       "   'influentialCitationCount': 2},\n",
       "  {'paperId': 'e5bdbc2aa035375b3f45e651740911ea1cd8b7d4',\n",
       "   'title': 'FAMINet: Learning Real-Time Semisupervised Video Object Segmentation With Steepest Optimized Optical Flow',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '79883f040e270a32e7a81b54a3ed16d12833d201',\n",
       "   'title': 'Enhanced Correlation Matching based Video Frame Interpolation',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': '23441af3334813c3b89f8a07550ebf25eb3b2e4b',\n",
       "   'title': 'Learning Scene Dynamics from Point Cloud Sequences',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '0ba107ccae60ab607fcfc1604b237e62f61e58e8',\n",
       "   'title': 'Tracking blobs in the turbulent edge plasma of a tokamak fusion device',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '57777c84ad0c719188c12856b4fb0a77ce08535b',\n",
       "   'title': 'Triple-Level Model Inferred Collaborative Network Architecture for Video Deraining',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '8259c5a775562ccd115426f3bafc5ef02698b060',\n",
       "   'title': 'Parallel multiscale context-based edge-preserving optical flow estimation with occlusion detection',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'b3c7ab9b4c60af188c2cad1da9b6ea6915de6248',\n",
       "   'title': 'Optical Flow Reusing for High-Efficiency Space-Time Video Super Resolution',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'b23c19f64aabd32b6e43b938a41d33e0e65bd359',\n",
       "   'title': 'Optical Flow Estimation for Spiking Camera',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': '66aa1188acd972414e1d72d11c3fb97f0d35e692',\n",
       "   'title': 'SFGAN: Unsupervised Generative Adversarial Learning of 3D Scene Flow from the 3D Scene Self',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '9b1546bc2ecbc2a699d83f113c549806212a7398',\n",
       "   'title': 'Diverse Generation from a Single Video Made Possible',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '37486b4948d9b31632c2ca030ca6d9d268af4423',\n",
       "   'title': 'Spatio-Temporal Recurrent Networks for Event-Based Optical Flow Estimation',\n",
       "   'influentialCitationCount': 2},\n",
       "  {'paperId': '118b80981c90e3af3971ec76f17c195cc3519cab',\n",
       "   'title': 'MetaPose: Fast 3D Pose from Multiple Views without 3D Supervision',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': '8c6bbda2e6bc34915e537f0f00419e1e87bcc637',\n",
       "   'title': 'Physics-Based Noise Modeling for Extreme Low-Light Photography',\n",
       "   'influentialCitationCount': 3},\n",
       "  {'paperId': '9933a5af7895354087baf6c96b64dc8a8973eaed',\n",
       "   'title': 'Perceiver IO: A General Architecture for Structured Inputs & Outputs',\n",
       "   'influentialCitationCount': 23},\n",
       "  {'paperId': '96a597a1b6649992cf55d8ef758bc6de684fe3ee',\n",
       "   'title': 'Self-Supervised Video Object Segmentation by Motion-Aware Mask Propagation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'a25955091564eb7ca69123dbea5d9f064851f95a',\n",
       "   'title': 'Accelerating Video Object Segmentation with Compressed Video',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'aa11dc07028c13278106f6f7686418560d90f09b',\n",
       "   'title': 'Detail Preserving Residual Feature Pyramid Modules for Optical Flow',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': '34b72cdd37341b57192f8912cae7814bd2029fe9',\n",
       "   'title': 'MaCLR: Motion-Aware Contrastive Learning of Representations for Videos',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'df9dfbe775df0c66a57308ec52900a590a92c9f7',\n",
       "   'title': 'SCTN: Sparse Convolution-Transformer Network for Scene Flow Estimation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '36f7bc342aa27b61fd5c9a18bf9b189773781a08',\n",
       "   'title': 'Comparing Correspondences: Video Prediction with Correspondence-wise Losses',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': '8cacd04c9d12ac17106c546257852b7f2a46a254',\n",
       "   'title': 'ASFlow: Unsupervised Optical Flow Learning With Adaptive Pyramid Sampling',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': '423a32ae52806af0a4c730e34399363a61c10c35',\n",
       "   'title': 'Towards Understanding Adversarial Robustness of Optical Flow Networks',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'a3f05f998e22a5136e470b676ba39737708de0a4',\n",
       "   'title': 'Whole-pixel registration of non-rigid images using correspondences interpolation on sparse feature seeds',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '8a4c0bebaa586b73541e1b511b5c015700176f76',\n",
       "   'title': 'Occlusion Boundary: A Formal Definition & Its Detection via Deep Exploration of Context',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'a7d478f0e4b69f136819aa409085b8b6b5048b1c',\n",
       "   'title': 'Learned Variational Video Color Propagation Supplementary material – ECCV 2022',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'e06a8706f7110f0229e837a91f48bb605154a30f',\n",
       "   'title': 'A STUDY ON SELF-SUPERVISED MULTI-FRAME WITH FULL-IMAGE WARPING',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '2b15763ee79d20f9474db8b18a29b84bfaa87e9d',\n",
       "   'title': 'Attacking a Defended Optical Flow Network',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '6f65cf9b02d80b76f89cfaf469a4bcc32b6be827',\n",
       "   'title': 'Learning Omnidirectional Flow in 360 ◦ Video via Siamese Representation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '6621d9253567892d6c68d449cb4a5268128c48a7',\n",
       "   'title': 'Assessment of movement and pose in a hospital bed by ambient and wearable sensor technology in healthy subjects',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '2a25e9f841d9459acd706c8bccbb81c1432d6c4c',\n",
       "   'title': 'Features in Extra Dimensions: Spatial and Temporal Scene Representations',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '0cd6b5eb6182c6e52adc3abb3d8ecfad4639d5b4',\n",
       "   'title': 'Deep 360° Optical Flow Estimation Based on Multi-Projection Fusion',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'eaef56a01beb0751f41008fa6fc946bbb50f8319',\n",
       "   'title': 'Optical Flow Models and Training Techniques in Data-Constrained Environment',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'da8967f070b2f7b6d6a3055cf70b578eb84c671f',\n",
       "   'title': 'Event Transformer FlowNet for optical flow estimation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '0e6dd58f5d60c154da8f3a6ea549390890c6b606',\n",
       "   'title': 'Soccer captioning: dataset, transformer-based model, and triple-level evaluation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '188481705dec16e8df7534b7171031481f5c6ef8',\n",
       "   'title': 'Monitored Distillation for Positive Congruent Depth Completion SUPPLEMENTARY MATERIALS',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '4c391bf50ae47723b8ebcab18a6267d37d8d93ed',\n",
       "   'title': 'Supplementary Materials for Temporally consistent semantic video editing',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '809c243a4fc2e8f12c827f13f2bc65523ce78052',\n",
       "   'title': 'Supplementary Material: Flow-Guided Transformer for Video Inpainting',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '5d79920f4d52cd7f329429b26bc35a07177cdfcc',\n",
       "   'title': 'Human-in-the-Loop Video Semantic Segmentation Auto-Annotation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'e334f65c6edb56e6535d12a807b86c5f6a5cda50',\n",
       "   'title': 'Deep Bayesian Video Frame Interpolation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'fe8630121240d0d3cd904b50d54d8a5a7d17a51a',\n",
       "   'title': 'Structure and Motion from Casual Videos',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'e1b87fe0d5dbcacb54532bb405aff50bc78fcf0c',\n",
       "   'title': 'Learned Variational Video Color Propagation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '74695c2b17b1636f8afd5ecc9f1343c78aa9b91a',\n",
       "   'title': 'Adaptive Co-teaching for Unsupervised Monocular Depth Estimation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '4b6d9cff397a456aeecd377ff833d08ebc190d41',\n",
       "   'title': 'Supplementary Material for CamLiFlow',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'aa695411aed1fe4220e5ad36970710aa0ad47ad3',\n",
       "   'title': 'APES: Articulated Part Extraction from Sprite Sheets –Supplementary Material–',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'c11c7a8a09a6c9bba3832a815c7e6a8df114ea93',\n",
       "   'title': 'Learn to Fuse Input Features for Large-Deformation Registration with Differentiable Convex-Discrete Optimisation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '40c5e3b9550d07d11b6d7bce6be5ba38d3da70af',\n",
       "   'title': 'U NSUPERVISED S EMANTIC S EGMENTATION BY D ISTILLING F EATURE C ORRESPONDENCES',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '02445c06baf47802b4f8ab3ce51bdb75693bf7f2',\n",
       "   'title': 'A Flow-based Generative Network for Photo-Realistic Virtual Try-On',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '087f0fea6cca7871be4698a78ef2abd1a5b25a6d',\n",
       "   'title': 'Integration of Deep Optical Flow in Visual-Inertial Odometry',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'c0f6fdd076c183c669f0331e1e5b498ec61fa5b1',\n",
       "   'title': 'Video-based Behavior Understanding of Children for Objective Diagnosis of Autism',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': 'c85b7ccc728c1b79b75d4dd0f0a367897b39629b',\n",
       "   'title': 'Sparse LiDAR Assisted Self-supervised Stereo Disparity Estimation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '15ba487a3ced7f722fb24025dcd653ea55866614',\n",
       "   'title': '360{\\\\deg} Optical Flow using Tangent Images',\n",
       "   'influentialCitationCount': 2},\n",
       "  {'paperId': '70c31a496c366e5676a65a87738982c0483b618b',\n",
       "   'title': 'Reconfigurable Hybrid Model Convolutional Stage – Infinity Laplacian Applied to Depth Completion',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'ac809d5de6249fb1be2a7632cf246d718d459830',\n",
       "   'title': 'Pixel-wise Deep Image Stitching',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '4322200814437b6b4e13ba4feee89d46cbc9f329',\n",
       "   'title': 'Formulating Event-based Image Reconstruction as a Linear Inverse Problem using Optical Flow',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '8f66cd3c89239ae596656eb13d8290035c7e550a',\n",
       "   'title': 'A Hierarchical Spatio-Temporal Graph Convolutional Neural Network for Anomaly Detection in Videos',\n",
       "   'influentialCitationCount': 2},\n",
       "  {'paperId': '375ec578b88d11ef333ab040806e37cd874085e0',\n",
       "   'title': 'Scalable 3D Semantic Segmentation for Gun Detection in CT Scans',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '033147336e661183224f6ac5d46ca21c645b5c29',\n",
       "   'title': 'Fast and Context-Aware Framework for Space-Time Video Super-Resolution',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '1f99f47d2061f3eb86065ca6024e0d56a744e308',\n",
       "   'title': 'Class-agnostic Reconstruction of Dynamic Objects from Videos',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '0ef34bac54ad267a2d9211b74616995fb9e1c2b4',\n",
       "   'title': 'Dimensions of Motion: Learning to Predict a Subspace of Optical Flow from a Single Image',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '1c8008a343dff523f1b52d9ae3d71f59ad64fdc9',\n",
       "   'title': 'Dimensions of Motion: Monocular Prediction through Flow Subspaces',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'd5dd472de6170ce5924175d350e813b29f155d24',\n",
       "   'title': 'Direct Dense Pose Estimation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'd909acffb3f83eb140ac77b3b9f76c03cd995ee9',\n",
       "   'title': 'Neural frame interpolation for rendered content',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'de266aceacf9c946ca144edfce2ccda1bc9ce9d2',\n",
       "   'title': 'Behind-The-Scenes (BTS): Wiper-Occlusion Canceling for Advanced Driver Assistance Systems in Adverse Rain Environments',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'a125dede6a87892f3c27e038961d8d20a9285b73',\n",
       "   'title': 'MUNet: Motion Uncertainty-aware Semi-supervised Video Object Segmentation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '7fd0820de123c29de6299e53a8fc2835c94ae02c',\n",
       "   'title': 'Robust Visual Odometry Using Position-Aware Flow and Geometric Bundle Adjustment',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '327598d800a858176806063f2574e1899e235bdd',\n",
       "   'title': 'Enhanced Real-Time Intermediate Flow Estimation for Video Frame Interpolation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '15fc6b79d8f41ffe5a7af44934dc0b0ca0e54b15',\n",
       "   'title': 'DeMFI: Deep Joint Deblurring and Multi-Frame Interpolation with Flow-Guided Attentive Correlation and Recursive Boosting',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': '17dca59f0b614f75c1429a280ba703cad6b404ba',\n",
       "   'title': 'Temporally Consistent Online Depth Estimation in Dynamic Scenes',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '014447fa3fa40d046d3bbe752125ae74092d0fb6',\n",
       "   'title': 'Consistent Semantic Attacks on Optical Flow',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '6419160675cfb2999a9a7cb5ca226383f3b21db0',\n",
       "   'title': 'The Emergence of Objectness: Learning Zero-Shot Segmentation from Videos',\n",
       "   'influentialCitationCount': 2},\n",
       "  {'paperId': 'de182bb3a06a458b4866c671417c5c27cca5fccd',\n",
       "   'title': 'Dense Unsupervised Learning for Video Segmentation',\n",
       "   'influentialCitationCount': 2},\n",
       "  {'paperId': '0572e4c8998d8910468e940bc5bfdb505646fc68',\n",
       "   'title': 'FabricFlowNet: Bimanual Cloth Manipulation with a Flow-based Policy',\n",
       "   'influentialCitationCount': 2},\n",
       "  {'paperId': '3826b47d3e8a7ef99d8c757c778e7d11633df84e',\n",
       "   'title': 'BBC-Oxford British Sign Language Dataset',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '717f851a4eeda82b6f3eaa463e2042f903ebf5ff',\n",
       "   'title': 'Joint Detection of Motion Boundaries and Occlusions',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '3638cbc0eec1ca3f6ede7e2f3672cfc85e553215',\n",
       "   'title': 'Motion-Guided Physics-Based Learning for Cardiac MRI Reconstruction',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '45d7d2909b361b3263cbc66bb0845454c2690fe6',\n",
       "   'title': 'DocScanner: Robust Document Image Rectification with Progressive Learning',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'd3bcfc30a93f6f1f8b1c6cb5296d1334d998091c',\n",
       "   'title': 'RAFT-SLAM: Deep Optical-Flow Assisted Simultaneous Localization and Mapping',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '407b494da190391ba46153318df68cc3384aab1e',\n",
       "   'title': 'UVO Challenge on Video-based Open-World Segmentation 2021: 1st Place Solution',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '88536a66c1340b3777ff2de39abb59eb9766f3d8',\n",
       "   'title': 'A multi-scale unsupervised learning for deformable image registration',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '0f9c5f6f6012dc51528ce13ad58ba4e71383b04a',\n",
       "   'title': 'Multi-Object Tracking and Segmentation with a Space-Time Memory Network',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '30aa5f3e2e3975cb79350f28827109183652318d',\n",
       "   'title': 'DMVO: A Multi-motion Visual Odometry for Dynamic Environments',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '5e98f0097a02f45e971bdcb724ce00224483ee29',\n",
       "   'title': '1st Place Solution for the UVO Challenge on Video-based Open-World Segmentation 2021',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': '7c69d5b671331a55e9fda14d8a076aa8b47ca926',\n",
       "   'title': 'Edit Like A Designer: Modeling Design Workflows for Unaligned Fashion Editing',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'f432f0ad9ed62e48c632e0abd6bcac2064bc512d',\n",
       "   'title': 'Salient Error Detection based Refinement for Wide-baseline Image Interpolation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '32804357cc8da6caead768ee17d7ceea5bdbc173',\n",
       "   'title': 'Stereo Video Super-Resolution via Exploiting View-Temporal Correlations',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '20f9ae00f13ca6c2d4158289b263ea6e3a8001c2',\n",
       "   'title': 'Implicit Feature Refinement for Instance Segmentation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'b2b3941436f2384ba6a1ee0e2eca4e0c96260209',\n",
       "   'title': 'GLM-Net: Global and Local Motion Estimation via Task-Oriented Encoder-Decoder Structure',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'aa3ce2e1782b45866f150eff186ec915fcedca3b',\n",
       "   'title': 'How Video Super-Resolution and Frame Interpolation Mutually Benefit',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': 'e5cd08b3890fc722b3ccfded1b0bc3480fc3ed2d',\n",
       "   'title': 'Unsupervised Object Learning via Common Fate',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '42f5d9af719f804839ebebbab0cea93bd949e5ce',\n",
       "   'title': 'MGPSN: Motion-Guided Pseudo Siamese Network for Indoor Video Head Detection',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '91bb7d02abd7551b20699c5400c2169599937d8f',\n",
       "   'title': 'Mpsn: Motion-Aware Pseudo Siamese Network for Indoor Video Head Detection',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '8a1cbc71deac64756fb757e68cb0fbb28d8f20d8',\n",
       "   'title': 'Separable Flow: Learning Motion Cost Volumes for Optical Flow Estimation',\n",
       "   'influentialCitationCount': 6},\n",
       "  {'paperId': '3b315623b210aec5d8895e328f30f4bacb32a503',\n",
       "   'title': 'SLIM: Self-Supervised LiDAR Scene Flow and Motion Segmentation',\n",
       "   'influentialCitationCount': 3},\n",
       "  {'paperId': '6ef6ef6199558c3b4d7e8cb2cd018de171894e8f',\n",
       "   'title': 'Inverting a Rolling Shutter Camera: Bring Rolling Shutter Images to High Framerate Global Shutter Video',\n",
       "   'influentialCitationCount': 3},\n",
       "  {'paperId': '829f9f80ccf6900b01c07cf1795596409108084f',\n",
       "   'title': 'R-MSFM: Recurrent Multi-Scale Feature Modulation for Monocular Depth Estimating',\n",
       "   'influentialCitationCount': 3},\n",
       "  {'paperId': '924053d36e393653e566a4962805ccba6d998497',\n",
       "   'title': 'SeLFVi: Self-supervised Light-Field Video Reconstruction from Stereo Video',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '1f4da61139d1385c44c222e7a7f85192ca6da5f8',\n",
       "   'title': 'VaPiD: A Rapid Vanishing Point Detector via Learned Optimizers',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': '5b77f887fad63b4376516d53d756303f6d3b709b',\n",
       "   'title': 'Learning Motion-Appearance Co-Attention for Zero-Shot Video Object Segmentation',\n",
       "   'influentialCitationCount': 2},\n",
       "  {'paperId': 'a20482387d63cf2d0ffda08a289eb604ba4cf187',\n",
       "   'title': 'Assignment-Space-based Multi-Object Tracking and Segmentation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '77130dbbd9bcbbebddeed91e3980242b7f3fcc93',\n",
       "   'title': 'High Quality Disparity Remapping with Two-Stage Warping',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'ca34ad0326525105cb302694c85be9e1f791df6a',\n",
       "   'title': 'MAAD: A Model and Dataset for \"Attended Awareness\" in Driving',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '7754a2a82ed16ecf21ba339a1eef059f3db2b978',\n",
       "   'title': 'Sensor-Guided Optical Flow',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '74cc640c064db35d679473297582c5934fa4770b',\n",
       "   'title': 'PDC-Net+: Enhanced Probabilistic Dense Correspondence Network',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': '684189b6bce95c9417c1b92be3032aa0c4b059e1',\n",
       "   'title': 'Warp-Refine Propagation: Semi-Supervised Auto-labeling via Cycle-consistency',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '15dfb5b1ad47f63196aaad74467999fbe81e7573',\n",
       "   'title': 'An End to End Learning based Ego Vehicle Speed Estimation System',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '7806ad7885d732040cb1fbf23857bba5b6779edd',\n",
       "   'title': 'Layered neural atlases for consistent video editing',\n",
       "   'influentialCitationCount': 3},\n",
       "  {'paperId': 'c4b2868c5cac5748430ed475b51fdacafb1b002d',\n",
       "   'title': 'Face Forgery Detection Based On Segmentation Network',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'd2bd71ad1aa29ca573dacc3e3fba8820c843d73d',\n",
       "   'title': 'PIRenderer: Controllable Portrait Image Generation via Semantic Neural Rendering',\n",
       "   'influentialCitationCount': 19},\n",
       "  {'paperId': '09c8d8249d9e61dace9bd1e0b3cd8042a7ef365d',\n",
       "   'title': 'RAFT-Stereo: Multilevel Recurrent Field Transforms for Stereo Matching',\n",
       "   'influentialCitationCount': 13},\n",
       "  {'paperId': 'ea44a6265a3b84ce26c7b5fb162126d78118003e',\n",
       "   'title': 'Dual-view Snapshot Compressive Imaging via Optical Flow Aided Recurrent Neural Network',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'bfe2a0b20d12e3d488cdbf273f94e3c645f7944e',\n",
       "   'title': 'Automatic Portrait Video Matting via Context Motion Network',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '14e1f486ab36eccfa1fd28c28f06a6f63d5a6c26',\n",
       "   'title': 'Video Pose Distillation for Few-Shot, Fine-Grained Sports Action Recognition',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'fed4c11c40a559031bae2e7f092ebfc6ad8256c5',\n",
       "   'title': 'Effective Ensemble of Deep Neural Networks Predicts Neural Responses to Naturalistic Videos',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '67515d1f7df144683b059e684da7974e40aeaca1',\n",
       "   'title': 'DROID-SLAM: Deep Visual SLAM for Monocular, Stereo, and RGB-D Cameras',\n",
       "   'influentialCitationCount': 11},\n",
       "  {'paperId': '81a96c19334c5933166dd97d23c378c5b53eb541',\n",
       "   'title': 'HPOF:3D Human Pose Recovery from Monocular Video with Optical Flow',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': '49cc433d754e0c1bbc00e6d4bb11a1e894210482',\n",
       "   'title': 'E-RAFT: Dense Optical Flow from Event Cameras',\n",
       "   'influentialCitationCount': 7},\n",
       "  {'paperId': '125acdb500e3e0ce1db47bbfa95642e261c891d0',\n",
       "   'title': 'Full-Velocity Radar Returns by Radar-Camera Fusion',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'a19bb4b7cca19ada7a3acd8e02497cd67138e402',\n",
       "   'title': 'Generating Superpixels for High-resolution Images with Decoupled Patch Calibration',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '2aebe99ee733ae480d139ebc3191333783fe12ca',\n",
       "   'title': 'Progressive and Selective Fusion Network for High Dynamic Range Imaging',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'd6bd037e83e3812a7f4a173e24cff7f35ed6950e',\n",
       "   'title': 'Learning Dynamic Interpolation for Extremely Sparse Light Fields with Wide Baselines',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '395ea87285e43fb2b9e3232086bdc3cb5a9d210e',\n",
       "   'title': 'Occlusion-Aware Video Object Inpainting',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '1d33df8e6a9684625c0de729b8667d47f842a0e4',\n",
       "   'title': 'Multi-Source Fusion and Automatic Predictor Selection for Zero-Shot Video Object Segmentation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'e0d677dec0248e4673fae079b6479fce96133f5b',\n",
       "   'title': 'Full-duplex strategy for video object segmentation',\n",
       "   'influentialCitationCount': 7},\n",
       "  {'paperId': '8744abf0647938950599f4f72d663cf7fd5d6af1',\n",
       "   'title': 'Online Training of Spiking Recurrent Neural Networks with Phase-Change Memory Synapses',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '88a85c56aac5e926f020851c21ba3e82d6b677c8',\n",
       "   'title': 'Recurrent Mask Refinement for Few-Shot Medical Image Segmentation',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': '817e7002e4c13cac6ed3ac83fac7b373cd94d2ef',\n",
       "   'title': 'Unsupervised Recurrent All-Pairs Field Transforms for Particle Image Velocimetry',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'e15e53031eaf1219719c91be6df4931b56506ab5',\n",
       "   'title': 'Can a humanoid social robot stimulate the interactivity of cognitively impaired elderly? A thorough study based on computer vision methods',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '5cbf6bfe61851dbd60a1b4f896fbc482e09f3bba',\n",
       "   'title': 'ADeLA: Automatic Dense Labeling with Attention for Viewpoint Adaptation in Semantic Segmentation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'd9d210ef158e220c5dfc8a964a5bbbae07c40921',\n",
       "   'title': 'An Improved Fractional-Order Variational Optical Flow Model Combining Structure Tensor',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'fb877c091d87a75aeb28a01002c34761b473ab64',\n",
       "   'title': 'DOVE: Learning Deformable 3D Objects by Watching Videos',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'c155e759c4361661d7e80afbc67cad744a716c28',\n",
       "   'title': 'Deep Iterative 2D/3D Registration',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '099d059990300565771903f53517fccb499a69a8',\n",
       "   'title': 'Consistent depth of moving objects in video',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'f13df75ee19e21cf9d461b34ff333e3db027e6d7',\n",
       "   'title': 'SCV-Stereo: Learning Stereo Matching From a Sparse Cost Volume',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '6a1c6e976358d88ed00a407d2b9bea07cea90311',\n",
       "   'title': 'Consistent depth of moving objects in video',\n",
       "   'influentialCitationCount': 2},\n",
       "  {'paperId': '3fe41ee4ec74a6aa6b4fcf21dbeff38a7a1fc59c',\n",
       "   'title': 'End-to-end Multi-modal Video Temporal Grounding',\n",
       "   'influentialCitationCount': 3},\n",
       "  {'paperId': 'c07845d2bab5c69b8f088d259e2971457c4cae01',\n",
       "   'title': 'Merging Tasks for Video Panoptic Segmentation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '64f27a4b92c5252f616209a3204c632d71409eb8',\n",
       "   'title': 'SCOD: Active Object Detection for Embodied Agents using Sensory Commutativity of Action Sequences',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '729e0859d03251c42f8759b805f8017cfcc6f4ab',\n",
       "   'title': 'Deep recurrent optical flow learning for particle image velocimetry data',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'cb97632b211f81be879d351912bcdf2d7e7109f7',\n",
       "   'title': 'SDOF-GAN: Symmetric Dense Optical Flow Estimation With Generative Adversarial Networks',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'f485fc0b8a20a98379c4d2a742e0efd51fd38b92',\n",
       "   'title': 'Fractal Pyramid Networks',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '875ff50350f5c34771fbff50d9ee91bc44800f5f',\n",
       "   'title': 'Restoration and Enhancement of Historical Stereo Photos',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '92dffe0e9c257538b863c24c538470c77304669c',\n",
       "   'title': 'Uncertainty-Aware Convolutional Neural Networks for Vision Tasks on Sparse Data',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '5a7d324b3c41d10e029b104a5a96771683688184',\n",
       "   'title': 'MoDist: Motion Distillation for Self-supervised Video Representation Learning',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': '67c0fc759566611087ef00f97f28afc4ca65a5ce',\n",
       "   'title': 'Discriminative correlation filters in robot vision',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '78a0fb70b79116eb8d42c5951ced4f9efba513f0',\n",
       "   'title': 'Keeping Your Eye on the Ball: Trajectory Attention in Video Transformers',\n",
       "   'influentialCitationCount': 25},\n",
       "  {'paperId': '2446a59a1a673a7722c5b432d063a9045cf19902',\n",
       "   'title': 'Pretrained Encoders are All You Need',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '15dd0360ece5ea522b5ccb1832c9c11d7041f976',\n",
       "   'title': 'Towards Training Stronger Video Vision Transformers for EPIC-KITCHENS-100 Action Recognition',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '7d6ad701a86596845401815e40b12994da10b9b0',\n",
       "   'title': 'Frame Rate Up-Conversion Using Key Point Agnostic Frequency-Selective Mesh-to-Grid Resampling',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '8c7d3f2ed6d1f68835d9f6f606625baee3a8ea2b',\n",
       "   'title': 'A Bio-Inspired Motion Detection Circuit Model for the Computation of Optical Flow: The Spatial-Temporal Filtering Reichardt Model',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'ca62a92a6e0a77f728ad425966b04bf266ebd5ba',\n",
       "   'title': 'Deep Matching Prior: Test-Time Optimization for Dense Correspondence',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '9eb7509bbdb33052b7a6c22a70699752ab09eecc',\n",
       "   'title': 'Deep Image Comparator: Learning to Visualize Editorial Change',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '390ec1f13ac58429a092fb01678d4c3105482aaa',\n",
       "   'title': 'Depth distillation: unsupervised metric depth estimation for UAVs by finding consensus between kinematics, optical flow and deep learning',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'e17529c6ce6099f95358da16d92b109ca7490446',\n",
       "   'title': 'PatchMatch-Based Neighborhood Consensus for Semantic Correspondence',\n",
       "   'influentialCitationCount': 2},\n",
       "  {'paperId': 'b4a0ec01ddc7e71893764cd8f57b63dc6d7f1996',\n",
       "   'title': 'Reciprocal Transformations for Unsupervised Video Object Segmentation',\n",
       "   'influentialCitationCount': 7},\n",
       "  {'paperId': '888600a4a584a217a3baf120683e62dacf3afb27',\n",
       "   'title': 'CoCosNet v2: Full-Resolution Correspondence Learning for Image Translation',\n",
       "   'influentialCitationCount': 9},\n",
       "  {'paperId': '3f16e45cdf761273655d8698794422f50dcbd5a6',\n",
       "   'title': 'Learning to Warp for Style Transfer',\n",
       "   'influentialCitationCount': 2},\n",
       "  {'paperId': 'e4aef4816ea7de92889dcd8e8af88c1d7058dfbe',\n",
       "   'title': 'Radar-Camera Pixel Depth Association for Depth Completion',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': '7de783ee81976a41a5281564a993c26f55b3b428',\n",
       "   'title': 'Bitrate Estimation for Spatial Scalable Videos',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'be5d94e7ed1d1a6fd10054a297046bf3da254ccf',\n",
       "   'title': 'Driver Intention Anticipation Based on In-Cabin and Driving Scene Monitoring Using Deep Learning',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '18b331cbef86ca58981c54900a3c023be6d753d4',\n",
       "   'title': 'Predicting Driver Intention Using Deep Neural Network',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '49ea570f36d036c625652d20457c4bc32351a324',\n",
       "   'title': 'Attention-guided Temporally Coherent Video Object Matting',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': '4a5f5fe37087def5d269e814808014791df7ce43',\n",
       "   'title': 'View-dependent Scene Appearance Synthesis using Inverse Rendering from Light Fields',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '0046e38532ef0632ea3ade769029c702a51dbfbe',\n",
       "   'title': 'Guidance And Teaching Network For Video Salient Object Detection',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '7165bd148bfd290593f0932b40290d9be2009df4',\n",
       "   'title': 'SMURF: Self-Teaching Multi-Frame Unsupervised RAFT with Full-Image Warping',\n",
       "   'influentialCitationCount': 5},\n",
       "  {'paperId': '156ddb6feea4339d4258049aa840efbbd92ad705',\n",
       "   'title': 'Omnimatte: Associating Objects and Their Effects in Video',\n",
       "   'influentialCitationCount': 4},\n",
       "  {'paperId': '378f5305d7250e7290dd1cde87b319617d285d39',\n",
       "   'title': 'Exploiting Aliasing for Manga Restoration',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'e60704493f7bfa11b71aeec4459635085fb5bd5c',\n",
       "   'title': 'Confidence-Guided Adaptive Gate and Dual Differential Enhancement for Video Salient Object Detection',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': '6b0a81d050e0bc0e49010c49f51ec3fcbaab6b28',\n",
       "   'title': 'Dynamic View Synthesis from Dynamic Monocular Video',\n",
       "   'influentialCitationCount': 7},\n",
       "  {'paperId': 'a0e468a9737fe870e28e474e3fa962b776e710e8',\n",
       "   'title': 'Neural Trajectory Fields for Dynamic Novel View Synthesis',\n",
       "   'influentialCitationCount': 2},\n",
       "  {'paperId': 'b0d8650d08e6041c8851bfbba70097536fc4fbcb',\n",
       "   'title': 'LASR: Learning Articulated Shape Reconstruction from a Monocular Video',\n",
       "   'influentialCitationCount': 8},\n",
       "  {'paperId': '567218e84585558bf18a7d63c13f632680e124f1',\n",
       "   'title': '4DComplete: Non-Rigid Motion Estimation Beyond the Observable Surface',\n",
       "   'influentialCitationCount': 6},\n",
       "  {'paperId': '341ea2e4a19a07db2a779c84533ed1427372e6f9',\n",
       "   'title': 'Does elderly enjoy playing Bingo with a robot? A case study with the humanoid robot Nadine',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '101558a78e21628827692a6e8ae56fe111c272da',\n",
       "   'title': 'MetaFlow: a meta-learning-based network for optical flow estimation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '9ee5045f42d7fbd4f848e91a354d63793365fdd1',\n",
       "   'title': 'AutoFlow: Learning a Better Training Set for Optical Flow',\n",
       "   'influentialCitationCount': 6},\n",
       "  {'paperId': '1c23f531ab02143c7c38755b91e0576acdc45e95',\n",
       "   'title': 'High-Resolution Optical Flow from 1D Attention and Correlation',\n",
       "   'influentialCitationCount': 5},\n",
       "  {'paperId': '2ab2d8f7b35f20ed55a34088b2b67b3c7e60be3a',\n",
       "   'title': 'Extreme Rotation Estimation using Dense Correlation Volumes',\n",
       "   'influentialCitationCount': 3},\n",
       "  {'paperId': '12a3c87ab628e588d50cfe101b3e688e4c53faba',\n",
       "   'title': 'Learning to Better Segment Objects from Unseen Classes with Unlabeled Videos',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'c0ada46dcaca4b91428f73b1994a39a5a9c6366e',\n",
       "   'title': 'Let’s See Clearly: Contaminant Artifact Removal for Moving Cameras',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '9dd395562b2a239fcaf6ae200279d430640b770f',\n",
       "   'title': 'Noise-Aware Video Saliency Prediction',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '46bd741c6a49a097d2893a7442a40feb9e31d502',\n",
       "   'title': 'Self-supervised Video Object Segmentation by Motion Grouping',\n",
       "   'influentialCitationCount': 8},\n",
       "  {'paperId': '8428aae45217e4a5ba3e6ddd64beabba55bb23fd',\n",
       "   'title': 'MESD: Exploring Optical Flow Assessment on Edge of Motion Objects with Motion Edge Structure Difference',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '6d453f5df60963a232fdc62f5c5f70b4c55f5185',\n",
       "   'title': 'Learning optical flow from still images',\n",
       "   'influentialCitationCount': 2},\n",
       "  {'paperId': '88a3579aecc1f0c7a3d5b57a5c07cd51c242b3c4',\n",
       "   'title': 'Multiple Object Tracking with Correlation Learning',\n",
       "   'influentialCitationCount': 5},\n",
       "  {'paperId': '71b424f88ad7a8060d1bf5b12f9894e4e96c0a00',\n",
       "   'title': 'Progressive Temporal Feature Alignment Network for Video Inpainting',\n",
       "   'influentialCitationCount': 3},\n",
       "  {'paperId': '920bc66d14e8b97dda8a6a923413dc4b7adf7e2b',\n",
       "   'title': 'LIFE: Lighting Invariant Flow Estimation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'b5126ed0d46ef7af3663f60fcaacf1c503e4065d',\n",
       "   'title': 'Track, Check, Repeat: An EM Approach to Unsupervised Tracking',\n",
       "   'influentialCitationCount': 2},\n",
       "  {'paperId': 'd2ac32c2fbfd1b8fc53c62880868d71c0e2dfd57',\n",
       "   'title': 'Learning to Estimate Hidden Motions with Global Motion Aggregation',\n",
       "   'influentialCitationCount': 19},\n",
       "  {'paperId': '701c56592f6b4132f5869f175a46c88df12a3340',\n",
       "   'title': 'Deep Animation Video Interpolation in the Wild',\n",
       "   'influentialCitationCount': 4},\n",
       "  {'paperId': '08cfd4a23d3be9fb6ba0c35722e151429dbe5ede',\n",
       "   'title': 'Learning Optical Flow from a Few Matches',\n",
       "   'influentialCitationCount': 5},\n",
       "  {'paperId': 'fac555390b4547929fef6e54070ce9fbbc07921b',\n",
       "   'title': 'Optical Flow Dataset Synthesis from Unpaired Images',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '651d6b5c8c5618706cfbcb845055b330e063520b',\n",
       "   'title': 'Multitarget Tracking with Transformers',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '09c950f1cbc92e2be877b0035f8b98a7d8f55853',\n",
       "   'title': 'Next Generation Multitarget Trackers: Random Finite Set Methods vs Transformer-based Deep Learning',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '640667e929b2ce4fe4cce4f060c4e710c817365e',\n",
       "   'title': 'Deep Two-View Structure-from-Motion Revisited',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': '904135043cf25911e45e13b09064ff5e85c9c89a',\n",
       "   'title': 'DCVNet: Dilated Cost Volume Networks for Fast Optical Flow',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '19594ad99a146f86d252574f2f3bdcfeef3ab6a0',\n",
       "   'title': 'What Causes Optical Flow Networks to be Vulnerable to Physical Adversarial Attacks',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': '565f23e8c0501252f9830f42b978735f6b4049f1',\n",
       "   'title': 'HumanGPS: Geodesic PreServing Feature for Dense Human Correspondences',\n",
       "   'influentialCitationCount': 3},\n",
       "  {'paperId': '9808c882294fc3b6a1bfed85cc69d622d4ec7751',\n",
       "   'title': 'Generalizing to the Open World: Deep Visual Odometry with Online Adaptation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '68b6042daae271be316e04ddc39794a325771861',\n",
       "   'title': 'Whole-pixel registration of non-rigid images using correspondences interpolation on sparse feature seeds',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '2b5c4b3dba186f6bf5670af9da53c99f357399ef',\n",
       "   'title': 'GyroFlow: Gyroscope-Guided Unsupervised Optical Flow Learning',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': '1536febbc3e15d51642991797f6ce624838a468e',\n",
       "   'title': 'COTR: Correspondence Transformer for Matching Across Images',\n",
       "   'influentialCitationCount': 16},\n",
       "  {'paperId': 'bde28ab593d17588474fef20766c65693e0866ed',\n",
       "   'title': 'DRO: Deep Recurrent Optimizer for Structure-from-Motion',\n",
       "   'influentialCitationCount': 6},\n",
       "  {'paperId': '650b5a65a80029a649ecbf0d85f97ec2881f0203',\n",
       "   'title': 'Efficient Regional Memory Network for Video Object Segmentation',\n",
       "   'influentialCitationCount': 10},\n",
       "  {'paperId': 'aeaa9ba2a453a60478d66acbb15678a5dd882686',\n",
       "   'title': 'Tangent Space Backpropagation for 3D Transformation Groups',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': 'a810620659eee14561b69b6c02733f95ab87b027',\n",
       "   'title': 'ORStereo: Occlusion-Aware Recurrent Stereo Matching for 4K-Resolution Images',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '04b1f172f1630db156c02046b54d9ecdf613a3fa',\n",
       "   'title': 'PVStereo: Pyramid Voting Module for End-to-End Self-Supervised Stereo Matching',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '3361ac7eeed94d5c5a84ebd7184ac5eeb23fd5a3',\n",
       "   'title': 'FastFlowNet: A Lightweight Network for Fast Optical Flow Estimation',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': '9a93fadaa32bd688d88125c09f143737e252cbfa',\n",
       "   'title': 'ARVo: Learning All-Range Volumetric Correspondence for Video Deblurring',\n",
       "   'influentialCitationCount': 9},\n",
       "  {'paperId': '3be3fe4de570e17790a2b44cbc4b5fb6b3493af4',\n",
       "   'title': 'ES-Net: An Efficient Stereo Matching Network',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '4b4727a8ed464a2addb34023fac8aff47acefb51',\n",
       "   'title': 'Multi-Stage Raw Video Denoising with Adversarial Loss and Gradient Mask',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '581ba7d93349ac0e1eec74385160205bc1accb8a',\n",
       "   'title': 'DeepTag: An Unsupervised Deep Learning Method for Motion Tracking on Cardiac Tagging Magnetic Resonance Images',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'ba4f1f4106615ea2af6a345e7897abcc18662884',\n",
       "   'title': 'Accurate Visual-Inertial SLAM by Feature Re-identification',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '21229d4c984f9a6bcc3571742df48f6bd0971b90',\n",
       "   'title': 'STEP: Segmenting and Tracking Every Pixel',\n",
       "   'influentialCitationCount': 6},\n",
       "  {'paperId': 'c7b66c1af93a04b9a1d5852b1a44b689ee87be8d',\n",
       "   'title': 'Normalized Convolution Upsampling for Refined Optical Flow Estimation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'e7ac993bc5a754994ffeb1e0bd340516c797a63e',\n",
       "   'title': 'Neural Re-rendering for Full-frame Video Stabilization',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '21be8dd1df500ff00ba02f4f157e1c090b4f9937',\n",
       "   'title': 'Hybrid Neural Fusion for Full-frame Video Stabilization',\n",
       "   'influentialCitationCount': 2},\n",
       "  {'paperId': 'c143ea9e30b1f2d93a9c060253845423f9e60e1f',\n",
       "   'title': 'Is Space-Time Attention All You Need for Video Understanding?',\n",
       "   'influentialCitationCount': 139},\n",
       "  {'paperId': '5e38dc1ccf33ac1df09b8eb6476f110cb3d1966f',\n",
       "   'title': 'Learning N: M Fine-grained Structured Sparse Neural Networks From Scratch',\n",
       "   'influentialCitationCount': 9},\n",
       "  {'paperId': '4937389b8e9bf7b0b9c56773ffd4ed4e4d15a5ed',\n",
       "   'title': 'VideoClick: Video Object Segmentation with a Single Click',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'ab9ef24dcfe54f8c616554e253764b1b5c271664',\n",
       "   'title': 'Optical Flow Estimation Via Motion Feature Recovery',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'af20c2fec4fdcb49a227c1f62ba61d565f323b19',\n",
       "   'title': 'Self-Supervised Representation Learning from Flow Equivariance',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '3b65b8ed14ccb6ed102e0290adc57d00e27218c9',\n",
       "   'title': 'Learning Accurate Dense Correspondences and When to Trust Them',\n",
       "   'influentialCitationCount': 7},\n",
       "  {'paperId': 'af9903f4526dc912c56b34ca7d8bf2ecb6927820',\n",
       "   'title': 'Unsupervised Monocular Depth Reconstruction of Non-Rigid Scenes',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '2cc6b5366f41e51a8a39097f6498d865011c3431',\n",
       "   'title': 'Dynamic Facial Expression Recognition under Partial Occlusion with Optical Flow Reconstruction',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '0a15a7ea04aaa4a0e20ab3ff46576e92026788cc',\n",
       "   'title': 'Robust Consistent Video Depth Estimation',\n",
       "   'influentialCitationCount': 10},\n",
       "  {'paperId': '54f5e54a90e7f74dfadbc5b3cc08fa43e4851290',\n",
       "   'title': 'PV-RAFT: Point-Voxel Correlation Fields for Scene Flow Estimation of Point Clouds',\n",
       "   'influentialCitationCount': 8},\n",
       "  {'paperId': '590073947a4cd7cb2f1c8840076e047a35704fb9',\n",
       "   'title': 'RAFT-3D: Scene Flow using Rigid-Motion Embeddings',\n",
       "   'influentialCitationCount': 9},\n",
       "  {'paperId': '55d7325804bfc1b362b9d2a9613f996b9e9be29f',\n",
       "   'title': 'UPFlow: Upsampling Pyramid for Unsupervised Optical Flow Learning',\n",
       "   'influentialCitationCount': 2},\n",
       "  {'paperId': '6c954a5034b543a70e621c9f18997510b82f0a47',\n",
       "   'title': 'Improved Handling of Motion Blur in Online Object Detection',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '13034a395d5c6728c9b11e777828d9998018cbf6',\n",
       "   'title': 'Neural Scene Flow Fields for Space-Time View Synthesis of Dynamic Scenes',\n",
       "   'influentialCitationCount': 29},\n",
       "  {'paperId': '0f1af3f94f4699cd70a554f68f8f9e2c8e3d53dd',\n",
       "   'title': 'Nerfies: Deformable Neural Radiance Fields',\n",
       "   'influentialCitationCount': 42},\n",
       "  {'paperId': 'a6fed6b0c9c18aa02e5063bf6767b4272e38bb7c',\n",
       "   'title': 'Recurrent Multi-view Alignment Network for Unsupervised Surface Registration',\n",
       "   'influentialCitationCount': 2},\n",
       "  {'paperId': '1e3074c3dac8f924e21c79a3eb606606d0c0a70a',\n",
       "   'title': 'FlowStep3D: Model Unrolling for Self-Supervised Scene Flow Estimation',\n",
       "   'influentialCitationCount': 15},\n",
       "  {'paperId': 'd458813307ede4020961e0cee9f3e275cce80a88',\n",
       "   'title': 'Deep Multi-view Depth Estimation with Predicted Uncertainty',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'e4ac49aa6f1d7ea8bfa3b09b4642bc2ec68ca5a0',\n",
       "   'title': 'EffiScene: Efficient Per-Pixel Rigidity Inference for Unsupervised Joint Learning of Optical Flow, Depth, Camera Pose and Motion Segmentation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '65d1940f48243c4fb7f5cbfdc0d28042c4d38e41',\n",
       "   'title': '“What’s This?” - Learning to Segment Unknown Objects from Manipulation Sequences',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '88b1113f94c0ab9521af358f4d9f7e9bff643e12',\n",
       "   'title': 'Revisiting Adaptive Convolutions for Video Frame Interpolation',\n",
       "   'influentialCitationCount': 2},\n",
       "  {'paperId': '9868b29b7cf2979104f1e26697f774dbc2c9b7d9',\n",
       "   'title': 'Video Denoising by Combining Patch Search and CNNs',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '39ca8f8ff28cc640e3b41a6bd7814ab85c586504',\n",
       "   'title': 'Deformable DETR: Deformable Transformers for End-to-End Object Detection',\n",
       "   'influentialCitationCount': 297},\n",
       "  {'paperId': 'b000b9982df894a66a5c7159506d7bda2cf62e1f',\n",
       "   'title': 'OIFlow: Occlusion-Inpainting Optical Flow Estimation by Unsupervised Learning',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '43c09a9d8a631942371c998eaf606294275bccc8',\n",
       "   'title': 'Burst Photography for Learning to Enhance Extremely Dark Images',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': '154278b4c3de46fe0e89b87a53eee1c3932315a7',\n",
       "   'title': 'STC-Flow: Spatio-temporal Context-aware Optical Flow Estimation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '1b1abfbb832b2123f3b9ada9449f6b5b28548914',\n",
       "   'title': 'Automatic generation of dense non-rigid optical flow',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '46aceb26f487d4da6440a15f6c34de4e3ed5a0cc',\n",
       "   'title': 'Supplementary Materials for Separable Flow',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '045e280ffa774366a726faf1327d0d88551a6718',\n",
       "   'title': 'Sensor-Guided Optical Flow Supplementary material',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '829b272d41e316170823718a79c0f95dceb03eef',\n",
       "   'title': 'Dense Optical Flow from Event Cameras',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '033ca87372d74ee2d9d4bc283e64f8f7bb3bc512',\n",
       "   'title': 'COHESIV: Contrastive Object and Hand Embeddings for Segmentation In Video',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '9ec007634ff429960b708d327c1442044cf21859',\n",
       "   'title': 'Monocular Arbitrary Moving Object Discovery and Segmentation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '9690ed370806740efe7f69e5cb243053a032e1a9',\n",
       "   'title': 'Segmenting Invisible Moving Objects',\n",
       "   'influentialCitationCount': 2},\n",
       "  {'paperId': '4eb57d5d59b128b0322330193879b0b24c3546bf',\n",
       "   'title': 'Hierarchical Interaction Network for Video Object Segmentation from Referring Expressions',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'e06c0a71788723268edeaa3e16f8cd9f74458370',\n",
       "   'title': 'Unsupervised computation of salient motion maps from the interpretation of a frame-based classification network',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '5435942daca9fdbeeb6def7201403195d0f39fa3',\n",
       "   'title': 'Diffusion-Based Refinement of Optical Flow',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '61008d0d0353f0ae8e69b3990978cf622ed1aee2',\n",
       "   'title': 'Distractor-Aware Video Object Segmentation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '28785908490277c863e36553950c5868d1923765',\n",
       "   'title': 'Advanced Data Augmentation for the RAFT Optical Flow Approach',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'a949b84dd676a5320744f5703bb42fdb87513a87',\n",
       "   'title': '360° Optical Flow using Tangent Images',\n",
       "   'influentialCitationCount': 2},\n",
       "  {'paperId': '51cc6df9587f6d57d6b894e8acbb4685b6df2869',\n",
       "   'title': 'ViSER: Video-Specific Surface Embeddings for Articulated 3D Shape Reconstruction',\n",
       "   'influentialCitationCount': 2},\n",
       "  {'paperId': '1e47f138362303bf644f6499b48a2c21bed3e9bd',\n",
       "   'title': 'oflibnumpy & oflibpytorch: Optical Flow Handling and Manipulation in Python',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '6faf0acb097c09b5db87601b26183e58ca90e0ee',\n",
       "   'title': 'Occlusion-Aware Video Object Inpainting (Supplemental material)',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'afb51d6454f1f0437d6787f5667ce5737d1fb3e6',\n",
       "   'title': 'Nerfies: Deformable Neural Radiance Fields (Supplementary Materials)',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '5052a5e8b53a3119bbd1450adc2849d67a2e3cc3',\n",
       "   'title': 'High-Resolution Optical Flow from 1D Attention and Correlation Supplementary Material',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'ceb4f4cbc2b5c32b998cd1bf6ad5eff3e99f90c0',\n",
       "   'title': 'POOF: Efficient Goalie Pose Annotation using Optical Flow',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '2853f6a5da6f968a0b911ef4d00b81268e21a2dd',\n",
       "   'title': 'Efficient Image Registration Network for Non-Rigid Cardiac Motion Estimation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '308f42a647b9a9a3fcbe32312a61a717469690b9',\n",
       "   'title': 'Segmenting out Generic Objects in Monocular Videos',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '9406b229222565d9214d0e2c4761494b47c3b177',\n",
       "   'title': 'HDR4CV: High Dynamic Range Dataset with Adversarial Illumination for Testing Computer Vision Methods',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '0bc7fbbaa52dbfdb2ba17155156244792130bd9c',\n",
       "   'title': 'Adaptive Template and Transition Map for Real-Time Video Object Segmentation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'c528f7f6a9045b7d6b3745637b73975edd09d9c2',\n",
       "   'title': 'Multimodal Transformer Networks for Pedestrian Trajectory Prediction',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '0ccb368dea65537dae0951e0e9e1fe83671b8237',\n",
       "   'title': 'Semi-Automatic 2D to 3D Video Conversion',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '6b885efdc059b7765ba8411a08e11af5b4c3921d',\n",
       "   'title': 'Efficient Video Object Segmentation with Compressed Video',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '48767c4d6ad042f95810be1be8e68b1ccd866e52',\n",
       "   'title': 'Efficient Video Object Segmentation with Compressed Video',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'd972b975eb95eb4e3a51c41631e9745973e3348f',\n",
       "   'title': 'Robust Consistent Video Depth Estimation Supplementary Material',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '6b5ad3ad6cdf7ecec40b386dba5e05abb6683a2c',\n",
       "   'title': 'Self-supervised Learning of Decomposed Object-wise 3D Motion and Depth from Monocular Videos',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '269e33a05691478f5b24ef27c1474eb797a2b341',\n",
       "   'title': 'Deep Networks for Image-to-Image Prediction',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '7bb626edc37f4d7d3a48b1201872a102f36aa466',\n",
       "   'title': 'An Anisotropic Selection Scheme for Variational Optical Flow Methods with Order-Adaptive Regularisation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'f134525b707157cc259e166d811a983fc18c184a',\n",
       "   'title': 'A Novel Spatio-Temporal 3D Convolutional Encoder-Decoder Network for Dynamic Saliency Prediction',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'a777a2946d6a3914c7d89aaa092f5cb09efac6a9',\n",
       "   'title': 'Implicit Feature Pyramid Network for Object Detection',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': '436e1d15c415e621b8ae68712b7cc0203a3f4554',\n",
       "   'title': 'Iterative Knowledge Exchange Between Deep Learning and Space-Time Spectral Clustering for Unsupervised Segmentation in Videos',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '2eb770c6a3a359f50fb29336b15f6b58ac2f7ae7',\n",
       "   'title': 'Full-Resolution Correspondence Learning for Image Translation',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': '17d3ecc84d06c2d5d19e5b3a90885534a1707e6e',\n",
       "   'title': 'Unsupervised Optical Flow Using Cost Function Unrolling',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'dfba9ee53dab98cffcd42a74ae604adbb3a1a7f2',\n",
       "   'title': 'Cost Function Unrolling in Unsupervised Optical Flow',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'c8993a95dac7a0bf86fb96ee30cf653a57755783',\n",
       "   'title': 'Can Temporal Information Help with Contrastive Self-Supervised Learning?',\n",
       "   'influentialCitationCount': 3},\n",
       "  {'paperId': '3ede5c472bea1d1dfab0fd3dbb5422f402962622',\n",
       "   'title': 'RIFE: Real-Time Intermediate Flow Estimation for Video Frame Interpolation',\n",
       "   'influentialCitationCount': 22},\n",
       "  {'paperId': '5b33e4fe0fe68e74f441085e2dbcc29f4ee1c821',\n",
       "   'title': 'CoT-AMFlow: Adaptive Modulation Network with Co-Teaching Strategy for Unsupervised Optical Flow Estimation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '71a2054789a83405f8c2a7273d71de50e78b0d49',\n",
       "   'title': 'Displacement-Invariant Matching Cost Learning for Accurate Optical Flow Estimation',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': 'b6eb1047eecb39d40da3c09faa599c7dfd560a89',\n",
       "   'title': 'Deep Selective Combinatorial Embedding and Consistency Regularization for Light Field Super-resolution',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '1292ef59c77f74de6804e16db2c37bc2a3a02941',\n",
       "   'title': 'Towards General Purpose and Geometry Preserving Single-View Depth Estimation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '64ea46a09286bb97e8ce06a6ef085ec26bbf9166',\n",
       "   'title': 'PRAFlow_RVC: Pyramid Recurrent All-Pairs Field Transforms for Optical Flow Estimation in Robust Vision Challenge 2020',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'bd1b9aac9b0a4fd9b653c6215a9d38e8d37b7130',\n",
       "   'title': 'Learnable Cost Volume Using the Cayley Representation',\n",
       "   'influentialCitationCount': 1},\n",
       "  {'paperId': '4066594a97f5eed7e0db0cfaa9e47d36c0d79801',\n",
       "   'title': 'Restoration and Enhancement of Historical Stereo Photos Through Optical Flow',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '8c5a73baec63a08d617b0fd249d1ffff3f929a75',\n",
       "   'title': 'Real-Time Spatio-Temporal Action Localization via Learning Motion Representation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'a61a79943f55bd79f4f6cadd4893ac550a458645',\n",
       "   'title': 'DEFORMABLE DETR: DEFORMABLE TRANSFORMERS',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'c84780beb9a2756fb5099e6a677826103541338a',\n",
       "   'title': 'Large Displacement Optical Flow Estimation Based on Robust Interpolation of Sparse Correspondences',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'a08d99bec173b7fec18709acf16ef209ec0d5a0e',\n",
       "   'title': 'PatchFlow: A Two-Stage Patch-Based Approach for Lightweight Optical Flow Estimation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '0795d8d0e415484710025f0ac3ce1c5c79666fcd',\n",
       "   'title': 'Synthesizing Light Field Video from Monocular Video',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'b77660a06b6282ae1cc3fc715b56c1a35adbe100',\n",
       "   'title': 'DeFlowSLAM: Self-Supervised Scene Motion Decomposition for Dynamic Dense SLAM',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': '2cad253ae89bb116e4ed719e6314c1bc75dd3ef7',\n",
       "   'title': 'GMFlow: Learning Optical Flow via Global Matching Supplementary Material',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'cf6a902bb51fc8c75e29db3cb91b04f12782e066',\n",
       "   'title': 'Coupled Iterative Refinement for 6D Multi-Object Pose Estimation',\n",
       "   'influentialCitationCount': 0},\n",
       "  {'paperId': 'a94f40bc7a3e6caa9a57e14670fc9209c6276c22',\n",
       "   'title': 'Motion-based MAV Detection in GPS-denied Environments',\n",
       "   'influentialCitationCount': 0}],\n",
       " 'references': [{'paperId': '50fbf62ed38a6c4ff1acdfb0bae6465f89866fc6',\n",
       "   'title': 'A Lightweight Optical Flow CNN —Revisiting Data Fidelity and Regularization'},\n",
       "  {'paperId': 'ce901c28e7321b1811ae5dde7ff7e9074307d57f',\n",
       "   'title': 'MaskFlownet: Asymmetric Feature Matching With Learnable Occlusion Mask'},\n",
       "  {'paperId': 'c842b46f715dae530c368ce97e5419e521f1769f',\n",
       "   'title': 'ScopeFlow: Dynamic Scene Scoping for Optical Flow'},\n",
       "  {'paperId': 'e1dc70fcd76af8adc3b351a1df8dbdf42479a0cf',\n",
       "   'title': 'Improving Optical Flow on a Pyramid Level'},\n",
       "  {'paperId': 'dfb22535ada5e35b9ed3523499127003e4afc00d',\n",
       "   'title': 'DeepV2D: Video to Depth with Differentiable Structure from Motion'},\n",
       "  {'paperId': 'bc294b251085b76f166c2ec16c3ee77f02800ec0',\n",
       "   'title': 'Models Matter, So Does Training: An Empirical Study of CNNs for Optical Flow Estimation'},\n",
       "  {'paperId': 'bced38211fdfd1ed8caf7b7eb7dd6edfd7b53255',\n",
       "   'title': 'Devon: Deformable Volume Network for Learning Optical Flow'},\n",
       "  {'paperId': '67dc469cf734a187fe263eb9f207884b7dd40d21',\n",
       "   'title': 'The Five Elements of Flow'},\n",
       "  {'paperId': '88e83776313effc1564044d7bf19972981815e3c',\n",
       "   'title': 'Differentiable Convex Optimization Layers'},\n",
       "  {'paperId': '9a618cca0d2fc78db1be1aed70517401cb3f3859',\n",
       "   'title': 'Deep Equilibrium Models'},\n",
       "  {'paperId': 'cdbef23475c744f0e8ebb62dd9ced57948e2442c',\n",
       "   'title': 'Hierarchical Deep Stereo Matching on High-Resolution Images'},\n",
       "  {'paperId': '0c0eb3040a32484fcb6270841e14b78f284e7570',\n",
       "   'title': 'DeepView: View Synthesis With Learned Gradient Descent'},\n",
       "  {'paperId': 'a0c3a0a2ee00d0e0ca9a65f7b663d22b0be38d98',\n",
       "   'title': 'SelFlow: Self-Supervised Learning of Optical Flow'},\n",
       "  {'paperId': '281c84088a4294bc0c74b4bb21d1800f2f925a5e',\n",
       "   'title': 'Iterative Residual Refinement for Joint Optical Flow and Occlusion Estimation'},\n",
       "  {'paperId': '0d6e863518d284348fafcf0c9c22d464d5ab7a5e',\n",
       "   'title': 'Taking a Deeper Look at the Inverse Compositional Algorithm'},\n",
       "  {'paperId': '7b4ac890f9635d839a043adce0c23090aa8a02f9',\n",
       "   'title': 'Hierarchical Discrete Distribution Decomposition for Match Density Estimation'},\n",
       "  {'paperId': 'a14af711aaa3ae83eb64d1f517b024b8c3094a8a',\n",
       "   'title': 'Trellis Networks for Sequence Modeling'},\n",
       "  {'paperId': 'd07284a6811f1b2745d91bdb06b040b57f226882',\n",
       "   'title': 'Decoupled Weight Decay Regularization'},\n",
       "  {'paperId': 'e8371a6a7ff5f3bf0dcdda4742bfe8edfc5e9054',\n",
       "   'title': 'Flow Fields: Dense Correspondence Fields for Highly Accurate Large Displacement Optical Flow Estimation'},\n",
       "  {'paperId': '15422a62664c6d79c9a3e70625e1f07b1f245c10',\n",
       "   'title': 'Volumetric Correspondence Networks for Optical Flow'},\n",
       "  {'paperId': 'ac5181b8f47b13edd885dc900065d3c19d6dcaf1',\n",
       "   'title': 'DeepView: High-quality view synthesis by learned gradient descent'},\n",
       "  {'paperId': '76792d5c474e168a86f8337b2d56531c2825c81c',\n",
       "   'title': 'DeepTAM: Deep Tracking and Mapping'},\n",
       "  {'paperId': 'c2039c76ef7dc86af9e758d7fee3058d9bfbd550',\n",
       "   'title': 'Recurrent Squeeze-and-Excitation Context Aggregation Net for Single Image Deraining'},\n",
       "  {'paperId': '5430ccd976e738827304b1535e63cc85f09c2cdb',\n",
       "   'title': 'BA-Net: Dense Bundle Adjustment Network'},\n",
       "  {'paperId': '051b3763c2ad4e4271db712b0e9a4cfe298d05db',\n",
       "   'title': 'LiteFlowNet: A Lightweight Convolutional Neural Network for Optical Flow Estimation'},\n",
       "  {'paperId': '2229c78224607a440130c8ca18bc1992c00176d6',\n",
       "   'title': 'FlowFields++: Accurate Optical Flow Correspondences Meet Robust Interpolation'},\n",
       "  {'paperId': '259dcd1afe22e569132ccc41697ac368504c4dd1',\n",
       "   'title': 'End-to-End Learning of Motion Representation for Video Understanding'},\n",
       "  {'paperId': '33389b1da844f13aba317e8b16c814888c26c827',\n",
       "   'title': 'Learning for Disparity Estimation Through Feature Constancy'},\n",
       "  {'paperId': 'd92ef81e39d65d89f2c35d63088d1950ed862e7d',\n",
       "   'title': 'PWC-Net: CNNs for Optical Flow Using Pyramid, Warping, and Cost Volume'},\n",
       "  {'paperId': '4ec81d1096139b25117c42d70f29b0cc6f003587',\n",
       "   'title': 'Learned Primal-Dual Reconstruction'},\n",
       "  {'paperId': 'b36a5bb1707bb9c70025294b3a310138aae8327a',\n",
       "   'title': 'Automatic differentiation in PyTorch'},\n",
       "  {'paperId': 'a44730c5b7d1cba7e8d073b6a6219312ed8bba75',\n",
       "   'title': 'Variational Networks: Connecting Variational Methods and Deep Learning'},\n",
       "  {'paperId': '857bc1f10bbfb5ff340230114d5c30bcf2224d1c',\n",
       "   'title': 'Optical Flow in Mostly Rigid Scenes'},\n",
       "  {'paperId': '143e10cae07f27f2db9de171eb04a332ddbfeab4',\n",
       "   'title': 'Accurate Optical Flow via Direct Cost Volume Processing'},\n",
       "  {'paperId': '23012c72b9559321222fb6137a03ce3e14440727',\n",
       "   'title': 'Solving ill-posed inverse problems using iterative deep neural networks'},\n",
       "  {'paperId': '49e8fec24cce8b73706bc5fcd2c3f681addb9982',\n",
       "   'title': 'The 2017 DAVIS Challenge on Video Object Segmentation'},\n",
       "  {'paperId': '0076b232181e4e5be58dce8354a813ad2bbf663a',\n",
       "   'title': 'OptNet: Differentiable Optimization as a Layer in Neural Networks'},\n",
       "  {'paperId': 'edd846e76cacfba5be37da99c006e3ccc9b861b0',\n",
       "   'title': 'FlowNet 2.0: Evolution of Optical Flow Estimation with Deep Networks'},\n",
       "  {'paperId': 'a93d81c7f033f1e2b54d3288b60d214f55ccc010',\n",
       "   'title': 'Optical Flow Estimation Using a Spatial Pyramid Network'},\n",
       "  {'paperId': 'e24f9317ad8e391902c43f6b160730e98ad9904d',\n",
       "   'title': 'The HCI Benchmark Suite: Stereo and Flow Ground Truth with Uncertainties for Urban Autonomous Driving'},\n",
       "  {'paperId': 'f5719438eb7e26827db9c3cd469063d1d12e1f19',\n",
       "   'title': 'Full Flow: Optical Flow Estimation By Global Optimization over Regular Grids'},\n",
       "  {'paperId': '1ced31e02234bc3d1092ffb2c7442ffbd51cb309',\n",
       "   'title': 'A Large Dataset to Train Convolutional Networks for Disparity, Optical Flow, and Scene Flow Estimation'},\n",
       "  {'paperId': '658cdec56b02edf3364fe184d6f166761877b429',\n",
       "   'title': 'Discrete Optimization for Optical Flow'},\n",
       "  {'paperId': 'edf455c3b5b8d1c6337c72e39940125036354d03',\n",
       "   'title': 'Object scene flow for autonomous vehicles'},\n",
       "  {'paperId': 'c2fb5b39428818d7ec8cc78e152e19c21b7db568',\n",
       "   'title': 'FlowNet: Learning Optical Flow with Convolutional Networks'},\n",
       "  {'paperId': 'c8034536e5093b665bca049c1e4d495076540df4',\n",
       "   'title': 'Non-local Total Generalized Variation for Optical Flow Estimation'},\n",
       "  {'paperId': '1eb09fecd75eb27825dce4f964b97f4f5cc399d7',\n",
       "   'title': 'On the Properties of Neural Machine Translation: Encoder–Decoder Approaches'},\n",
       "  {'paperId': '56493a503eecb659bbef2fe4dd1fb915d251cac0',\n",
       "   'title': 'DeepFlow: Large Displacement Optical Flow with Deep Matching'},\n",
       "  {'paperId': '79b949d9b35c3f51dd20fb5c746cc81fc87147eb',\n",
       "   'title': 'Vision meets robotics: The KITTI dataset'},\n",
       "  {'paperId': '7d53f0c87c8ab0de6f3e74515e3ffaf3fab40c62',\n",
       "   'title': 'A Naturalistic Open Source Movie for Optical Flow Evaluation'},\n",
       "  {'paperId': '472e8257dca67af31539bc2bdc1479a4c43bca2f',\n",
       "   'title': 'A First-Order Primal-Dual Algorithm for Convex Problems with\\xa0Applications to Imaging'},\n",
       "  {'paperId': 'aa9f82781a0d844faec8616ffbe68113536fefea',\n",
       "   'title': 'Large displacement optical flow'},\n",
       "  {'paperId': '63623c63ffddd08d266d884680d3493e8b7705f1',\n",
       "   'title': 'Stereo Processing by Semiglobal Matching and Mutual Information'},\n",
       "  {'paperId': '0f6bbe9afab5fd61f36de5461e9e6a30ca462c7c',\n",
       "   'title': 'A Duality Based Approach for Realtime TV-L1 Optical Flow'},\n",
       "  {'paperId': '65297c4e40fd9b8129fc593be1b8c8ef775c86ba',\n",
       "   'title': 'A framework for the robust estimation of optical flow'},\n",
       "  {'paperId': 'a3229dc33ecb80c59a75b906c46b586dd059b781',\n",
       "   'title': 'Determining Optical Flow'},\n",
       "  {'paperId': None,\n",
       "   'title': 'Unit (32) Res. Unit (32) Res. Unit (64) Res. Unit (64) Res. Unit (96) Res. Unit(96)'}]}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_done = df_sem_sch_authors[\"author_searched\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_id = \"1706.03762\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f\"https://api.semanticscholar.org/graph/v1/paper/arXiv:{arxiv_id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.twitter_key import SemanticScholarCreds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get(url, headers={\"x-api-key\":SemanticScholarCreds.API_KEY })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'paperId': '204e3073870fae3d05bcbc2f6a8e263d9b72e776',\n",
       " 'title': 'Attention is All you Need'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find authors[##########################################..................] 6188/8663\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [17], line 39\u001b[0m\n\u001b[1;32m     37\u001b[0m df_sem_scholar_papers \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([df_sem_scholar_papers, _df_sem_scholar_papers])\n\u001b[1;32m     38\u001b[0m df_sem_sch_authors\u001b[39m.\u001b[39mto_pickle(\u001b[39m\"\u001b[39m\u001b[39m../data/sem_sch_authors.pickle\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 39\u001b[0m df_sem_scholar_papers\u001b[39m.\u001b[39;49mto_pickle(\u001b[39m\"\u001b[39;49m\u001b[39m../data/sem_sch_papers.pickle\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     40\u001b[0m time\u001b[39m.\u001b[39msleep(\u001b[39m2\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/dlsys/lib/python3.10/site-packages/pandas/core/generic.py:3064\u001b[0m, in \u001b[0;36mNDFrame.to_pickle\u001b[0;34m(self, path, compression, protocol, storage_options)\u001b[0m\n\u001b[1;32m   3012\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   3013\u001b[0m \u001b[39mPickle (serialize) object to file.\u001b[39;00m\n\u001b[1;32m   3014\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3060\u001b[0m \u001b[39m4    4    9\u001b[39;00m\n\u001b[1;32m   3061\u001b[0m \u001b[39m\"\"\"\u001b[39;00m  \u001b[39m# noqa: E501\u001b[39;00m\n\u001b[1;32m   3062\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpickle\u001b[39;00m \u001b[39mimport\u001b[39;00m to_pickle\n\u001b[0;32m-> 3064\u001b[0m to_pickle(\n\u001b[1;32m   3065\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   3066\u001b[0m     path,\n\u001b[1;32m   3067\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[1;32m   3068\u001b[0m     protocol\u001b[39m=\u001b[39;49mprotocol,\n\u001b[1;32m   3069\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m   3070\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/dlsys/lib/python3.10/site-packages/pandas/io/pickle.py:112\u001b[0m, in \u001b[0;36mto_pickle\u001b[0;34m(obj, filepath_or_buffer, compression, protocol, storage_options)\u001b[0m\n\u001b[1;32m    109\u001b[0m     handles\u001b[39m.\u001b[39mhandle\u001b[39m.\u001b[39mwrite(pickle\u001b[39m.\u001b[39mdumps(obj, protocol\u001b[39m=\u001b[39mprotocol))\n\u001b[1;32m    110\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    111\u001b[0m     \u001b[39m# letting pickle write directly to the buffer is more memory-efficient\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m     pickle\u001b[39m.\u001b[39;49mdump(obj, handles\u001b[39m.\u001b[39;49mhandle, protocol\u001b[39m=\u001b[39;49mprotocol)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in progressbar(list(range(len(authors))), \"find authors\"):\n",
    "    if authors[i] not in authors_done:\n",
    "        try:\n",
    "            results = sch.search_author(authors[i])\n",
    "        except:\n",
    "            failed_authors.append([i, authors[i]])\n",
    "            continue\n",
    "        _df_sem_sch_authors = pd.DataFrame(columns=sem_sch_author_cols)\n",
    "        _df_sem_scholar_papers = pd.DataFrame(columns=sem_sch_paper_cols)\n",
    "\n",
    "\n",
    "        for author_data in results._data:\n",
    "            author_df = {k:v for k,v in author_data.items() if k in sem_sch_author_cols}\n",
    "            \n",
    "            if author_df[\"aliases\"] is None:\n",
    "                author_df[\"aliases\"] = [author_df[\"name\"]]\n",
    "            author_df = pd.DataFrame.from_dict(author_df)\n",
    "            _df_sem_sch_authors = pd.concat([author_df, _df_sem_sch_authors])\n",
    "            paper_auth = pd.DataFrame(columns=sem_sch_paper_cols)\n",
    "            for paper in author_data[\"papers\"]:\n",
    "                paper_deets = {k:v for k,v in paper.items() if k in sem_scholdar_api_reqs}\n",
    "                more_authors = {k:v for k,v in paper.items() if k == \"authors\"}\n",
    "                more_authors_df = pd.DataFrame.from_records(more_authors[\"authors\"])\n",
    "                paper_deets_df = pd.DataFrame([v for _,v in paper_deets.items()]).T\n",
    "                paper_deets_df.columns = sem_scholdar_api_reqs\n",
    "                paper_deets_df.index = range(1)\n",
    "                more_authors_df[\"paperId\"] = paper_deets_df[\"paperId\"].values[0]\n",
    "                more_authors_df[\"paperId\"] = more_authors_df[\"paperId\"].astype(\"object\")\n",
    "                paper_deets_df[\"paperId\"] = paper_deets_df[\"paperId\"].astype(\"object\")\n",
    "                more_papers_df =  more_authors_df.merge(paper_deets_df,on=\"paperId\", how=\"left\")\n",
    "                paper_auth = pd.concat([paper_auth, more_papers_df])\n",
    "            _df_sem_scholar_papers = pd.concat([_df_sem_scholar_papers, paper_auth])\n",
    "        _df_sem_sch_authors[\"author_searched\"] = authors[i]\n",
    "        _df_sem_scholar_papers[\"author_searched\"] = authors[i]\n",
    "\n",
    "        df_sem_sch_authors = pd.concat([df_sem_sch_authors, _df_sem_sch_authors])\n",
    "        df_sem_scholar_papers = pd.concat([df_sem_scholar_papers, _df_sem_scholar_papers])\n",
    "        df_sem_sch_authors.to_pickle(\"../data/sem_sch_authors.pickle\")\n",
    "        df_sem_scholar_papers.to_pickle(\"../data/sem_sch_papers.pickle\")\n",
    "        time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find authors[########....................................................] 756/5552\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/mf/n_myj7d91ndgl7zl03cg69gc0000gn/T/ipykernel_7290/467057965.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mdf_sem_scholar_papers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_sem_scholar_papers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_df_sem_scholar_papers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mdf_sem_sch_authors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/sem_sch_authors.pickle\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mdf_sem_scholar_papers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/sem_sch_papers.pickle\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dlsys/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_pickle\u001b[0;34m(self, path, compression, protocol, storage_options)\u001b[0m\n\u001b[1;32m   2960\u001b[0m             \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2961\u001b[0m             \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2962\u001b[0;31m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2963\u001b[0m         )\n\u001b[1;32m   2964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dlsys/lib/python3.7/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mto_pickle\u001b[0;34m(obj, filepath_or_buffer, compression, protocol, storage_options)\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             )\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i,_ in progressbar(failed_authors, \"find authors\"):\n",
    "    try:\n",
    "        results = sch.search_author(authors[i])\n",
    "    except:\n",
    "        failed_authors.append([i, authors[i]])\n",
    "        continue\n",
    "    _df_sem_sch_authors = pd.DataFrame(columns=sem_sch_author_cols)\n",
    "    _df_sem_scholar_papers = pd.DataFrame(columns=sem_sch_paper_cols)\n",
    "\n",
    "\n",
    "    for author_data in results._data:\n",
    "        author_df = {k:v for k,v in author_data.items() if k in sem_sch_author_cols}\n",
    "        \n",
    "        if author_df[\"aliases\"] is None:\n",
    "            author_df[\"aliases\"] = [author_df[\"name\"]]\n",
    "        author_df = pd.DataFrame.from_dict(author_df)\n",
    "        _df_sem_sch_authors = pd.concat([author_df, _df_sem_sch_authors])\n",
    "        paper_auth = pd.DataFrame(columns=sem_sch_paper_cols)\n",
    "        for paper in author_data[\"papers\"]:\n",
    "            paper_deets = {k:v for k,v in paper.items() if k in sem_scholdar_api_reqs}\n",
    "            more_authors = {k:v for k,v in paper.items() if k == \"authors\"}\n",
    "            more_authors_df = pd.DataFrame.from_records(more_authors[\"authors\"])\n",
    "            paper_deets_df = pd.DataFrame([v for _,v in paper_deets.items()]).T\n",
    "            paper_deets_df.columns = sem_scholdar_api_reqs\n",
    "            paper_deets_df.index = range(1)\n",
    "            more_authors_df[\"paperId\"] = paper_deets_df[\"paperId\"].values[0]\n",
    "            more_authors_df[\"paperId\"] = more_authors_df[\"paperId\"].astype(\"object\")\n",
    "            paper_deets_df[\"paperId\"] = paper_deets_df[\"paperId\"].astype(\"object\")\n",
    "            more_papers_df =  more_authors_df.merge(paper_deets_df,on=\"paperId\", how=\"left\")\n",
    "            paper_auth = pd.concat([paper_auth, more_papers_df])\n",
    "        _df_sem_scholar_papers = pd.concat([_df_sem_scholar_papers, paper_auth])\n",
    "    _df_sem_sch_authors[\"author_searched\"] = authors[i]\n",
    "    _df_sem_scholar_papers[\"author_searched\"] = authors[i]\n",
    "\n",
    "    df_sem_sch_authors = pd.concat([df_sem_sch_authors, _df_sem_sch_authors])\n",
    "    df_sem_scholar_papers = pd.concat([df_sem_scholar_papers, _df_sem_scholar_papers])\n",
    "    df_sem_sch_authors.to_pickle(\"../data/sem_sch_authors.pickle\")\n",
    "    df_sem_scholar_papers.to_pickle(\"../data/sem_sch_papers.pickle\")\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "proxy = FreeProxy(rand=True, elite=True).get()\n",
    "with requests.Session() as session:\n",
    "   for proxy in proxies:\n",
    "       send_request(session, proxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://119.8.236.97:3128'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with requests.Session() as session:\n",
    "   for proxy in proxies:\n",
    "       send_request(session, proxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scholarly import ProxyGenerator\n",
    "from scholarly import scholarly\n",
    "# Set up a ProxyGenerator object to use free proxies\n",
    "# This needs to be done only once per session\n",
    "pg = ProxyGenerator()\n",
    "pg.FreeProxies()\n",
    "scholarly.use_proxy(pg)\n",
    "\n",
    "# Now search Google Scholar from behind a proxy\n",
    "search_query = scholarly.search_pubs('Perception of physical stability and center of mass of 3D objects')\n",
    "scholarly.pprint(next(search_query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "def levenshteinDistanceDP(token1, token2):\n",
    "    distances = numpy.zeros((len(token1) + 1, len(token2) + 1))\n",
    "\n",
    "    for t1 in range(len(token1) + 1):\n",
    "        distances[t1][0] = t1\n",
    "\n",
    "    for t2 in range(len(token2) + 1):\n",
    "        distances[0][t2] = t2\n",
    "        \n",
    "    a = 0\n",
    "    b = 0\n",
    "    c = 0\n",
    "    \n",
    "    for t1 in range(1, len(token1) + 1):\n",
    "        for t2 in range(1, len(token2) + 1):\n",
    "            if (token1[t1-1] == token2[t2-1]):\n",
    "                distances[t1][t2] = distances[t1 - 1][t2 - 1]\n",
    "            else:\n",
    "                a = distances[t1][t2 - 1]\n",
    "                b = distances[t1 - 1][t2]\n",
    "                c = distances[t1 - 1][t2 - 1]\n",
    "                \n",
    "                if (a <= b and a <= c):\n",
    "                    distances[t1][t2] = a + 1\n",
    "                elif (b <= a and b <= c):\n",
    "                    distances[t1][t2] = b + 1\n",
    "                else:\n",
    "                    distances[t1][t2] = c + 1\n",
    "\n",
    "    return distances[len(token1)][len(token2)]\n",
    "        \n",
    "levenshteinDistanceDP(\"kelm\", \"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.15 ('si507')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ddd7320518ce5601792dbb0fe8a48e4eb03406ca8ae1602029fd684085d640f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
