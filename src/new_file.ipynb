{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from primitive_objects import Authors, ArxivPaper, SemSchPaper\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem_sch_papers_df = pd.read_pickle(\"../data/sem_sch_papers.pickle\")\n",
    "arxiv_papers_df = pd.read_pickle(\"../data/arxiv_paper_ids.pickle\")\n",
    "authors_df = pd.read_pickle(\"../data/sem_sch_authors.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_primary_key = authors_df[[\"name\", \"paperCount\", \"citationCount\",\"hIndex\"]].drop_duplicates()\n",
    "author_primary_key.index = range(author_primary_key.shape[0])\n",
    "author_primary_key[\"author_unq_id\"] = range(author_primary_key.shape[0])\n",
    "authors_df_new = pd.merge(authors_df,author_primary_key, on=[\"name\", \"paperCount\",\"citationCount\",\"hIndex\"], how=\"left\")\n",
    "author_ids = authors_df[\"authorId\"].unique()\n",
    "authors_df_np = authors_df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = []\n",
    "for author_id in tqdm(author_ids):\n",
    "    row_nums = np.where(authors_df_np[:, 0] == author_id)[0]\n",
    "    df_auth =  authors_df_np[row_nums, :]\n",
    "    author_name = df_auth[:, 1][0]\n",
    "    author_aliases = np.unique(df_auth[:, 2]).tolist()\n",
    "    homepage = df_auth[:, 3][0]\n",
    "    paper_count = df_auth[:, 4][0]\n",
    "    citations = df_auth[:, 5][0]\n",
    "    hindex = df_auth[:, 6][0]\n",
    "    author_name_query = df_auth[:, 7][0]\n",
    "    author = Authors(\n",
    "        author_id = author_id, \n",
    "        author_name = author_name, \n",
    "        author_aliases = author_aliases, \n",
    "        homepage = homepage, \n",
    "        paper_count = paper_count, \n",
    "        citations = citations, \n",
    "        hindex = hindex, \n",
    "        author_name_query=author_name_query\n",
    "        )\n",
    "    authors.append(author)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Papers DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sem sch papers df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_ids = sem_sch_papers_df.paperId.unique()\n",
    "sem_sch_papers_df_np = sem_sch_papers_df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem_sch_papers_df = sem_sch_papers_df.sort_values(by=\"paperId\")\n",
    "sem_sch_papers_df.index = range(sem_sch_papers_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers = np.zeros((len(paper_ids))).tolist()\n",
    "prev_id = sem_sch_papers_df.paperId.values[0]\n",
    "paper_index = 0\n",
    "for row in tqdm(sem_sch_papers_df.iterrows()):\n",
    "    curr_id = row[1][\"paperId\"]\n",
    "    if row[0] == 0:\n",
    "        paper = SemSchPaper(\n",
    "            curr_id,\n",
    "            row[1][\"title\"],\n",
    "            [row[1][\"authorId\"]],\n",
    "            row[1][\"abstract\"],\n",
    "            row[1][\"year\"],\n",
    "            row[1][\"referenceCount\"],\n",
    "            row[1][\"citationCount\"],\n",
    "            row[1][\"influentialCitationCount\"],\n",
    "            row[1][\"isOpenAccess\"]\n",
    "        )\n",
    "    else:\n",
    "        if curr_id == prev_id:\n",
    "            \n",
    "            paper.authors.append(row[1][\"authorId\"])\n",
    "        else:\n",
    "            papers[paper_index] = paper\n",
    "            paper_index +=1\n",
    "            paper = SemSchPaper(\n",
    "                curr_id,\n",
    "                row[1][\"title\"],\n",
    "                [row[1][\"authorId\"]],\n",
    "                row[1][\"abstract\"],\n",
    "                row[1][\"year\"],\n",
    "                row[1][\"referenceCount\"],\n",
    "                row[1][\"citationCount\"],\n",
    "                row[1][\"influentialCitationCount\"],\n",
    "                row[1][\"isOpenAccess\"]\n",
    "            )\n",
    "    prev_id = curr_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_dict_keys = [\"id\", \"title\", \"authors\", \"abstract\", \"category\", \"year\",\n",
    "\"reference_count\",\"citation_count\", \"influential_paper_citations\",\"is_open_access\"]\n",
    "author_dict_keys = [\"id\", \"name\", \"aliases\", \"homepage\", \"paper_count\", \"citations\",\n",
    "\"hindex\", \"name_query\", \"papers\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = {\"a\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tes\n"
     ]
    }
   ],
   "source": [
    "if dd.get(\"a\"):\n",
    "    print(\"tes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_dict = {}\n",
    "\n",
    "for paper in tqdm(papers):\n",
    "    if isinstance(paper, SemSchPaper):\n",
    "        local_dict = {}\n",
    "        paper_id = paper.id\n",
    "        for k in paper_dict_keys:\n",
    "            k_v = getattr(paper, k)\n",
    "            local_dict[k] = k_v\n",
    "        paper_dict[paper_id] = local_dict\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "author_dict = {}\n",
    "for author in tqdm(authors):\n",
    "    if isinstance(author, Authors):\n",
    "        local_dict = {}\n",
    "        author_id = author.id\n",
    "        for k in author_dict_keys:\n",
    "            try:\n",
    "                k_v = getattr(author, k)\n",
    "            except:\n",
    "                k_v = None\n",
    "            local_dict[k] = k_v\n",
    "        author_dict[author_id] = local_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/papers.json\", \"w\") as f:\n",
    "    json.dump(paper_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/authors.json\", \"w\") as f:\n",
    "    json.dump(author_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/all_authors.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(author_ids.tolist()))\n",
    "\n",
    "with open(\"../data/all_papers.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(paper_ids.tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from primitive_objects import Authors, SemSchPaper\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import re\n",
    "import langid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/all_authors.txt\", 'r') as f:\n",
    "    author_ids = f.readlines()\n",
    "with open(\"../data/all_papers.txt\", 'r') as f:\n",
    "    paper_ids = f.readlines()\n",
    "author_ids = [f.replace(\"\\n\",\"\") for f in author_ids]\n",
    "paper_ids = [f.replace(\"\\n\",\"\") for f in paper_ids]\n",
    "\n",
    "with open(\"../data/papers.json\", 'r') as f:\n",
    "    cache_papers = json.load(f)\n",
    "\n",
    "with open(\"../data/authors.json\", 'r') as f:\n",
    "    cache_authors = json.load(f)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_keys = list(cache_papers.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_dict = cache_papers[\"00000ea534600af26a435c739e17bbaf460ee485\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<primitive_objects.SemSchPaper at 0x7fb2c577fa90>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SemSchPaper(**paper_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['id', 'title', 'authors', 'abstract', 'category', 'year', 'reference_count', 'citation_count', 'influential_paper_citations', 'is_open_access'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(cache_papers.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = []\n",
    "for author_id in author_ids:\n",
    "    if cache_authors.get(author_id):\n",
    "        cache_dict = cache_authors[author_id]\n",
    "        author = Authors(cache_file=cache_dict)\n",
    "    authors.append(author)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers = []\n",
    "for paper_id in paper_ids:\n",
    "    if cache_papers.get(paper_id):\n",
    "        cache_dict = cache_papers[paper_id]\n",
    "        paper = SemSchPaper(cache_file=cache_dict)\n",
    "    papers.append(paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, OPTForCausalLM\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/galactica-1.3b\")\n",
    "model = OPTForCausalLM.from_pretrained(\"facebook/galactica-1.3b\", device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_suffix = \"\\n\\nWhat scientific entities are mentioned in the abstract above?\\n\\n\"\n",
    "summary_suffix = \"\\n\\nTLDR:\"\n",
    "split_str= \"What scientific entities are mentioned in the abstract above\\?\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for paper in tqdm(papers):\n",
    "    abstract = paper.abstract\n",
    "    \n",
    "    if (abstract is not None) and (langid.classify(abstract)[0] == 'en'):\n",
    "        abstract = \" \".join(abstract.split(\" \")[:300])\n",
    "        input_text = abstract + entities_suffix\n",
    "        input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "        outputs = model.generate(input_ids, max_length=160)\n",
    "        output_text = tokenizer.decode(outputs[0])\n",
    "        match = re.split(split_str,output_text)\n",
    "        categories = [f.replace(\"</s>\",\"\") for f in match[-1].split(\", \")]\n",
    "        paper.category = categories\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.15 ('si507')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ddd7320518ce5601792dbb0fe8a48e4eb03406ca8ae1602029fd684085d640f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
